---
title: Repairing cooperation through a cognitive intervention in the repeated Trust Game
subtitle: 
titlerunning: 
authorrunning: 
# thanks: The authors have no conflicts of interest to declare that are relevant to the content of this article. This work was supported by the UK Engineering and Physical Sciences Research Council under grant EP/S515255/1. 

authors:
- name: Ismail Guennouni
  address: Department of Experimental Psychology, University College London, 26 Bedford Way, London WC1H 0AP, United Kingdom
  email: i.guennouni.17@ucl.ac.uk

- name: Maarten Speekenbrink
  address: Department of Experimental Psychology, University College London, 26 Bedford Way, London WC1H 0AP, United Kingdom
  email: m.speekenbrink@ucl.ac.uk

- name: Quentin Huys
  address: Max Planck Institute of Computational Psychiatry
  email: q.huys@ucl.ac.uk

- name: Samuel Dupret
  address: HLI
  email: sam.dupret@ucl.ac.uk



keywords:
- Economic Games 
- Hidden Markov Models
- Repair of Cooperation
- Cognitive Intervention 


abstract: | 
  Social trust is an important building block of strong social bonds, and its absence is a risk factor for social dysfunction. As such, interventions to foster and strengthen trust-based cooperation are highly desirable. Using the repeated Trust Game paradigm, we assess the effectiveness of a cognitive intervention aimed at repairing the potential breakdown of cooperation from a pre-programmed, one-off defection by the opponent. Over two games, participants are given the role of the trustee and face what they believe are two different players. In between games, they either receive a brief cognitive intervention or not. The intervention led to more cooperative behavior both pre and post defection by the opponent. HMM modelling of participants actions shows participants in the intervention group had a lower probability of transitioning to non cooperative states. Posterior latent state analysis also showed a  higher proportion of players best described by more cooperative latent states in the intervention condition compared to the control condition.
  
  
 
  

bibliography: "bib/cogIntervention.bib"
biblio-style: spphys
output:
  bookdown::pdf_document2:
   toc: false
---

```{r setupCoax, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE) 
knitr::opts_chunk$set(out.width = "\\textwidth")
```

```{r load-packages05, include = FALSE}
library(papaja)
library(kableExtra)
require(knitr)
require(citr)
require(bookdown)

# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded. 
library(tidyverse)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
library(depmixS4)
library(flextable)
library(gridExtra)
library(forcats)
library(ggsignif)


```

```{r analysis-preferences, include = FALSE}
# Seed for random number generation
set.seed(42)
options(tinytex.verbose = TRUE)
```

# Introduction

At the core of social interaction is figuring out the goals, intentions, and decision-making process of the interaction partner. This inference is however fraught with uncertainty, as we cannot reasonably observe these features without prior knowledge of the person. Absent a history of interaction, one needs to decide whether to take the risk of trusting others. The challenge of trust is that it is by construction a risky endeavour. For example, if we deem a person trustworthy, we might decide to take the risk of investing in the relationship hoping for a collaborative outcome. If we misplace our trust, this can come at a high cost to us. Not trusting others is also risky since opportunities for cooperation may be foregone.

<!-- and any substitution for trust, such as excessive suspicion, over-reliance on self and other maladaptive strategies are likely to add burden and costs to a person. -->

Evidence from the literature emphasises the importance of social trust in determining why some people fare better than others physically and mentally [@giordano_trust_2016 ; @meng_multilevel_2014]. It affects the health status of individuals through reinforcing social support networks, maintaining community norms and facilitating collective action. Research into the determinants of psychopathology has linked trust-based constructs to the emergence of mental health disorders. @fonagy_role_2014 identified epistemic trust, or the belief in the authenticity and personal relevance of interpersonally transmitted knowledge, as an important function of early attachment relationships. It allows the individual receiving social information to let go of their natural self-protective vigilance, which can become a pathological hypervigilance frequently observed after traumatic experiences and a key factor for the emergence of multiple mental health disorders [@fonagy_mentalizing_2017].

<!-- A well-established paradigm in the study of the emergence and maintenance of trust is the repeated trust game [@joyce_trust_1995]. In this game, one player takes the role of the "investor" and is provided with a fixed endowment at the start of each trial. They get to decide how much of their endowment to invest with the other player taking the role of the "trustee". The amount that is sent is tripled and the trustee gets to decide, in return, how much of the tripled amount to send back to the investor. If the investor sends a non-zero amount, they express trust in the other player for that round, as the amount they will receive back is uncertain. Assuming the trustee sends back more than the initial investment, they signal trustworthiness to the investor and both players make gains. This scenario would constitute a cooperative exchange and would be mutually beneficial. However, cooperation in this setting is prone to be broken through intentional or simply misinterpreted actions that can convey lack of trust or trustworthiness such as low investments and returns [@bendor_when_1991]. In order to repair a damaged cooperative equilibrium, players need to infer that their behaviour has violated social norms and offer amends through generous actions at potentially a high cost to them. @king-casas_rupture_2008 links the breakdown of cooperation in trustees with Borderline Personality Disorder to the absence or reduction of activation in brain regions associated with the perception of norm violations.  -->

Since a lack of epistemic trust is a risk factor for social dysfunction [@fonagy_mentalizing_2017], and given the importance of trust for building and maintaining strong social bonds, interventions to foster and strengthen trust-based cooperation would be highly beneficial to society. Such interventions would allow people to more easily repair broken relationships, and continue harvesting the benefits of cooperation even in the presence of accidental or intentional social norm violations.

<!-- Mechanism design, pioneered by @vickrey_counterspeculation_1961, is a field that studies incentive alignment and looks for ways to promote social welfare or revenue maximization, despite self-interest of the individual actors. In the context of social dilemmas, key mechanisms were explored with good effect to foster and maintain the cooperative outcome. @axelrod_evolutionary_1986 studied the emergence and stability of behavioral norms to regulate non-cooperative actions in social settings. He identifies a behavioral norm as a dominant behavioural strategy which is often punished by others when not adhered to. A meta-norm is the propensity to incur a cost in order to enforce a norm. @axelrod_evolutionary_1986 showed that when playing a social dilemma game, individuals have a strong incentive to enforce punishment of defectors lest they are in turn punished by others. This led to a decline of defection. Thus, meta-norms can be seen as a mechanism to promote and sustain cooperation in a population. In the context of the trust game, @charness_investment_2008 explored the effect a third party monitor can have on the amounts sent and received. This third-party's payoff is unaffected by the decisions made by the investor and trustee. However, the study allowed the third party to punish overly selfish trustees or reward Investors making a loss on the interaction. They found that the actions of both players were materially more cooperative in the presence of this third party. @fiedler_effect_2017 found that the introduction of a third party that monitors the investments and returns of the players led to more cooperative behavior, even when the third party had no ability to reward or punish the players.  -->

A well-established paradigm in the study of trust is the repeated trust game [@joyce_trust_1995]. To encourage the emergence and maintenance of trust in this setting, some studies focused on modifying the game mechanism [@charness_investment_2008; @fiedler_effect_2017]. Others chose to intervene directly on the participants. For example, @drazkowski_gratitude_2017 found that trust was increased when participants were asked to think about and write down five things that they were grateful for. @burnham_friend-or-foe_2000 found that trust was also increased when participants were primed with the concepts of friend and foe. 

Whilst these interventions show that it is possible to improve cooperative outcomes at the start of the game, they did not address how to repair a breakdown of trust that might occur due to intentional or accidental non-cooperative actions by the players. Indeed, cooperative play in the repeated trust game can easily break down when there is a transgressive behavior, such as a nil or very low investment by the investor after cooperation has been established, or a return of the trustee below the investment sent. Such ruptures of cooperation appear frequently when the trustee suffers from mental health disorders affecting the social domain such as Borderline Personality Disorder [@lieb_borderline_2004]. In theses situations, BPD trustees fail to engage in trust repairing behavior such as coaxing the investor through sending high return to signal trustworthiness, and this failure may be linked to a failure to perceive their low returns in the game as a violation of social norms [@king-casas_rupture_2008].

In devising potential interventions to repair trust, we can derive inspiration from the cognitive interventions championed by successful psychological therapies that aim to improve aspects of interpersonal dysfunction in BPD patients. Whilst there is no proven pharmacological therapy for BPD, some forms of psychotherapy such as Mentalisation Based Therapy [@allen_handbook_2006-1] and Dialectical Behavior Therapy [@linehan_cognitive-behavioral_1993], have been clinically validated as efficacious approaches to improve various dysfunctional behaviors in BPD patients, including those related to social interaction [@gunderson_borderline_2018]. However, these therapies suffer from a high variability in treatment responses. Determining which interventions are effective for particular patients has been very challenging [@rudge_mechanisms_2020; @arch_longitudinal_2012]. One promising approach is the study of how specific psychotherapeutic treatment components affect quantitative markers of behavior such as those inferred through computational modelling techniques [@huys_computational_2016; @reiter_neuro-cognitive_2021]. As such, using specific cognitive probes inspired by therapeutic interventions complemented by computational modelling of behavior in tasks, may allow us to uncover cognitive mechanisms targeted by common forms of psychotherapy. This may in turn form the basis for targeting of existing psychotherapies to different individuals.

In this study, we assess the effectiveness of a cognitive intervention aimed at repairing the potential breakdown of cooperation from a pre-programmed, one-off low investment sent by an computer investor. The intervention focuses on explaining the potential harm from reciprocating non-cooperative actions and suggesting a non-impulsive course of action to coax the investor back into cooperation. Participants are given the role of the trustee and are randomly assigned to either a control group or an intervention group. They play two instances of the repeated Trust Game facing what they believe are two different players. In between games, they either receive a cognitive intervention (intervention condition) or not (control condition, where participants are asked to solve anagrams). In reality, participants face the same computerised agent in both instances, which is programmed to play according to an HMM fitted to real players data. We explore whether the intervention has an effect on the behaviour of the trustee and whether the learning is transferred to a new repeated Prisoner's Dilemma game when facing a seemingly new player.


```{r dataLoad, include=FALSE }
d_finished <- readRDS("data/d_finished.RDS")
```


# Method

## Participants and Design

A total of 318 participants were recruited on the Prolific Academic platform (prolific.co). The mean age of participants was `r round(mean(as.numeric(d_finished$exitSurvey.age), na.rm=TRUE),1)` years. Participants were paid a fixed fee of £5 plus a bonus dependent on their performance. The experiment had a 2 (Condition: Intervention or Control) by 2 (Game : Pre or Post Intervention) design, with repeated measures on the first factor. Participants were randomly assigned to one of the two levels of the second factor.

## Procedure

```{r timeline, fig.cap = "A) Experiment overview. After playing 15 rounds of a repeated trust game (RTG) as trustee, participants were randomized to either receive the control or active intervention. They then played the second set of 15 rounds of RTG (again as trustee) to examine intervention effects, and 7 rounds of a repeated prisoner’s dilemma to examine generalization of intervention effects. Finally, participants answered questionnaires and were debriefed.", fig.align='center', out.width="80%"}

knitr::include_graphics("figures/timeline.png")

```


<!-- Figure \ref{fig:timeline} shows the timeline of the experiment. After reviewing an information sheet about the experiment, participants were informed that there would be three phases to go through, with them facing a different opponent in each phase. They would face the same player throughout the first phase, consisting of the "Investment Game" with several rounds. This was the moniker used for the repeated trust game, and a total of 15 rounds were played. Participants were then randomly assigned to either a control or intervention condition. -->

<!-- <!-- After reading instructions on how to play the trust game, players were told that they would be assigned the role of the trustee.  A comprehension quiz on the trust game followed the instructions. The first trust game then ensued:  Each round started with an investment stage where the investor decided how much to send to the trustee and that choice was revealed. Immediately afterwards, participants were presented with a two-dimensional field to indicate their emotional state on two dimensions: valence, from unpleasant to pleasant (on the horizontal axis) and arousal, from low arousal to high arousal (on the vertical axis). After selecting a point on the field, participants were asked to decide how much to send back to the investor using a slider ranging from sending back nothing to sending back the whole (tripled) investment. Following that choice, an outcome page summarised both players decisions and showed the total pay-off for each player and the round then concluded. At the end of the game, participants were asked to rate the player they were facing on 4 attributes using a scale from 1 to 10: Trustworthiness, friendliness, cooperativeness and selfishness. -->

<!-- In the second phase of the experiment, participants were informed they would be paired with a different player. This phase was similar to the first phase in terms of the game played (RTG) and the number of rounds. In all rounds of the RTG, participants gave feedback after seeing the investment received. This feedback was given though a two dimensional grid that was either related to their emotional state (degree of valence of arousal) in the Intervention group, or unrelated to the emotional state in the control group (speed of investor's response and magnitude of investment). At the end of each RTG, participants were asked to rate how cooperative, selfish, trustworthy and friendly they thought their interaction partner was. Details of the two dimensional grid and player ratings are given in the supplement. -->

<!-- After both trust games,  players were told they would be paired with a new player in the third phase of the experiment. This third phase consisted of 7 rounds of the prisoner's dilemma game, facing the new player. Throughout all games, players were explicitly told to aim to maximise the number of points as their bonus would depend on the score they accumulated throughout the experiment. The total number of rounds was not communicated to the participants in any of the games played. -->

<!-- After the three phases were completed, participants were asked to complete a series of questionnaires at the end of the experiment.  -->

<!-- <!-- These included: the PAI-BOR measuring Borderline traits [@morey_personality_1991], the DERS measuring Emotion Regulation ability [@gratz_multidimensional_2004] and the RFQ8 for mentalising abilities [@fonagy_development_2016].  -->

<!-- Finally, participants were asked a series of questions around how they played each phase. First, they were asked whether they thought they played differently in the second compared to the first phase of the RTG. Second, participants had to select whether they thought the opponents they faced were human or computer agents. Finally, we revealed to the participants that they faced the same computer agent throughout the RTG. We explained that any change in their perception of the opponent or any change in how the opponent played is due to their own change in behavior as the agent was simply reacting to their actions. Finally, we asked participants to reveal whether this experiment has taught them anything about how they should behave in social situations. -->

The experiment as shown in Figure \ref{fig:timeline} began with participants briefed there will be three phases, and that they would face a new opponent in each phase. Phase one was a 15 round Trust Game (RTG) in which participants had the role of the trustee, facing the same investor opponent. Participants were then assigned to either the control or intervention conditions. Phase two was similar to Phase one, with participants being told they faced a new player. In both phases, participants were asked for feedback in each round after seeing the investment. The nature of the feedback solicited varied by condition, either emotion-related (intervention) or unrelated (control). Participants rated their interaction partner on various attributes after each phase. More details on these attributes, nature of feedback and exact instructions are found in the supplement. Phase three involved 7 rounds of the repeated prisoner's dilemma game (RPD) with a third player. Participants were explicitly told to aim to maximise the number of points in all phases. The total number of rounds was not communicated to the participants in any of the games played.

Post-experiment, participants completed questionnaires related to mentalising abilities, emotion regulation and BPD traits (see details in supplement). They were then quizzed on their game-play, including whether they detected that all opponents were computer agents. The reveal explained that they were facing identical AI agents and that any perceived opponent changes were due to participants' own behavior.

## Interventions

The intervention was built on interventions from DBT skills training, asking patients to reflect on the consequences of actions taking in emotional states [@linehan_dbt_2015]. Specifically, participants were presented with a low investment and asked to indicate their response. They were then invited to consider what their ultimate aim in the game was and whether this response was most likely to achieve their aim. The intervention is detailed in the supplementary information.

In the control condition, participants were asked to solve five anagrams ("listen", "triangle", "deductions", "players", "care"). They provided their answers in a free-form text box. The time given to solve the anagrams was the same as that given to respond to questions in the intervention manipulation.

## Design of the AI agents in the RTG and RPD

```{r, include=FALSE}
Anti_social <-  c(0.1025436430408, 0.1221931236853, 0.1345215238995,
0.1368182252617, 0.1285592471751, 0.1116014322677, 0.0895041220882,
0.0663166721334, 0.0453950277118, 0.0287077419587, 0.0167723588011,
0.0090530028158, 0.0045143317507, 0.0020796744990, 0.0008851094702,
0.0003480141146, 0.0001264134789, 0.0000424213859, 0.0000131513231,
0.0000037665630, 0.0000009965755)

Neutral <- c(0.003393529, 0.006930874, 0.013053553, 0.022671228,
0.036310144, 0.053627606, 0.073039389, 0.091734929, 0.106248217,
0.113479701, 0.111769796, 0.101517390, 0.085028780, 0.065675083,
0.046778251, 0.030725245, 0.018610323, 0.010394861, 0.005354126,
0.002543094, 0.001113881)

Pro_social <- c(0.003162697, 0.001057162, 0.001410197, 0.001881016,
0.002508877, 0.003346113, 0.004462480, 0.005950950, 0.007935434,
0.010581067, 0.014107909, 0.018809194, 0.025075644, 0.033427845,
0.044559370, 0.059394206, 0.079163228, 0.105506029, 0.140606514,
0.187373417, 0.249680651)

investment <- seq(0:20) -1

response_probs <- as.data.frame(cbind(investment,Anti_social,Neutral,Pro_social)) %>% 
  rename("low-trust" = "Anti_social", "medium-trust"="Neutral", "high-trust" = "Pro_social") %>%
  pivot_longer(cols=c("low-trust","medium-trust","high-trust"),
                    names_to='Investor_state',
                    values_to='probability') %>% 
   mutate(across(Investor_state, factor, levels=c("low-trust","medium-trust","high-trust")))
```

```{r, include=FALSE}

plotinvHMM <- ggplot(response_probs,                            
       aes(x = investment,
           y = probability,
           fill = Investor_state)) +
  geom_bar(stat = "identity",
           position = "dodge") + 
  labs(fill='Latent investor state') + 
  theme_bw() + 
  theme(legend.position = "bottom")
  

```

```{r, include=FALSE}

unhappy_pars <- rbind(c(3.5435248 , 0.0592584), c(0.1611541, 0.4675468), c(0,0)) 
neutral_pars <- rbind(c(0.8846036, - 0.4394031), c(2.4214322, - 0.0710711), c(0,0))
happy_pars <- rbind(c(-2.004988 ,- 0.151186), c(-1.2976976 , - 0.1357088), c(0,0))

pars_inv <- list(unhappy_pars, neutral_pars, happy_pars)

plot_HMM_transitions <- function(ns, pars_mat) {

  trans_prob <- data.frame(
    from = rep(1:ns, each=100*ns),
    to = rep(1:ns, each=100),
    ret = seq(-20,60,length=100),
    probs = 0
  )
  
  
  y <- matrix(0.0,ncol=ns, nrow=100)
  
  for(from in 1:ns) {
  pars <- matrix(pars_mat[[from]], ncol=2)
  # print(pars)
  
    for(to in 1:ns) {
        x <- trans_prob[trans_prob$from == from & trans_prob$to == to,"ret"]
        y[,to] <- exp(pars[to,1] + pars[to,2]*x)
    }
    y <- y/rowSums(y)

    
    for(to in 1:ns) {
      trans_prob$probs[trans_prob$from == from & trans_prob$to == to] <- y[,to]
    }
  }
  
  df <- as.data.frame(trans_prob) %>% 
    mutate(from = recode(from, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust"),
           to = recode(to, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust") ) %>% 
    mutate(across(from, factor, levels=c("low-trust","medium-trust","high-trust"))) %>% 
    mutate(across(to, factor, levels=c("low-trust","medium-trust","high-trust")))
                                    
  
  ggplot(df,aes(x=ret,y=probs, colour = as.factor(to))) + geom_line() + facet_wrap(~from) + ylim(c(0,1)) +  labs(x = "Investor's Net Return", y = "Transition probability", color='State Transitioned to') + 
    theme_bw() + theme(legend.position = "bottom")


}

```

```{r, include=FALSE}

plotInvTran <- plot_HMM_transitions(3, pars_inv) 

```


```{r HMMPanels, fig.cap="A: Distribution of investments by the artificial investor agent conditional on its latent state as estimated by a three state hidden Markov model fitted to human dyadic play dataset. B: Transition function for the HMM investor conditional on its current state and the net return from the previous round of play.", fig.align="center"}

ggpubr::ggarrange(plotinvHMM , plotInvTran, nrow=2, ncol=1, labels = c("A", "B"), common.legend = TRUE, legend = "bottom")

```
The role of the investor was in reality played by an adaptive artificial agent whose strategy was modelled on the behaviour of human participants taking the role of the investor in the RTG. Using data from human dyadic interaction in the 10 round trust game, we estimate a Hidden Markov Model (HMM) to characterise the investor's behavior as emanating from a small number of latent states [@rabiner_hmm_1989]. In this instance, for both iterations of the repeated trust game, the HMM used was identical: it had three states that can be described as "low-trust", "medium-trust" and "high-trust". Each latent state was associated with a distribution over all possible investor actions (from 0 to 20 investment) that reflected the amount of trust, as presented in Figure \ref{fig:HMMPanels}.A. Transition probabilities between these latent states were modelled as a function of the net return in the previous round conditional on the investor's state as shown in Figure \ref{fig:HMMPanels}.B.

<!-- In order to probe efforts to repair trust, we introduced rounds where the investor deviated from the policy provided by the HMM, and chose to send a low investment in the Trust Game, or chose the non-cooperative action in the Prisoner's Dilemma. In the trust games, we programmed the HMM agent to send a very low investment (2 out of 20) to the trustee on specific rounds (round 12 pre-intervention and 13 post-intervention). For the repeated Prisoner's Dilemma game, we programmed the agent to choose the non-cooperative action on round 4. After each "defection" round, the agents were programmed to proceed their policy from before that round, effectively ignoring the participants' response to their defection. For instance, the HMM investor would send an investment in the post defection round that was consistent with the outcome of the round immediately prior to that round. For the RPD, the agent would continue to play tit-for-tat, but also ignoring what happened in the defection round, and basing its action on mirroring what the other player did in the round immediately prior to the defection round. This ignorance of reactions to the defection rounds was chosen to reflect an accidental defection, with the Investor being open to repair subsequent interaction.  -->

In order to probe efforts to repair trust, we simulated trust breaches in both Trust Games and the Prisoner's Dilemma. The AI was programmed to break trust on specific rounds (12 pre-intervention, 13 post-intervention in the Trust Game; round 4 in Prisoner's Dilemma). After these "defection" rounds, the AI returned to its previous strategy, disregarding the participant's response to the breach. This simulated an accidental defection and a readiness to repair the interaction, providing insights into trust repair dynamics.

<!-- ## Computational analysis of trustee returns -->

<!-- In order to characterise the effect of the intervention on the trustees strategy, we fit a Hidden Markov Model to the percentage returns of the trustees for the RTG data. The model allows for switching between latent trustee states over time. Hidden Markov models assume that an observable trustee return at time $t$ depends on a latent trustee state at time $t$. It is assumed that the latent state at time $t$ depends on the latent state at the previous time $t-1$. The model is specified by the state-conditional action distributions (these are provided by the likelihood of the fitted models), an initial state distribution (the distribution over the strategies at the initial round), and the state-transition probabilities (probability of switching from one state/strategy to another). Initial state probabilities and the transition probabilities were estimated with the depmixS4 package [@visser_depmixs4_2021]. -->

## Analysis of participants returns in the RTG

To explore whether participants behaved differently after the intervention compared to the control group over all rounds, we estimate a linear-mixed effects model as implemented in the R package "afex" [@singmann_afex_2022], with fixed effects for Condition (intervention or control), Game-number (pre- or post-intervention) and Investment, as well as interactions between Condition and both Investment and Game-number, and participant-wise random intercepts and random slopes for Game-number. More complex models with additional random effects provided could not be estimated reliably. For the $F$-tests, we used the Kenward-Roger approximation to the degrees of freedom, as implemented in the R package "afex". We Z-transform the Investment variable as centering is beneficial to interpreting the main effects more easily in the presence of interactions.

To model participants returns in the RTG across games and conditions, we fit various hidden Markov models to participants returns using the depmixS4 package [@visser_depmixs4_2021]. The transition between latent states is assumed to depend on the investment received and a dummy variable to characterise the group that the participant belongs to. Details on how the models are constructed as well as the various contrast codes used for the dummy variables are found in the supplement. We fit models with different numbers of hidden states, and use the Bayesian Information Criterion [@schwarz_estimating_1978-1] to select the best model.

# Behavioral results

<!-- Our investment levels are clearly comparable. Our random matching condition is the most directly comparable to Berg et al., (1995) and Charness et al., (2008), both of whom used random matching. Our investment averages 4.97 out of 10 in the individual feedback condition, which falls right in between the investment level of 5.16 documented by Berg et al., (1995) and the 3.73 documented by Charness et al., (2008). The amount returned in the individual feedback condition with random matching is 5.61, which is slightly higher than the amounts returned in Berg et al., (1995) of 3.73 and Charness et al., (2008) of 4.65. The 19% return rate is comparable to results in similar designs. In an almost identical design, Fiedler et al., (2011) report a 17% return rate by responders. This is similar to our finding.  -->

```{r dataClean, include=FALSE}
# Filter only trust rounds and create % returns and investments 

avg_ret_df <- d_finished %>%
  dplyr::select(id, condition.f,roundType,investment,returns,roundNum,gameNum.f,BPD_trait,PBOR_score,DERS_score,RFQ_c,RFQ_u) %>% 
  mutate( condition.f = fct_recode(condition.f, "intervention" = "coaxing"))%>%
  filter(roundType=="trust",!is.na(roundNum)) %>% 
  mutate(roundNum = as.numeric(as.character(roundNum))) %>%
  mutate(inv_scaled = scale(investment)) %>% 
  mutate(inv_pct = investment/20, ret_pct = returns/(3*investment), ret_pct_0 = ifelse(investment==0,0,returns/(3*investment)))  %>% 
  # Creating Quartiles of % returns by participant over BOTH TRUST GAMES
  group_by(id) %>% 
  mutate(mean_pct_ret = mean(ret_pct), mean_abs_ret = mean(returns), mean_inv = mean(investment)) %>%
  ungroup() %>% 
  mutate(Quart_pct_ret = ntile(mean_pct_ret,4),
         Quart_abs_ret = ntile(mean_abs_ret,4),
         Quart_inv     = ntile(mean_inv, 4)) 

# %>%
#   filter(complete.cases(.))   # <- one player had NA in one round as a return, so we exclude him from analysis. 


# Number of people left for analysis. 
nrow(avg_ret_df %>% filter(condition.f == "intervention"))/30
nrow(avg_ret_df %>% filter(condition.f == "control"))/30

# average investment for first 10 rounds pre intervention
avg_pct <- avg_ret_df %>% filter(roundNum < 11 , gameNum.f == "pre") %>% summarise(avg_inv = mean(inv_pct), avg_ret = mean(ret_pct, na.rm=TRUE))
```

Average investments and returns prior to the defection round (Figure \ref{fig:gamesPlot}) were within the range of reported investments (40-60% of endowment) and returns (35-50% of total yield) in the literature [@charness_investment_2008; @fiedler_social_2011]. Estimated marginal means of percentage returns from fitting the mixed effects model specified in the methods section, as well as the distribution of the returns for participants across all trials are presented in Figure \ref{fig:violinPanels}.A.

<!-- Investments averaged `r round(avg_pct$avg_inv,3)*100` $\%$ of endowment which is less than the $63.2\%$ documented by @fiedler_social_2011 and higher than the $37.3%$ documented by @charness_investment_2008, although the latter used repeated one shot games with random matching. Returns averaged `r round(avg_pct$avg_ret,3)*100` $\%$  of the total yield (3x investment sent), which is higher than the $35\%$ found in the same setting in @fiedler_social_2011.  -->

```{r gamesPlot, echo=FALSE, fig.cap="Average and standard errors of the trustee's return as a percentage of the multiplied investment received for each round and for both conditions. The red line shows the returns pre-manipulation and the blue line post-manipulation.We note a different reaction to the pre-programmed one-off low investment between the two conditions: Whilst there is a dip in returns pre-manipulation for both conditions,  post manipulation we see higher returns in the intervention condition compared to the dip in returns seen in the control condition in the right panel",fig.align="center", fig.width=6, fig.height = 4}

# colors <- c("investment" = "blue", "returns" = "red")
# 
# ggplot(avg_ret_df,aes(x=as.factor(roundNum),group = 1)) +
#   stat_summary(fun = "mean", geom = "line", aes(y=returns, color ="returns")) +
#   stat_summary(fun.data = "mean_se", geom = "errorbar", alpha =0.3, width = 0.2, aes(y=returns) ) +
#   stat_summary(fun = "mean", geom = "line", alpha =0.4,aes(y=investment, color = "investment")) +
#   stat_summary(fun.data = "mean_se", geom = "errorbar", alpha =0.3, width = 0.2, aes(y=investment) ) +
#   facet_wrap(~condition.f*gameNum.f) +
#   labs(x = "Round",
#        y = "Investment / Return",
#        color = "Legend") +
#   scale_color_manual(values = colors) +
#   theme_bw() +
#   theme(legend.position = "bottom") 

# Alternative chart with pre vs post percentage returns in one panel as suggested by QH.

ggplot(avg_ret_df ,aes(x=as.factor(roundNum),group=gameNum.f, color = gameNum.f)) +
  stat_summary(fun = "mean", geom = "line", aes(y=ret_pct)) +
  stat_summary(fun.data = "mean_se", geom = "errorbar", alpha =0.3, width = 0.2, aes(y=ret_pct) )+
  labs(x = "Round",
       y = "Percentage Return",
       color = "Game") +
  # ylab("Percentage Return") +
  # xlab("Round") +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(~condition.f)

```

```{r, include=FALSE, cache=TRUE}

mod_returns_pct <- mixed( ret_pct ~ gameNum.f*condition.f*inv_scaled+ (1 + gameNum.f| id), avg_ret_df, REML= TRUE)
anova(mod_returns_pct)
summary(mod_returns_pct)


prepost_bycond <- pairs(emmeans::emmeans(mod_returns_pct, c("gameNum.f"), by = "condition.f", pbkrtest.limit = 9400))

cond_effect <- pairs(emmeans::emmeans(mod_returns_pct, c("condition.f"), by="gameNum.f"))
```

```{r, include=FALSE}
pctRet_all <- afex::afex_plot(mod_returns_pct, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
            mapping = c("linetype", "shape", "fill"),
            data_geom = geom_violin, 
            data_arg = list(width = 0.5),
            factor_levels = list(gameNum.f = c("Pre", "Post")), legend_title = "Condition") + 
  theme_bw() + 
  labs(y = "Percentage Return", x = "Game") + 
  ggtitle("All rounds percentage returns") + 
  theme(plot.title = element_text(size = 10)) +
  theme(legend.position = "bottom") 
            
```

<!-- If the intervention has an effect, then we should expect a higher increase in returns after the intervention compared to the control condition, which should be evident from an interaction between Condition (intervention vs control) and Game-number (pre- vs post-manipulation). Therefore, the variable of interest here is the interaction between Condition and Game-number.  -->

We find an interaction effect between Condition (intervention vs. control) and Game-number (pre- vs. post-manipulation) ($F(1,314.2) = 26.9, p < 0.001$). Post-hoc tests show that there was an increase in the percentage returned in the intervention group (`r papaja::apa_print(prepost_bycond)$statistic$Intervention_Pre_post`) but not in the control group (`r papaja::apa_print(prepost_bycond)$statistic$Control_Pre_post`). We also found a significant main effect for Condition ( $F(1,315.31) = 9.52, p = 0.002)$), such that the intervention group had higher percentage returns than the control group. There was also a significant main effect of Investment( $F(1,9208) = 373.6, p < 0.001$) such that higher investments were associated with higher percentage returns.

There was an interaction effect of Investment by Condition ($F(1,9207) =45.38, p < 0.001$), such that the positive effect of investment on percentage returns was greater in the control group than in the intervention group. This suggests that the higher returns we see in the intervention group are not simply due to higher investments. Finally, we find a three way interaction between Game-number, Condition and Investment ($F(1,8988)= 24.6, p < 0.001$), showing that the differentiated effect of the investment on the proportion returned by condition is itself moderated by the Game-number.

```{r, include=FALSE, cache=TRUE}
mod_invs <- mixed( investment ~ gameNum.f*condition.f  + (1 + gameNum.f| id), avg_ret_df )
summary(mod_invs)
anova(mod_invs)

# pairs(emmeans::emmeans(mod_invs, c("condition.f"), by = "gameNum.f" ))
# 
# pairs(emmeans::emmeans(mod_invs,c("gameNum.f") , by = c("condition.f")))
# 
# pairs(emmeans::emmeans(mod_invs, c("gameNum.f")))
# pairs(emmeans::emmeans(mod_invs, c("condition.f")))

 
```

```{r, include=FALSE}

inv_all <- afex_plot(mod_invs, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
            mapping = c("linetype", "shape", "fill"),
            data_geom = geom_violin,
            data_arg = list(width = 0.5),
            factor_levels = list(gameNum.f = c("Pre", "Post")), 
            legend_title = "Condition") + 
  theme_bw() + 
  ggtitle("All rounds investments") +
  labs(y = "HMM Investment", x = "Game") + 
  theme(plot.title = element_text(size = 10)) +
  theme(legend.position = "bottom")
          

```

The HMM agent exhibited a differentiated behavior between games and conditions. When examining the HMM agent investments, we fit a linear-mixed effects model, with fixed effects for Condition (intervention or control), Game-number (pre or post intervention), as well as interaction between Condition and Game-number, and participant-wise random intercepts and random slopes for Game-number. We find a main effect for both Condition ($F(1,317) = 8.7, p = 0.003$) and Game-number($F(1,317) = 8.3, p = 0.004$). As can be seen in Figure \ref{fig:violinPanels}.D, investment was higher in the intervention compared to the control condition across games ($p=0.003$). Across conditions, investment was also higher in the second game compared to the first ($p=0.003$).

In summary, participants in the control group sent back **lower** percentage returns in the second game (`r apa_print(prepost_bycond)$full_result$Control_Pre_post`) despite the HMM investor sending, on average higher investments. Those in the intervention group returned **higher** percentage returns in the second game (`r apa_print(prepost_bycond)$full_result$Intervention_Pre_post`), with the investor also sending higher investments. These higher returns in the intervention group compared to the control group were not purely driven by reciprocity towards higher investments since we find this interaction effect whilst controlling for investments in our model of participants returns.

## Looking at pre- and post-defection trials only

```{r, include=FALSE, cache=TRUE}
# ALL ROUNDS BEFORE DEFECTION TRIAL
pre_int_data <- avg_ret_df %>% filter(roundType=="trust",!is.na(gameNum.f),(roundNum < 12 & gameNum.f =="pre")| (roundNum < 13 & gameNum.f =="post"))

mod_returns_pre <- mixed( ret_pct ~ gameNum.f*condition.f*inv_scaled+ (1 + gameNum.f| id), pre_int_data, REML= TRUE)
anova(mod_returns_pre)
summary(mod_returns_pre)


pairs_pre_int <- pairs(emmeans::emmeans(mod_returns_pre, c("gameNum.f"), by = "condition.f", pbkrtest.limit = 9400, reverse=TRUE))

```

We restrict our analysis to the rounds prior to the pre-programmed defection (rounds 1 to 11 pre-manipulation and 1 to 12 post-manipulation) and fit the same linear mixed effects model to percentage returns as the one for the full data. Estimated marginal means of percentage returns as well as the distribution of the returns for participants across all trials are presented in Figure \ref{fig:violinPanels}.B. We do find an interaction effect between Condition and Game number ($F(1,317.99) = 17.1, p < 0.001$). This was due to an increase in the percentage returned pre low-investment trial in the intervention condition (`r apa_print(pairs_pre_int)$full_result$Intervention_Pre_post`) but not in the control group (`r apa_print(pairs_pre_int)$full_result$Control_Pre_post`). This indicates that participants were sending back higher returns in the intervention condition but not in the control condition even before the defection trial.

```{r, include=F}
pctRet_pre <- afex_plot(mod_returns_pre, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
            mapping = c("linetype", "shape", "fill"),
            data_geom = geom_violin,
            data_arg = list(width = 0.5),
            factor_levels = list(gameNum.f = c("Pre", "Post")), 
            legend_title = "Condition") + 
  theme_bw() + 
  labs(y = "Percentage Return", x = "Game") + 
  ggtitle("Pre defection trials percentage returns")+
  theme(plot.title = element_text(size = 10)) +
  theme(legend.position = "bottom")
```

The interventions focused on repairing cooperation in the wake of a transgressive action by the investor. To assess the effect of the intervention, we can therefore consider the percentage return after the "transgression" trials. We fit the same linear mixed effects model to percentage returns as the one for the full data while restricting the data to rounds 12 to 15 in the first game, and 13 to 15 in the second game. These trials represent all trials after the pre-programmed defection of the investor (low investment of $2$) until the end of the game (round 15).

```{r, include =FALSE}

# Defection trial only 
coax_data <- avg_ret_df %>%  filter(roundType=="trust",!is.na(gameNum.f),(roundNum == "12" & gameNum.f =="pre")| (roundNum == "13" & gameNum.f =="post"))

coax_data %>% group_by(gameNum.f, condition.f) %>% summarise(avg_inv = mean(investment),avg_return = mean(returns))


# ALL ROUNDS AFTER DEFECTION TRIAL (INCLUSIVE)
post_coax_data <- avg_ret_df %>% filter(roundType=="trust",!is.na(gameNum.f),(roundNum >= 12 & gameNum.f =="pre")| (roundNum >= 13 & gameNum.f =="post"))

post_coax_data %>% group_by(gameNum.f, condition.f) %>% summarise(avg_inv = mean(investment),avg_return = mean(returns))


```

```{r, include=FALSE, cache=TRUE}

mod_postcoax_trust <- mixed(ret_pct ~ gameNum.f*condition.f*inv_scaled  + ( 1 + gameNum.f|id), post_coax_data)
anova(mod_postcoax_trust)


postcoax_bygame <- emmeans::emmeans(mod_postcoax_trust, ~gameNum.f, pbkrtest.limit = 9400)
postcoax_bycond <- emmeans::emmeans(mod_postcoax_trust, ~condition.f, pbkrtest.limit = 9400)

postcoax_interaction <- emmeans::emmeans(mod_postcoax_trust, c("gameNum.f"), by = "condition.f", pbkrtest.limit = 9400)
postcoax_interaction

pairs(emmeans::emmeans(mod_postcoax_trust, c("gameNum.f"), by = "condition.f"))
```

```{r, include=FALSE}
pctRet_post <- afex_plot(mod_postcoax_trust, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
            mapping = c("linetype", "shape", "fill"),
            data_geom = geom_violin,
            data_arg = list(width = 0.5),
            factor_levels = list(gameNum.f = c("Pre", "Post")), 
            legend_title = "Condition") + 
  theme_bw() + 
  labs(y = "Percentage Return", x = "Game") + 
  ggtitle("Post defection trials percentage returns")+
  theme(plot.title = element_text(size = 10)) +
  theme(legend.position = "bottom")
```

```{r violinPanels, fig.cap="A: Marginal means and distributions of percentage trustee returns over all rounds, shown across participants by Game number and Condition. B: Marginal means and distributions of percentage trustee returns across all participants for pre-defection trials only, by Game number and Condition. C: Marginal means and distributions of percentage trustee returns across all participants for post-defection trials only, by Game number and Condition. D: Marginal means and distributions of investments over all rounds for HMM agents playing the role of the investor, by Game number and Condition", fig.align="center", fig.width=6, fig.height = 6}

ggpubr::ggarrange(pctRet_all, pctRet_pre, pctRet_post, inv_all, nrow=2, ncol=2, labels = c("A", "B", "C", "D"), common.legend = TRUE, legend = "bottom")
```

Figure \ref{fig:violinPanels}.C shows the marginal means of trustee returns and their distribution by Game-number and Condition. There was a significant interaction between Game-number and Condition. Participants sent back lower returns between games in the control condition (`r papaja::apa_print(pairs(postcoax_interaction, by = "condition.f", reverse=FALSE))$full_result$Control_Pre_post`), but no such difference in the intervention condition (`r papaja::apa_print(pairs(postcoax_interaction, by = "condition.f", reverse=FALSE))$full_result$Intervention_Pre_post`).

<!-- We found a main effect of Condition with returns on the intervention group higher than returns in the control group (`r apa_print(pairs(postcoax_bycond))$full_result`). We also found a main effect of Game-number, with returns higher for the pre-manipulation game compared to the post-manipulation game  (`r apa_print(pairs(postcoax_bygame))$full_result`). -->

## Emotion self-reports

```{r, include=TRUE}

# Get Emotions on x axis per round (valence)
emo.x <- d_finished %>% 
  mutate( condition.f = fct_recode(condition.f, "intervention" = "coaxing")) %>% 
  dplyr::select(id,roundType,condition.f,contains("emotionGrid")) %>% 
  dplyr::filter(roundType=="trust") %>% dplyr::select (-contains(".y") ) %>% pivot_longer(cols=contains(".x"), names_to = c("gameNumber","roundNum"), names_pattern ="return_trust_emotionGrid_(.*)_(.*)[.]x", values_to = "emo_coord_x") %>%
  distinct()  


#Get emotions on y axis (arousal)
emo.y <- d_finished %>%
  mutate( condition.f = fct_recode(condition.f, "intervention" = "coaxing")) %>%
  dplyr::select(id,roundType,condition.f,contains("emotionGrid")) %>% 
  dplyr::filter(roundType=="trust") %>% dplyr::select(-contains(".x") ) %>% pivot_longer(cols=contains(".y"), names_to = c("gameNumber","roundNum"), names_pattern ="return_trust_emotionGrid_(.*)_(.*)[.]y", values_to = "emo_coord_y") %>%
  distinct()  


# put emotions in one dataframe
full_emo <- full_join(emo.x,emo.y, by=c("id", "gameNumber","roundNum","roundType", "condition.f"))  %>% 
  mutate(roundNum=as.numeric(as.character(roundNum))) %>% 
  mutate(gameNum.f = factor(gameNumber,labels = c("pre","post"),levels=c("1","2"))) %>% 
  dplyr::select(-c("roundType","gameNumber")) %>% 
  # group_by(condition.f) %>% 
  mutate(emo_scaled_x = scale(emo_coord_x), emo_scaled_y= -scale(emo_coord_y))    # <--- SCALING and reversing Y coordinates (0,0 is top left)
  

#merge with returns dataframe
full_dat <- full_join(avg_ret_df, full_emo, by = c("id","condition.f","gameNum.f","roundNum" )) %>% filter(complete.cases(.))
#nrow(full_dat)

datCoax <- full_dat %>% filter(condition.f=="intervention")
datCtrl <- full_dat %>% filter(condition.f=="control")

```

```{r emoPlotCoax, fig.cap="Self-reported emotion valence and arousal as well as investment z-scores for each round of the repeated Trust Game averaged across participants in the intervention condition only.",fig.align="center", fig.width=6, fig.height = 4}

# colors <- c("Investment" = "blue", "Valence" = "red", "Arousal" = "green")
# 
# ggplot(datCoax,aes(x=roundNum)) + 
#   stat_summary(fun = "mean", geom = "line",group =1, aes(y=emo_scaled_x), color = "red") + 
#   stat_summary(fun = "mean", geom = "line",group =1, aes(y=emo_scaled_y), color = "green") + 
#   stat_summary(fun = "mean", geom = "line",group =1, aes(y=scale(investment)), color = "blue") + 
#   scale_color_manual(name = " ",values = colors, labels = c("Investment", "Emotion valence", "Emotion arousal")) +
#   labs(x = "Round", y="Series Z-score") +
#   geom_hline(yintercept = 0, linetype="dotted", color = "grey", linewidth=1.5) +
#   facet_grid(cols = vars(gameNum.f)) +
#   theme_bw() + 
#   theme(legend.position = "bottom")
# 


# # BOTH IN ONE GRAPH 
# library(ggplot2)
# 
# # Define the colors in alphabetical order
# colors <- c("Arousal" = "green", "Investment" = "blue", "Valence" = "red")
# 
# # Plot 'pre'
# p <- ggplot(datCoax[datCoax$gameNum.f == 'pre', ], aes(x=roundNum)) + 
#   stat_summary(fun = "mean", geom = "line", group =1, aes(y=emo_scaled_x, color = "Valence", linetype = "pre")) + 
#   stat_summary(fun = "mean", geom = "line", group =1, aes(y=emo_scaled_y, color = "Arousal", linetype = "pre")) + 
#   stat_summary(fun = "mean", geom = "line", group =1, aes(y=inv_scaled, color = "Investment", linetype = "pre")) +
# # Plot 'post'
#   stat_summary(data = datCoax[datCoax$gameNum.f == 'post', ], fun = "mean", geom = "line", group =1, aes(x=roundNum, y=emo_scaled_x, color = "Valence", linetype = "post")) + 
#   stat_summary(data = datCoax[datCoax$gameNum.f == 'post', ], fun = "mean", geom = "line", group =1, aes(x=roundNum, y=emo_scaled_y, color = "Arousal", linetype = "post")) + 
#   stat_summary(data = datCoax[datCoax$gameNum.f == 'post', ], fun = "mean", geom = "line", group =1, aes(x=roundNum, y=inv_scaled, color = "Investment", linetype = "post")) +
#   labs(x = "Round", y="Series Z-score") +
#   geom_hline(yintercept = 0, linetype="dotted", color = "grey", linewidth=1.5) +
#   scale_color_manual(name = " ", values = colors, labels = c("Emotion arousal", "Investment", "Emotion valence")) +
#   scale_linetype_manual(values = c("pre" = "dotted", "post" = "solid"), labels = c("Pre", "Post")) +
#   theme_bw() + 
#   theme(legend.position = "bottom")
# 
# # Print the plot
# print(p)

#################### two panels for before and after defection 
library(ggplot2)

# Define the colors in alphabetical order
colors <- c("Arousal" = "green", "Investment" = "blue", "Valence" = "red")

# Create a new variable to categorize the rounds
datCoax$roundGroup <- ifelse(datCoax$roundNum <= 10, "Rounds 1-10", "Rounds 11-15")

# Plot 'pre'
p <- ggplot(datCoax[datCoax$gameNum.f == 'pre', ], aes(x=roundNum)) + 
  stat_summary(fun = "mean", geom = "line", group =1, aes(y=emo_scaled_x, color = "Valence", linetype = "a_Pre")) + 
  stat_summary(fun = "mean", geom = "line", group =1, aes(y=emo_scaled_y, color = "Arousal", linetype = "a_Pre")) + 
  stat_summary(fun = "mean", geom = "line", group =1, aes(y=inv_scaled, color = "Investment", linetype = "a_Pre")) +
# Plot 'post'
  stat_summary(data = datCoax[datCoax$gameNum.f == 'post', ], fun = "mean", geom = "line", group =1, aes(x=roundNum, y=emo_scaled_x, color = "Valence", linetype = "b_Post")) + 
  stat_summary(data = datCoax[datCoax$gameNum.f == 'post', ], fun = "mean", geom = "line", group =1, aes(x=roundNum, y=emo_scaled_y, color = "Arousal", linetype = "b_Post")) + 
  stat_summary(data = datCoax[datCoax$gameNum.f == 'post', ], fun = "mean", geom = "line", group =1, aes(x=roundNum, y=inv_scaled, color = "Investment", linetype = "b_Post")) +
  labs(x = "Round", y="Series Z-score") +
  geom_hline(yintercept = 0, linetype="dotted", color = "grey", linewidth=1.5) +
  scale_color_manual(name = " ", values = colors, labels = c("Emotion arousal", "Investment", "Emotion valence")) +
  scale_linetype_manual(values = c("a_Pre" = "dotted", "b_Post" = "solid"), labels = c("Pre", "Post")) +
  scale_x_continuous(breaks = 1:max(datCoax$roundNum)) +
  facet_wrap(~roundGroup, scales = "free_x") +
  theme_bw() + 
  theme(legend.position = "bottom")

# Print the plot
print(p)



```

A key aspect of effective interventions is the emotional change. We examined emotion self-reports through fitting a linear mixed effects model to both emotion dimensions (valence and arousal) for the intervention group to explore whether the intervention changed the emotional appraisal of the investment, with fixed effects for Game-number (pre or post intervention) and Investment, as well as interaction between Investment and Game-number, with participant-wide random intercepts and random slopes for Game-number.

Higher investments were associated with more positive emotions ($F(1,4664) = 2902, p < 0.001$), and higher arousal ($F(1,4668.4) = 1919, p < 0.001$), while positive emotions declined between the two games ($\Delta M = 0.11, 95\% \ CI = [0.05, 0.18], t(\infty) = 3.72, p < .001$). However, there was no evidence that emotional reaction to the investment was lessened after the intervention. This means that participants in the intervention condition returned higher amounts post-intervention despite the emotional reaction to the lower investment being largely unchanged.

<!-- Figure \ref{fig:emoPlotCoax} shows the average, across participants *in the intervention condition*, of emotion valence, the degree of arousal as well as the HMM's investment z-scores. We find a significant positive correlation between the two emotion axis ($r=0.52, p < 0.001$) as well as between valence and Investment ($r=0.47, p < 0.001$), and arousal and Investment ($r=0.50, p < 0.001$). -->

```{r, include=FALSE}

mod_emo_x <- mixed( emo_scaled_x ~ gameNum.f*scale(investment) + (1 + gameNum.f| id), datCoax )
summary(mod_emo_x)
anova(mod_emo_x)

modVal <- emmeans::emmeans(mod_emo_x, ~gameNum.f)
pairs(modVal)


mod_emo_y <- mixed( emo_scaled_y ~ gameNum.f*scale(investment) + (1 + gameNum.f| id), datCoax )
summary(mod_emo_y)
anova(mod_emo_y)

modArousal <- emmeans::emmeans(mod_emo_y, ~gameNum.f)
pairs(modArousal)

# afex_plot(mod_emo_x, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
#             data_geom = geom_violin, 
#             data_arg = list(width = 0.5))
# 

# library(GGally)
# ggpairs(datCoax %>% dplyr::select(emo_scaled_x,emo_scaled_y,inv_scaled))

cor(datCoax %>% dplyr::select(emo_scaled_x,emo_scaled_y,investment))
cor.test(datCoax$emo_scaled_x, datCoax$emo_scaled_y)
```

<!-- For emotional valence, we find a main effect of Investment ($F(1,4664) = 2902, p < 0.001$), with higher investment leading to more positive emotions. We also find a main effect for Game-number, due to the reported emotional valence of investments decreasing significantly after the intervention ($\Delta M = 0.11, 95\% \ CI = [0.05, 0.18], t(\infty) = 3.72, p < .001$). For emotional arousal, fitting a similar mixed effects model we find only a main effect of Investment  ($F(1,4668.4) = 1919, p < 0.001$) with higher investment leading to higher arousal. These effects are still present if we exclude the defection trial. We did not find any interaction between emotional valence or arousal and the investment, which would indicate a moderating effect of the intervention on the reaction to investments. -->

## Player rating

<!-- One possible reason of the differentiated returns post manipulation between conditions is that participants had a different perception of the investor, post-manipulation, in the control condition compared to the control condition. To explore this possibility, we can determine whether participants rated their artificial opponents differently between conditions (intervention vs control) and games (pre- vs post-intervention) using the players ratings they had to submit at the end of each game. To analyse the participants rating of their opponents, we used a linear mixed-effects model for each of the four players ratings (cooperativeness, selfishness, trustworthiness, friendliness) with fixed effects for Game-number (pre or post manipulation) and Condition (intervention or control), as well as interaction between condition and Game-number, and participant-wise random intercepts.  -->

```{r, include=FALSE}

# Pivot longer ratings on each attribute 
df_coop <- d_finished %>% dplyr::select(id,condition.f,contains("cooperative")) %>%  
  pivot_longer(cols=contains("cooperative"), names_to = c("gameNumber"), names_pattern ="rating_cooperative_(.*)", values_to = "rating_coop") %>% distinct()

df_selfish <- d_finished %>% dplyr::select(id,condition.f,contains("selfish")) %>% 
  pivot_longer(cols=contains("selfish"), names_to = c("gameNumber"), names_pattern ="rating_selfish_(.*)", values_to = "rating_selfish") %>% distinct

df_trustworthy <- d_finished %>% dplyr::select(id,condition.f,contains("trustworthy")) %>% 
  pivot_longer(cols=contains("trustworthy"), names_to = c("gameNumber"), names_pattern ="rating_trustworthy_(.*)", values_to = "rating_trustworthy") %>% distinct() 

df_friendly  <-  d_finished %>% dplyr::select(id,condition.f,contains("friendly")) %>% 
  pivot_longer(cols=contains("friendly"), names_to = c("gameNumber"), names_pattern ="rating_friendly_(.*)", values_to = "rating_friendly") %>%  distinct()  

#merge all data frames together
datRatings <- list(df_coop, df_selfish,df_trustworthy, df_friendly) %>% 
              reduce(full_join, by=c('id','gameNumber','condition.f') ) %>% 
              mutate(gameNum.f = factor(gameNumber,labels = c("pre","post"),levels=c("1","2")))

# Group means for each rating 
mu <- datRatings %>% group_by(gameNum.f, condition.f) %>% summarise(mean_coop = mean(rating_coop),
                                                  mean_selfish = mean(rating_selfish),
                                                  mean_trustworthy = mean(rating_trustworthy),
                                                  mean_friendly = mean(rating_friendly)
                                                  )
```

```{r, include=FALSE}


# Cooperative
coop_mod <- mixed(rating_coop ~ gameNum.f*condition.f + (1 | id), datRatings)
summary(coop_mod)

pairs(emmeans::emmeans(coop_mod, c("gameNum.f"), by = "condition.f"))

#Selfish
self_mod <- mixed(rating_selfish ~ gameNum.f*condition.f + (1 | id), datRatings)
summary(self_mod)
pairs(emmeans::emmeans(self_mod, c("gameNum.f"), by = "condition.f"))

#Trustworthy 
trust_mod <- mixed(rating_trustworthy ~ gameNum.f*condition.f + (1 | id), datRatings)
summary(trust_mod)
pairs(emmeans::emmeans(trust_mod, c("gameNum.f"), by = "condition.f"))


#Friendly
friend_mod <- mixed(rating_friendly ~ gameNum.f*condition.f + (1 | id), datRatings)
summary(friend_mod)
pairs(emmeans::emmeans(friend_mod, c("gameNum.f"), by = "condition.f"))

# Conduction t-tests 
# t.test(rating_coop ~ gameNumber, data = datRatingsCoax, paired = TRUE)
# t.test(rating_selfish ~ gameNumber, data = datRatingsCoax, paired = TRUE)
# t.test(rating_trustworthy ~ gameNumber, data = datRatingsCoax, paired = TRUE)
# t.test(rating_friendly ~ gameNumber, data = datRatingsCoax, paired = TRUE)


```

<!-- showed a main effect of Game-number on all attributes, with participants rating the second player as less cooperative (∆M = 0.42, 95% CI [0.15, 0.69], t(317.00) = 3.10, p = .002), less trustworthy (∆M = 0.43, 95% CI [0.16, 0.70], t(317.00) = 3.19, p = .002), less friendly (∆M = 0.40, 95% CI [0.17, 0.64], t(317.00) = 3.36, p = .001) and more selfish(∆M = −0.36, 95% CI [−0.61, −0.10], t(317.00) = −2.76, p = .006). Importantly, there was a main effect of Condition , with participants in the intervention condition rated players higher than those in the control condition on cooperativeness (∆M = 0.40, 95% CI [0.00, 0.80], t(317.00) = 1.95, p = .052) and lower on selfishness (∆M = −0.41, 95% CI [−0.80, −0.02], t(317.00) = −2.04, p = .042). There was no evidence for an interaction effect between Game-number and Condition on any of the attributes. -->

Participants rated their artificial opponents differently between conditions (intervention vs control) and games (pre- vs post-intervention). The players ratings submitted at the end of each game showed a main effect of Game-number on all attributes, with participants rating the second player as less cooperative (`r apa_print(pairs(emmeans::emmeans(coop_mod, c("gameNum.f"))))$full_result`), less trustworthy (`r apa_print(pairs(emmeans::emmeans(trust_mod, c("gameNum.f"))))$full_result`), less friendly (`r apa_print(pairs(emmeans::emmeans(friend_mod, c("gameNum.f"))))$full_result`) and more selfish(`r apa_print(pairs(emmeans::emmeans(self_mod, c("gameNum.f"))))$full_result`). We also find a main effect of Condition as participants in the intervention condition rated players higher than those in the control condition on cooperativeness (`r apa_print(pairs(emmeans::emmeans(trust_mod, c("condition.f"))))$full_result`) and lower on selfishness (`r apa_print(pairs(emmeans::emmeans(self_mod, c("condition.f"))))$full_result`). There was no evidence for an interaction effect between Game-number and Condition on any of the attributes.

<!-- However, breaking down the interaction term by Condition, we find that participants rated the post-intervention player significantly lower on all positive attributes and higher on the negative one (selfish). There was no such difference in player ratings the control condition. -->

## Transfer to the Prisoner's Dilemma Game

```{r, include=FALSE}

PD_data <- d_finished %>%
  mutate( condition.f = fct_recode(condition.f, "intervention" = "coaxing")) %>%
  dplyr::select(id, condition.f,roundType,roundNum, PDoption,PDchoice, AiChoicePD,gameNum.f, PBOR_score) %>% 
                          filter(roundType == "PD",!is.na(roundNum)) %>% 
                          dplyr::mutate(coop = ifelse(PDchoice=="cooperate",1,0),phase = ifelse(roundNum <= 4, 0,1)) 

# Average cooperation rates per round
#PD_data %>% group_by(roundNum, condition.f) %>% summarise(coopRate = mean(coop))
```

```{r PDCoop, include=FALSE, fig.cap="Mean and standard error of the rate at which the cooperative action was chosen by the participants for each round of the repeated Prisoner's Dilemma game. Round 4 is where we programmed the Tit-for-Tat agent to defect, which explains the lower cooperation rate we see in round 5 onwards",fig.align="center", fig.width=6, fig.height =3}
# plot of cooperation rates per round
ggplot(PD_data,aes(x=roundNum,group = 1)) + 
  stat_summary(fun = "mean", geom = "line", aes(y=coop), color ="red") + 
  stat_summary(fun.data = "mean_se", geom = "errorbar",alpha =0.3, width = 0.2, aes(y=coop) ) + 
  facet_grid(~ condition.f) +
  xlab("Round") + 
  ylab("Cooperation rate (%)") +
  scale_x_continuous(breaks = round(seq(1,10, by = 1),1)) + 
  theme_bw()

```

```{r, include=FALSE}

ipd_mod <- mixed(coop ~ condition.f * phase + (1 |id), data= PD_data, method = "LRT", family= "binomial") 
summary(ipd_mod)

ipd_mod_r5 <- glm(coop ~ condition.f, data= PD_data%>% filter(roundNum >= 5)) 
summary(ipd_mod_r5)

```

We next asked whether the coaxing behavior induced by the intervention generalized to the RPD. Across participants, we look at the rate at which the cooperative action was chosen in each round. Using a logistic mixed-effects model with Condition and Phase (before or after defection trial) as fixed effects and a random intercept for participants, we found no evidence for a different cooperation rate in the intervention condition compared to the control condition. We also found no difference in cooperation rates post defection trial between conditions.

## Self report and debrief questionnaires

```{r, include=FALSE}
########### HOW DO PBOR SCORES affect returns and intervention effect ?########

avg_ret_df <- avg_ret_df %>% mutate(PBOR_scaled = scale(PBOR_score), DERS_scaled = scale(DERS_score), RFQc_scaled = scale(RFQ_c))

# these are repeated measures here, so not independent. need to used mixed effects model.
mixed_PBOR_pct <- afex::mixed(ret_pct ~ PBOR_scaled*gameNum.f*condition.f + investment + (1 | id ), data= avg_ret_df)
summary(mixed_PBOR_pct)

# At average value of PBOR score  
emmeans(mixed_PBOR_pct, pairwise ~ PBOR_scaled * condition.f )

## Looking at difference between average returns across rounds
#scoreDAT <- avg_ret_df %>% dplyr::select(id,diff_pctRet, PBOR_scaled, DERS_scaled, RFQ_c, condition.f) %>% unique()


```

```{r, include=FALSE}
# Install the 'psych' package if you haven't already
if (!requireNamespace("psych", quietly = TRUE)) {
  install.packages("psych")
}

# Load the 'psych' package
library(psych)

questionnaires <- avg_ret_df %>% group_by(id) %>% dplyr::select(PBOR_score,DERS_score,RFQ_c) %>% unique() %>% ungroup()
# Perform EFA
efa_result <- fa(questionnaires %>% dplyr::select(PBOR_score,DERS_score,RFQ_c), nfactors = 2, fm = "minres", rotate = "varimax")
# Print the EFA result
print(efa_result)

```

We find no interaction effect of the questionnaire scores with the Condition variable, nor a main effect of the questionnaire scores on participants returns in the RTG.

```{r, include=FALSE}
turing <- read_csv("data/turing.csv")
colnames(turing) <- c("responses", "category")

turing  %>%
    group_by(category) %>%
    summarize(count = n()) %>%
    mutate(percentage = count / sum(count) * 100) %>%
    dplyr::select(category, percentage)

```

When asked whether they thought their opponent was Human or not, $40$% of participants thought they were either facing a human or were not sure of the nature of the opponent. Many answers reflected participants projecting human traits such as "spitefulness" or "greed" onto the artificial opponent's behavior.

# HMM analysis of participant returns

```{r, include=FALSE}


# Removing player whose return was not properly recorded by data (NA in one of the rounds) so as to run depmixS4
id_with_na <-  as.character(avg_ret_df[is.na(avg_ret_df$returns),"id"])

# Create return percentage bins Bins
avg_ret_df <- avg_ret_df %>%
  filter(id != id_with_na) %>% 
  mutate(game_id = rep(1:636, each=15)) %>%
  group_by(game_id) %>%
  mutate(next_investment = lead(investment, default=0),
         investment_bin = cut(investment, breaks = c(-1,2.5,7.5,12.5,17.5,21)),  
         return_pct_bin = cut(ret_pct_0, breaks = c(-.1,.16,.33,.50,.66,0.84,1.1)),  # 0, 1/6, 2/6, 3/6,...
         intervention_ctrst = factor(ifelse(gameNum.f=="pre", 0,ifelse(condition.f=="control",1,2))),
         ctrl_only_ctrst = factor(ifelse(gameNum.f=="post" && condition.f=="control", 1,0)),
         coax_only_ctrst = factor(ifelse(gameNum.f=="post" && condition.f=="intervention", 1,0)),
         pre_post_ctrst = factor(ifelse(gameNum.f=="post", 1,0)))  %>% 
  ungroup()
# We put factor as otherwise R thinks that it's a linear variable. We want the first level to be reference group, 0. Default uses that. 

priordat <- avg_ret_df %>% filter(roundNum==1)


############### HMM support functions   #########################

# order the states of the HMM to allow it to order them as low ret/mid/ret/high ret. 
label_switch <- function(mod,labels) {
  # labels is vector, first element is new label for original state 1, second is new label for original state 2, etc.
  if(!is(mod,"depmix") || !is(mod,"depmix.fitted")) stop("this function is for depmix models")
  n_states <- mod@nstates
  if(length(labels) != n_states || length(unique(labels)) != n_states || !(all(labels) %in% 1:n_states)) {
    stop("labels needs to be a vector of unique integers between 1 and", n_states)
  }
  inv_labels <- sapply(1:n_states,function(x) which(labels == x))
  tmp <- mod
  # relabel prior
  ppars <- getpars(mod@prior)
  fpars <- getpars(mod@prior,which="fixed")
  out_pars <- as.numeric(t(matrix(ppars,nrow=length(ppars)/n_states,byrow = TRUE)[,inv_labels]))
  out_fixed <- as.logical(t(matrix(fpars,nrow=length(fpars)/n_states,byrow = TRUE)[,inv_labels]))
  if(!tmp@prior@family$link=="identity") tmp@prior@family$base <- labels[tmp@prior@family$base]
  # relabel transition
  for(i in 1:n_states) {
    ppars <- getpars(mod@transition[[inv_labels[i]]])
    fpars <- getpars(mod@transition[[inv_labels[i]]],which="fixed")
    out_pars <- c(out_pars,as.numeric(t(matrix(ppars,nrow=length(ppars)/n_states,byrow = TRUE)[,inv_labels])))
    out_fixed <- c(out_fixed,as.logical(t(matrix(fpars,nrow=length(fpars)/n_states,byrow = TRUE)[,inv_labels])))
    tmp@transition[[i]] <- mod@transition[[inv_labels[i]]]
    if(!tmp@transition[[i]]@family$link=="identity") tmp@transition[[i]]@family$base <- labels[tmp@transition[[i]]@family$base]
    #out_pars <- c(out_pars,getpars(mod@transition[[inv_labels[i]]]))
  }
  # relabel response
  for(i in 1:n_states) {
    out_pars <- c(out_pars,unlist(lapply(mod@response[[inv_labels[i]]],getpars)))
    out_fixed <- c(out_fixed,unlist(lapply(mod@response[[inv_labels[i]]],getpars,which="fixed")))
  }
  tmp <- setpars(tmp,out_fixed,which="fixed")
  tmp <- setpars(tmp,out_pars)
  if(is(tmp,"depmix.fitted")) tmp@posterior <- viterbi(tmp)
  return(tmp)
}


# ORDERING STATES
order_mod_gauss <- function(mod) {
  ns <- nstates(mod)
  sum <- rep(0.0,ns)
  for(i in 1:ns) {
    # Expected return in each state calculation 
    sum[i] = mod@response[[i]][[1]]@parameters$mu
  }
  # reordering the states
  mod <- label_switch(mod, rank(sum))
  return(mod)
}


```

```{r, include=F}
# define a response class which only contains the standard slots, no additional slots
setClass("discgaus", contains="response", slots=c(breaks="numeric"))

# define a generic for the method defining the response class

setGeneric("discgaus", function(y, pstart = NULL, fixed = NULL, ...) standardGeneric("discgaus"))

# define the method that creates the response class

setMethod("discgaus", 
          signature(y="ANY"), 
          function(y,pstart=NULL,fixed=NULL, breaks = c(-Inf, 0:19 + .5, Inf), ...) {
            y <- matrix(y,length(y))
            x <- matrix(1)
            parameters <- list()
            npar <- 2
            if(is.null(fixed)) fixed <- as.logical(rep(0,npar))
            if(!is.null(pstart)) {
              if(length(pstart)!=npar) stop("length of 'pstart' must be ",npar)
              parameters$mu <- pstart[1]
              parameters$sigma <- pstart[2]
            }
            mod <- new("discgaus",parameters=parameters,fixed=fixed,x=x,y=y,npar=npar, breaks=breaks)
            mod
          }
)

setMethod("show","discgaus",
          function(object) {
            cat("Gaussian with discrete support\n")
            cat("Parameters: \n")
            cat("mu: ", object@parameters$mu, "\n")
            cat("sigma: ", object@parameters$sigma, "\n")
          }
)

setMethod("dens","discgaus",
          function(object,log=FALSE) {
            p <- pnorm(object@breaks[-1], mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(object@breaks[-length(object@breaks)], mean = object@parameters$mu, sd = object@parameters$sigma)
            if(log) return(log(p[as.numeric(cut(object@y, breaks=object@breaks))])) else return(p[as.numeric(cut(object@y, breaks=object@breaks))])
          }
)

setMethod("setpars","discgaus",
          function(object, values, which="pars", ...) {
            npar <- npar(object)
            if(length(values)!=npar) stop("length of 'values' must be",npar)
            # determine whether parameters or fixed constraints are being set
            nms <- names(object@parameters)
            switch(which,
                   "pars"= {
                     object@parameters$mu <- values[1]
                     object@parameters$sigma <- values[2]
                   },
                   "fixed" = {
                     object@fixed <- as.logical(values)
                   }
            )
            names(object@parameters) <- nms
            return(object)
          }
)

setMethod("getpars","discgaus",
          function(object,which="pars",...) {
            switch(which,
                   "pars" = {
                     parameters <- numeric()
                     parameters <- unlist(object@parameters)
                     pars <- parameters
                   },
                   "fixed" = {
                     pars <- object@fixed
                   }
            )
            return(pars)
          }
)

setMethod("fit","discgaus",
          function(object,w) {
            if(missing(w)) w <- NULL
            if(!is.null(w)) {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(w*log(dens(object)))
              }
            } else {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(log(dens(object)))
              }
            }
            pars <- optim(c(object@parameters$mu, log(object@parameters$sigma)), fn=negLL)$par
            object <- setpars(object,c(pars[1], exp(pars[2])))
            object
          }
)

setClass("truncdiscgaus", contains="discgaus", slots=c(min="numeric", max="numeric"))

setMethod("dens","truncdiscgaus",
          function(object,log=FALSE) {
            breaks <- c(object@min, object@breaks[object@breaks > object@min & object@breaks < object@max], object@max)
            p <- pnorm(breaks[-1], mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(breaks[-length(breaks)], mean = object@parameters$mu, sd = object@parameters$sigma)
            p <- p/sum(p)
            if(log) return(log(p[as.numeric(cut(object@y, breaks=object@breaks))])) else return(p[as.numeric(cut(object@y, breaks=object@breaks))])
          }
)

setGeneric("truncdiscgaus", function(y, pstart = NULL, fixed = NULL, ...) standardGeneric("truncdiscgaus"))

setMethod("truncdiscgaus", 
          signature(y="ANY"), 
          function(y,pstart=NULL,fixed=NULL, breaks = c(-Inf, 0:19 + .5, Inf), min=0, max=20, ...) {
            y <- matrix(y,length(y))
            x <- matrix(1)
            parameters <- list()
            npar <- 2
            if(is.null(fixed)) fixed <- as.logical(rep(0,npar))
            if(!is.null(pstart)) {
              if(length(pstart)!=npar) stop("length of 'pstart' must be ",npar)
              parameters$mu <- pstart[1]
              parameters$sigma <- pstart[2]
            }
            mod <- new("truncdiscgaus",parameters=parameters,fixed=fixed,x=x,y=y,npar=npar, breaks=breaks, min=min, max=max)
            mod
          }
)


order_mod_gauss <- function(mod) {
  ns <- nstates(mod)
  sum <- rep(0.0,ns)
  for(i in 1:ns) {
    # Expected return in each state calculation 
    sum[i] = mod@response[[i]][[1]]@parameters$mu
  }
  # reordering the states
  mod <- label_switch(mod, rank(sum))
  return(mod)
}

# define a response class which only contains the standard slots, no additional slots
setClass("vtdgaus", contains="response", slots=c(yield="numeric"))

# define a generic for the method defining the response class

setGeneric("vtdgaus", function(y, pstart = NULL, fixed = NULL, ...) standardGeneric("vtdgaus"))

# define the method that creates the response class

setMethod("vtdgaus", 
          signature(y="ANY"), 
          function(y, yield, pstart=NULL,fixed=NULL, ...) {
            y <- matrix(y,length(y))
            x <- matrix(1)
            parameters <- list()
            npar <- 2
            if(is.null(fixed)) fixed <- as.logical(rep(0,npar))
            if(!is.null(pstart)) {
              if(length(pstart)!=npar) stop("length of 'pstart' must be ",npar)
              parameters$mu <- pstart[1]
              parameters$sigma <- pstart[2]
            } else {
              parameters <- list(mu=.5,sigma=1)
            }
            mod <- new("vtdgaus",parameters=parameters,fixed=fixed,x=x,y=y,npar=npar, yield=yield)
            mod
          }
)

setMethod("show","vtdgaus",
  function(object) {
    cat("Gaussian with variable discrete support for percentage responses\n")
    cat("Parameters: \n")
    cat("mu: ", object@parameters$mu, "\n")
    cat("sigma: ", object@parameters$sigma, "\n")
  }
)

setMethod("dens","vtdgaus",
  function(object,log=FALSE) {
      # determine cuts for pnorm based on 
      p <- pnorm(sapply(object@y + .5*(1/object@yield),function(x) min(x,1.001)), mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(sapply(object@y - .5*(1/object@yield),function(x) max(x,-0.001)), mean = object@parameters$mu, sd = object@parameters$sigma)
      norm <- (pnorm(1 + .001, mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(-0.001, mean = object@parameters$mu, sd = object@parameters$sigma))
      p <- p/norm
      # alternatively, normalize factor based on size of cuts
      #p <- pnorm(object@y + .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(object@y - .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma)
      #p <- p/(pnorm(1 + .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(0 - .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma))
    # probability when yield == 0 is always 1 
      p[object@yield == 0] <- 1
      if(log) return(log(p)) else return(p)
    }
)

setMethod("setpars","vtdgaus",
          function(object, values, which="pars", ...) {
            npar <- npar(object)
            if(length(values)!=npar) stop("length of 'values' must be",npar)
            # determine whether parameters or fixed constraints are being set
            nms <- names(object@parameters)
            switch(which,
                   "pars"= {
                     object@parameters$mu <- values[1]
                     object@parameters$sigma <- values[2]
                   },
                   "fixed" = {
                     object@fixed <- as.logical(values)
                   }
            )
            names(object@parameters) <- nms
            return(object)
          }
)

setMethod("getpars","vtdgaus",
          function(object,which="pars",...) {
            switch(which,
                   "pars" = {
                     parameters <- numeric()
                     parameters <- unlist(object@parameters)
                     pars <- parameters
                   },
                   "fixed" = {
                     pars <- object@fixed
                   }
            )
            return(pars)
          }
)

setMethod("fit","vtdgaus",
          function(object,w) {
            if(missing(w)) w <- NULL
            if(!is.null(w)) {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(w*log(dens(object)))
              }
            } else {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(log(dens(object)))
              }
            }
            pars <- optim(c(object@parameters$mu, log(object@parameters$sigma)), fn=negLL)$par
            object <- setpars(object,c(pars[1], exp(pars[2])))
            object
          }
)
```

```{r, include=F}
priordat <- avg_ret_df %>% filter(roundNum==1)
n_state_min <- 2
n_state_max <- 7

trust_simple <- trust_ctrl <- trust_coax <- trust_fullCtrst <- trust_prePost <- list()

# HMMs based on bins
for(i in n_state_min:n_state_max) {
  
  trust_simple[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
  
  trust_ctrl[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*ctrl_only_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
  
  trust_coax[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*coax_only_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
  
  trust_fullCtrst[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*intervention_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
  
  trust_prePost[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*pre_post_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))

}


# vtdgaus no contrasts
simple_HMMs <- ctrl_HMMs <- coax_HMMs <- fullCtrst_HMMs <- prePost_HMMs <- list()

for(i in n_state_min:n_state_max) {

  rModels <- rep(list(list(vtdgaus(y=avg_ret_df$ret_pct_0,yield=3*avg_ret_df$investment))),each=i)
  
  simple_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_simple[[i]]@transition,prior=trust_simple[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
  
  ctrl_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_ctrl[[i]]@transition,prior=trust_ctrl[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
  
  coax_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_coax[[i]]@transition,prior=trust_coax[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
  
  fullCtrst_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_fullCtrst[[i]]@transition,prior=trust_fullCtrst[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
  
  prePost_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_prePost[[i]]@transition,prior=trust_prePost[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
    
}
```

```{r, include=FALSE}

# fittedSimple <- fittedCoax  <- fittedCtrl  <- fittedFullCtrst  <- fittedPrePost  <- list()
# # increase default in multistart from 10 to 20. or set the same seed for every model
# 
# set.seed(20221028)
# for(i in n_state_min:n_state_max) {
# 
#   fittedSimple[[i]] <- multistart(simple_HMMs[[i]],nstart=20)
# }
# save(fittedSimple, file="fittedSimple.RData")
# ##############################
# 
# set.seed(20221028)
# for(i in n_state_min:n_state_max) {
#   fittedCtrl[[i]] <- multistart(ctrl_HMMs[[i]],nstart=20)
# }
# save(fittedCtrl, file="fittedCtrl.RData")
# ##############################
# 
# set.seed(20221028)
# for(i in n_state_min:n_state_max) {
#   fittedCoax[[i]] <- multistart(coax_HMMs[[i]],nstart=20)
# }
# save(fittedCoax, file="fittedCoax.RData")
# ##############################
# 
# set.seed(20221028)
# for(i in n_state_min:n_state_max) {
#   fittedPrePost[[i]] <- multistart(prePost_HMMs[[i]],nstart=20)
# }
# save(fittedPrePost, file="fittedPrePost.RData")
# #############################
# 
# 
# 
# for(i in n_state_min:n_state_max) {
#   fittedFullCtrst[[i]] <- multistart(fullCtrst_HMMs[[i]],nstart=20)
# }
# save(fittedFullCtrst, file="fittedFullCtrst.RData")
# ###############################


```

```{r, include=FALSE}

# THE CODE BELOW WAS NOT USED; ALL CONVERGED. PUT IT HERE IN CASE IT IS NEEDED LATER ON.
# library(depmixS4)
# 
# load("data/fittedSimple.RData")
# load("data/fittedCtrl.RData")
# load("data/fittedCoax.RData")
# load("data/fittedFullCtrst.RData")
# load("data/fittedPrePost.RData")
# load("data/newFull.RData")
# 
# has_converged <- function(object, numeric = TRUE){
#   msg <- object@message
#   if(numeric) as.integer(grepl("converged", msg)) else 0
# }
# 
# 
# fit_until_convergence <- function(fitted_model, max_iterations=2) {
#   cat(fitted_model@nstates)
#   iterations <- 0
#   converged <- has_converged(fitted_model)
#   
#   while (!converged && iterations < max_iterations) {
#     # Use parameters from the fitted model as initial parameters
#     initial_params <- getpars(fitted_model)
#     new_model <- setpars(fitted_model, initial_params)
#     
#     # Refit the model
#     fitted_model <- fit(new_model)
#     converged <- has_converged(fitted_model)
#     iterations <- iterations + 1
#   }
#   
#   if (converged) {
#     cat("NS = ", fitted_model@nstates,"Convergence has been reached.\n")
#     flush.console()
#     return(fitted_model)
#   } else {
#     cat("Maximum iterations reached. Convergence has not been reached.\n")
#     flush.console()
#     return(fitted_model)
#   }
# }
# 
# 
# run_parallel_fitting <- function(mods_vec,num_cores = 5) {
#   # Set up the parallel backend
#   my.cluster <- parallel::makeCluster(num_cores, type = "PSOCK")
#   doParallel::registerDoParallel(cl = my.cluster)
#   
#   # Export the fit_until_convergence function to the workers
#   parallel::clusterExport(my.cluster, "fit_until_convergence")
#   parallel::clusterExport(my.cluster, "has_converged")
# 
#   # Run the loop in parallel using foreach
#   converged_mods_vec <- foreach(mod = mods_vec, .packages = c("depmixS4"), .combine = "c") %dopar% {
#     cat(mod@nstates)
#     fit_until_convergence(mod)
#   }
# 
#   # Stop the parallel backend
#   parallel::stopCluster(my.cluster)
#   return(converged_mods_vec)
# }
# 
# 
# sapply(fittedSimple[2:7],has_converged)
# sapply(fittedCtrl[2:7],has_converged)
# sapply(fittedCoax[2:7],has_converged)
# sapply(fittedFullCtrst[2:7],has_converged)
# sapply(fittedPrePost[2:7],has_converged)
# sapply(newFull[2:7],has_converged)

```

```{r, include=FALSE}
# # The full contrast model convergence was not attained. Here we use parameters of fitted PrePost model as initial values of the FullContrast model to speed up fitting and aim for faster convergence.

# newFull <- fittedFullCtrst
# for (ns in n_state_min :n_state_max){
# 
#   fmod <- fittedPrePost[[ns]]
#   origin_pars <- getpars(fmod)
#   numCovTr <- 4
#   numCovIn <- 2
#   
#   # create a new vector which has the right number of pars for the full contrast model. 
#   new_pars <- c(origin_pars[1:(ns*2)])
#   # from is state we are transitioning from 
#   for(from in 1:ns) {
#   mat <- matrix(getpars(fmod)[seq(ns*numCovIn + 1 + (from - 1)*numCovTr*ns, ns*numCovIn + 1 + (from - 1)*numCovTr*ns + numCovTr*ns - 1)],ncol=numCovTr)
#   new_mat <- mat[,c(1:2,3,3,4,4)]
#   new_pars <- c(new_pars,as.numeric(new_mat))
#   }
#   
#   new_pars <- c(new_pars,origin_pars[(ns*numCovIn + 1 + (ns - 1)*numCovTr*ns + numCovTr*ns):length(origin_pars)])
#   
#   newFull[[ns]] <- setpars(newFull[[ns]],new_pars)
#   newFull[[ns]] <- fit(newFull[[ns]], emcontrol= em.control(maxit = 1000,random.start = FALSE))
# }
# 
# save(newFull, file="newFull.RData")
 
```

```{r, include=FALSE}

load("data/fittedSimple.RData")
load("data/fittedCtrl.RData")
load("data/fittedCoax.RData")
load("data/fittedFullCtrst.RData")
load("data/fittedPrePost.RData")
load("data/newFull.RData")

BICs_simple <- BICs_Ctrl <- BICs_Coax <- BICs_FullCtrst <- BICs_PrePost <-  BICs_newFull <- list()
for(i in n_state_min:n_state_max) {
  BICs_simple[[i]] <- BIC(fittedSimple[[i]]) 
  BICs_Ctrl[[i]] <- BIC(fittedCtrl[[i]])
  BICs_Coax[[i]] <- BIC(fittedCoax[[i]]) 
  BICs_FullCtrst[[i]] <- BIC(fittedFullCtrst[[i]]) 
  BICs_PrePost[[i]] <- BIC(fittedPrePost[[i]]) 
  BICs_newFull[[i]] <- BIC(newFull[[i]]) 
  
}

print("SIMPLE HMM models")
BICs_simple

print("HMM with contrast on post Control vs others")
BICs_Ctrl

print("HMM with contrast on post Coax vs others")
BICs_Coax

print("HMM with Pre vs Post Contrast")
BICs_PrePost

print("HMM with contrast levels Pre, Post Control and Post Coaxing")
BICs_FullCtrst

print("HMM with contrast levels Pre, Post Control and Post Coaxing, new fitting")
BICs_newFull

df_bics <- cbind(2:7,as.numeric(BICs_simple[2:7]), as.numeric(BICs_Ctrl[2:7]),as.numeric(BICs_Coax[2:7]), as.numeric(BICs_PrePost[2:7]), as.numeric(BICs_newFull[2:7]))
df_bics


```

```{r, include=FALSE}
library(knitr)
library(kableExtra)

# Create a data frame for the models
models <- data.frame(
  Model = c("HMM-inv", "HMM-prepost", "HMM-coax", "HMM-ctrl", "HMM-full"),
  Pre_Intervention =  c(0, -1, -1, -1, -1),
  Post_Intervention = c(0, 1, 1, -1, 2),
  Pre_Control =       c(0, -1, -1, -1, -1),
  Post_Control =      c(0, 1, -1, 1, 1)
)

# Create a table
models %>%
  kable("pipe", caption = "Models and their Contrasts") %>%
  kable_styling()

```

```{r table-BICs-coax, include =FALSE, warning = FALSE, echo=FALSE, ft.align="center", tab.id='table-BICs-coax', label='table-BICs-coax'}

data.frame(df_bics) %>% 
  `colnames<-` (c("Number of states","HMM-inv", "HMM-ctrl", "HMM-coax", "HMM-prepost","HMM-full")) %>%
  mutate_if(is.numeric, format, digits=4,nsmall = 0, big.mark = ",") %>% 
  knitr::kable(.,booktabs = TRUE,
  caption = 'Table of BICs for each of the estimated HMM models for assumed number of latent states between 2 and 7') %>% kable_styling(latex_options="scale_down")
```

We analyzed participants' behavior differences in the intervention versus control conditions using hidden Markov models (HMM). Five models were used: "HMM-inv" assumed transition states depended solely on investment, ignoring game number and condition. "HMM-prepost" contrasted Pre and Post Intervention. "HMM-coax" contrasted post-intervention with pre-intervention and both control conditions. "HMM-ctrl" contrasted post-control with pre-control and both intervention conditions. "HMM-full" grouped pre-control and pre-intervention as one, with separate groups for post-control and post-intervention. Models were fitted using 2 to 7 states, selecting the lowest BIC. Generally, 5-7 state models best explained the data. A likelihood ratio test compared the models' goodness of fit, contrasting the complex HMM-full model with nested models equating behavior in certain stages and conditions.

<!-- Table \ref{tab:table-BICs-coax} shows the BICs of the various fitted models for an assumed number of states between 2 and 7.  For a simple model without any contrasts (HMM-inv) and a model with post-control only contrast (HMM-ctrl) we find a 6-state model to be best fitting. If the contrast is between the post-intervention group and all the other groups (HMM-coax), then a 7 state model is best fitting. When the contrast is comparing only pre and post Intervention groups (HMM-prepost), a 5 state model fits best. Finally, when we distinguish between pre-manipulation, post-control and post-intervention (HMM-full), we find that a 5 state model fits best. Since we only fit models between 2 and 7 states, it is possible that for those where we find the 7 state model to be best fitting, models with a higher number of states could fit the data better. We decided to stop at 7 states for computational cost reasons and because the interpretation of models with a higher number of states becomes complex.  -->

```{r, include=FALSE}
summary(fittedSimple[[5]])

logLik(fittedSimple[[5]])
logLik(fittedCtrl[[5]])
logLik(fittedCoax[[5]])
logLik(fittedPrePost[[5]])
# logLik(fittedFullCtrst[[5]])
logLik(newFull[[5]])

# Nested model comparison for 5 states, with and without intervention contrast. llratio test shows no effect, meaning interaction term addition does not change goodness of fit of model. 
llratio(newFull[[5]], fittedSimple[[5]])

llratio(fittedCtrl[[5]],fittedSimple[[5]])
llratio(fittedCoax[[5]],fittedSimple[[5]])
llratio(fittedPrePost[[5]],fittedSimple[[5]])

llratio(newFull[[5]],fittedCtrl[[5]])
llratio(newFull[[5]],fittedCoax[[5]])
llratio(newFull[[5]],fittedPrePost[[5]])

```

In order to compare the goodness of fit of the various models, we test the relative likelihood of models using a likelihood ratio test. This procedure is useful to compare the most complex model (HMM-full, which allows for differences between pre-intervention and the two conditions post-intervention) to nested models which equate behaviour in some if the stages and conditions.

<!-- We start by comparing HMM-full with HMM-inv. We find that HMM-full fits the data better than HMM-inv ($\chi^2(84) = `r round(-2*as.numeric(logLik(fittedSimple[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$). Likewise HMM-ctrl fits better than HMM-inv ($\chi^2(44) = `r round(-2*as.numeric(logLik(fittedSimple[[5]])) - (-2*as.numeric(logLik(fittedCtrl[[5]]))) , 2)`$, $p < .001$). The same is true for HMM-coax compared to HMM-inv ($\chi^2(44) = `r round(-2*as.numeric(logLik(fittedSimple[[5]])) - (-2*as.numeric(logLik(fittedCoax[[5]]))) , 2)`$, $p < .001$) and HMM-prepost compared to HMM-inv ($\chi^2(44) = `r round(-2*as.numeric(logLik(fittedSimple[[5]])) - (-2*as.numeric(logLik(fittedPrePost[[5]]))) , 2)`$, $p < .001$). HMM-inv being the worst fitting model compared to the others indicates the existence of differentiated behavior pre vs post manipulation and/or between the control and intervention groups.  -->

Using likelihood ratio tests, we find that the HMM-full model fits significantly better than HMM-ctrl ($\chi^2(40) = `r round(-2*as.numeric(logLik(fittedCtrl[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$), HMM-coax ($\chi^2(40) = `r round(-2*as.numeric(logLik(fittedCoax[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$) and HMM-prepost ($\chi^2(40) = `r round(-2*as.numeric(logLik(fittedPrePost[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$). This is consistent with a differentiated behavior of the trustees between all three groups: the post-intervention group, the post-control group and the pre-manipulation group.

<!--    ORDER THE STATES    -->

```{r, include=FALSE}
tr_fdmod_5 <- order_mod_gauss(newFull[[5]])
```

```{r, include=FALSE}

state1 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[1]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

state2 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[2]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

state3 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[3]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

state4 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[4]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

state5 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[5]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

returns <- seq(0.025,0.975,length=20)

response_best_mod <- as.data.frame(cbind(returns,state1,state2,state3,state4,state5)) %>% 
  pivot_longer(cols=c("state1","state2","state3","state4","state5"),
                    names_to='Trustee_state',
                    values_to='probability')

```



<!-- Using the best fitting model according to likelihood ratio tests (HMM-full), Figure \ref{fig:trusteeHMMPlot} shows the distribution of the participants' returns conditional on the latent state they are in. The states are ordered based on the mean of the Gaussian distribution fitted to the response (percentage return). State 1 represents the state in which the returns have have the lowest underlying mean, and state 5 is the state in which the returns have the highest underlying mean. The higher the state number the more pro-social the policy adopted. More specifically, state 1 can be thought of as a non-cooperative state in which returns are low and close to 0, meaning that the trustee is keeping most of the tripled investment. State 2 is a state where the average return is around the investment sent and can be interpreted as a cautious state in which the return on trust is small. States 3, 4 and 5 are increasingly cooperative states. For instance, in state 5, the average return is close to two thirds of the tripled investment, meaning the trustee is keeping an amount similar to the investment that was sent and returning to the investor double the investment. -->

<!-- Figure \ref{fig:plotTransitionsDiscGaus} shows the transition between states as a function of the investment received for each group (pre-manipulation, post-control and post-intervention) using results from the best fitting model: HMM-full. The best fitting HMM model has multiple states and a high number of parameters. We can nonetheless focus on particular states linked to the breakdown and repair of cooperation. For instance, focusing on the transition functions to state 1 (the lowest return state with returns close to 0) from higher return states, we can compare the  post-control group to the post-intervention group. The red line representing the probability of transitioning to the low-return state 1 when the investment is close to 0 is lower in the intervention group compared to the control group when the trustee is in a relatively pro-social state (states 3 to 5). This is pointing towards more "forgiving" behavior where participants in the intervention group were less likely to transition to this anti-social state compared to the control group.  -->

Using the HMM-full model, we can retrieve participants' return distributions based on their latent states (Figures \ref{fig:postStatesBestMod}.A) and transition probabilities between these states (Figure \ref{fig:plotTransitionsDiscGaus}). The states are ranked by mean return, with State 1 having the lowest mean return and State 5 the highest. A higher state number indicates a more pro-social policy. We focused on states related to cooperation's breakdown and repair. We compared the transition probabilities between states when the investment is low for post-control and post-intervention groups. Figure \ref{fig:plotTransitionsDiscGaus} suggests that the intervention group is more forgiving of low investments, as they are less likely to shift to an anti-social state when faced with defection compared to the control group.


```{r, include=FALSE}

plot_state_transitions <- function(fmod, numCovIn, numCovTr) {

  #print(getpars(fmod))
  ns <- nstates(fmod)
  
  trans_prob <- data.frame(
    from = rep(1:ns, each=100*ns),
    to = rep(1:ns, each=100),
    investment = seq(0,20,length=100),
    prob_pre = 0,
    prob_ctrl = 0,
    prob_coax =0
  )
  
  y0 <- matrix(0.0,ncol=ns, nrow=100)
  y1 <- matrix(0.0,ncol=ns, nrow=100)
  y2 <- matrix(0.0,ncol=ns, nrow=100)
  
  for(from in 1:ns) {
  pars <- matrix(getpars(fmod)[seq(ns*numCovIn + 1 + (from - 1)*numCovTr*ns, ns*numCovIn + 1 + (from - 1)*numCovTr*ns + numCovTr*ns - 1)],ncol=numCovTr)
  #print(pars)
  
    for(to in 1:ns) {
        x <- trans_prob[trans_prob$from == from & trans_prob$to == to,"investment"]
        y0[,to] <- exp(pars[to,1] + pars[to,2]*x)
        #ctrst 2 = 1, post intervention vs pre
        y2[,to] <- exp(pars[to,1] + pars[to,2]*x + pars[to,3]*1 + pars[to,5]*x )
        #ctrst 1 = 1, post control vs pre
        y1[,to] <- exp(pars[to,1] + pars[to,2]*x + pars[to,4]*1 + pars[to,6]*x )
    }
    y0 <- y0/rowSums(y0)
    y1 <- y1/rowSums(y1)
    y2 <- y2/rowSums(y2)
    
    for(to in 1:ns) {
      trans_prob$prob_pre[trans_prob$from == from & trans_prob$to == to] <- y0[,to]
      trans_prob$prob_ctrl[trans_prob$from == from & trans_prob$to == to] <- y1[,to]
      trans_prob$prob_coax[trans_prob$from == from & trans_prob$to == to] <- y2[,to]
    }
  }
  
  
  
  saveRDS(trans_prob, "data/trans_prob.RDS")
  
  return(trans_prob)
  
  #  p_pre <- ggplot(trans_prob,aes(x=investment,y=prob_pre, colour = as.factor(to))) + geom_line() + facet_wrap(~from) + ylim(c(0,1)) + ggtitle("Transition function pre manipulation") + labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + theme_bw()
  # 
  # p_ctrl <- ggplot(trans_prob,aes(x=investment,y=prob_ctrl, colour = as.factor(to))) + geom_line() + facet_wrap(~from) + ylim(c(0,1)) + ggtitle("Transition function post control") + labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + theme_bw()
  # 
  # p_coax <- ggplot(trans_prob,aes(x=investment,y=prob_coax, colour = as.factor(to))) + geom_line() + facet_wrap(~from) + ylim(c(0,1)) + ggtitle("Transition function post intervention") + labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + theme_bw()
  # 
  # grid.arrange(p_pre, p_ctrl,p_coax, nrow=3, ncol=1)


}


# plot_state_transitions(tr_fdmod_5,numCovIn=2, numCovTr=6) 

```

```{r,include=F}

trans_prob <- readRDS("data/trans_prob.RDS")

ctrl_pre_plot <- ggplot(trans_prob,aes(x=investment,y=prob_ctrl, colour = as.factor(to))) + 
  geom_line() + 
  geom_line(aes(y=prob_pre),linetype="dotted") +
  facet_wrap(~from) + 
  ylim(c(0,1)) + 
  ggtitle("Transition function pre- and post-control manipulation") + 
  labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + 
  theme_bw()


coax_pre_plot <- ggplot(trans_prob,aes(x=investment,y=prob_coax, colour = as.factor(to))) + 
  geom_line() + 
  geom_line(aes(y=prob_pre),linetype="dotted") +
  facet_wrap(~from) + 
  ylim(c(0,1)) + 
  ggtitle("Transition function pre- and post-intervention manipulation") + 
  labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + 
  theme_bw()



```

```{r plotTransitionsDiscGaus, fig.cap="Transition function for the HMM-full trustee model. Each panel represents the state transitioned from, and each color the state transitioned to. Solid lines show estimated transition probabillities post-manipulation. Dotted lines show the same probabilities prior to the manipulation",fig.align="center", fig.width=6, fig.height = 7 }

grid.arrange(ctrl_pre_plot , coax_pre_plot , nrow=2, ncol=1)

# plot_state_transitions(tr_fdmod_5,numCovIn=2, numCovTr=6) 

```

<!-- To explore the differences in transition probabilities between the control and coaxing conditions, we can choose an investment and compare the probabilities of transitioning between States. For instance, in case the trustee is low in trustworthiness (State 1), and the investor sends an average amount, we can compare the likelihood of the trustee transitioning away from the low trustworthiness state. Assuming an investment of 10 (half the endowment), The trustee remains in State 1 with around $85\%$ probability in the control condition, but only $67\%$ probability after the coaxing intervention. Likewise, assuming the trustee is in State 4, and receiving a low investment of 2, there is a much lower probability ($0.2\%$) of transitioning to low trustworthiness state in the coaxing condition compared to the control condition ($21\%$). -->

```{r, include = FALSE}
set.seed(20221010)
# Get investor posterior states from model and add to data table

# mention we are using local decoding (refer to the book). 
predTrStates <- posterior(tr_fdmod_5, type="local")
avg_ret_df$TrState <-  factor(predTrStates, levels= c(1,2,3,4,5),labels=c("1","2","3","4","5"))

# avg_ret_df$TrState <-  factor(predTrStates, levels= c(5,4,3,2,1),labels=c("5","4","3","2","1"))


# predTrStates <- posterior(tr_fdmod_5)
# avg_ret_df$TrState <-  factor(predTrStates$state, levels= c(1,2,3,4,5),labels=c("1","2","3","4","5"))

library(dplyr)
temp_df <- avg_ret_df %>% dplyr::select(roundNum,investment,returns, next_investment, TrState)
```

```{r, include=FALSE}

trusteeHMMPlot <- ggplot(response_best_mod,                            
       aes(x = returns,
           y = probability,
           fill = Trustee_state)) +
  geom_bar(stat = "identity",
           position = "dodge") + 
  labs(fill='Latent trustee State') +
  theme_bw() + 
  theme(legend.position = "bottom")

# investor real state distribution (posterior)
postHMM <- ggplot(avg_ret_df %>% dplyr::filter(gameNum.f=="post")) +
  geom_bar(aes(x = roundNum, group = TrState, fill = TrState),  position = position_stack(reverse = TRUE)) + 
  facet_wrap(~condition.f) +  
  labs(x = "Round", fill='Posterior trustee state') +
  theme_bw() +
  theme(legend.position = "bottom")



```

```{r postStatesBestMod,  echo=FALSE, fig.cap = "A: Distribution of participants' percentage return for each of the latent states in the 5 state HMM-full model. The latent states are ordered by the mean of the Gaussian that best fits the policy in that state, so higher numbered states are more pro-social. B: Distribution of posterior trustee states post manipulation by condition for all rounds, as estimated by the most likely posterior state in the best fitting HMM model (HMM-full) using a local decoding procedure.", fig.align="center", fig.height = 8}

ggpubr::ggarrange(trusteeHMMPlot , postHMM , nrow=2, ncol=1,labels = c("A", "B"),common.legend = FALSE)

```




```{r, include= F}

props_df_5 <- avg_ret_df %>% 
  filter(gameNum.f=="post", roundNum== 5) %>% 
  group_by(condition.f,TrState) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))

prop.test(c(11,29), c(159,159))

props_df_14 <- avg_ret_df %>% 
  filter(gameNum.f=="post", roundNum== 14) %>% 
  group_by(condition.f,TrState) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))


prop.test(c(35,68), c(159,159))



props_df_13 <- avg_ret_df %>% 
  filter(gameNum.f=="post", roundNum== 13) %>% 
  group_by(condition.f,TrState) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))

# compare proportions in state 1 in round 13 between conditions
prop.test(c(48,72), c(159,159))

# compare proportions in states 4 and 5  in round 13 between conditions
prop.test(c(48,18), c(159,159))

# props_df_12 <- avg_ret_df %>% 
#   filter(gameNum.f=="post", roundNum== 12) %>% 
#   group_by(condition.f,TrState) %>% 
#   summarise(n = n()) %>%
#   mutate(freq = n / sum(n))

```

To quantitatively explore the differences in transition probabilities between the control and intervention conditions, we can estimate from the model, using local decoding methods from the depmixS4 package [@visser_depmixs4_2021], the most likely posterior state of the trustee participants by round given the actions they have taken. Figure \ref{fig:postStatesBestMod}.B shows that participants were more likely to be in a lower return state in the control condition compared to the intervention condition both pre and post defection. For instance, in round 5, state 1 was the most likely posterior state for only $7$% of participants in the intervention condition compared to $24$% in the control condition ($\chi^2(1) = 8.26, p < 0.01$). For the post-defection trial after the intervention (round 14), state 1 was the most likely state for only $22$% of participants in the intervention condition compared to $43$% in the control condition ($\chi^2(1) = 14.70, p < 0.001$). 

The posteriors also suggest that a non-negligible proportion of participants in the intervention condition did not exhibit a behaviour consistent with the goal of the intervention as they were still best fit by low-return states post intervention. For instance, focusing on round 13 post defection $30.2$% of those in the intervention condition were most likely to be in the least pro-social state 1. These differences can be seen as an indication of important heterogeneity in the effectiveness of the intervention.

```{r, include=FALSE}
# library(depmixS4)
# 
# n_bootstraps <- 1  # number of bootstrap resamples
# bootstrap_estimates <- matrix(NA, nrow=n_bootstraps, ncol=1)  # to store bootstrap estimates
# 
# ns <- 3
# numCovIn <- 2
# numCovTr <- 6
# from <- 3
# to <- 1
# 
# for (i in 1:n_bootstraps) {
#   # create a bootstrap resample of the data
#   #bootstrap_data <- data[sample(nrow(data), replace=TRUE), ]
#   bootstrap_data <- avg_ret_df %>% filter(id %in% sample(id,replace=TRUE))
#   
#   rModels <- rep(list(list(vtdgaus(y=bootstrap_data$ret_pct_0,yield=3*bootstrap_data$investment))),each=ns)
#   
#   simple_mod <- depmix(ret_pct ~ 1, data = bootstrap_data, nstates = ns, transition = ~ next_investment*intervention_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
#   
#   
#   # fit the model to the bootstrap resample
# 
#   model <- makeDepmix(response=rModels, transition = simple_mod@transition , prior = simple_mod@prior, initdata=priordat, ntimes = rep(15,636), homogeneous=FALSE)
#   
#   cat("two")
#   # trust_fullCtrst[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*intervention_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
#   
#   
# 
#   fit <- fit(model)
#   cat("post-fit")
# 
#   # store the estimates
#   #bootstrap_estimates[i, ] <- getpars(fit)
#   
#   pars <- matrix(getpars(fit)[seq(ns*numCovIn + 1 + (from - 1)*numCovTr*ns, ns*numCovIn + 1 + (from - 1)*numCovTr*ns + numCovTr*ns - 1)],ncol=numCovTr)
#   
#    bootstrap_estimates[i, ] <- pars[to,3]
#   
# }
# 
# # calculate 95% confidence intervals
# ci_lower <- apply(bootstrap_estimates, 2, function(x) quantile(x, 0.025))
# ci_upper <- apply(bootstrap_estimates, 2, function(x) quantile(x, 0.975))
# 
# # print the confidence intervals
# print(ci_lower)
# print(ci_upper)

```

# Discussion

In this experiment, we made human participants face artificial computer agents endowed with the ability to transition between latent states and react to the participants' returns. The number of states, the policy in each state as well as the way these agents transitioned between states was based on estimating a hidden Markov model to behaviour from real human participants. On average, we saw the emergence of cooperative behavior with investment and returns in line with what is reported in human dyadic interaction in the repeated trust game [@charness_investment_2008; @fiedler_social_2011]. The emergence of cooperative behavior and participant's uncertainty about whether they were facing human or artificial opponents, point to the potential of these agents to mimic human behavior in economic games whilst offering a higher degree of experimental control.

The intervention's aim was to articulate the effect of acting on impulse in case of a transgressive action from the investor in the form of a one-off low investment. When the agent defected as programmed, yielding a situation similar to the one presented in the intervention, the intervention led to higher percentage returns post defection compared to the control group, as intended. Participants emotional reactions to the received investment, we similar pre and post-intervention, so the higher returns were produced despite participants having the same emotional reaction. This might indicate that the intervention achieved its goal of encouraging participants to respond in a non-impulsive, considered way, overriding the emotional urge to retaliate. 

What was also notable was that the intervention led to generally higher returns post-intervention, even before the defection trial. This could be for a number of reasons. One possibility is that participants simply learned that by returning more, the investment on the next trial would be higher. However, this explanation is unlikely, as we did not see a similar increase in percentage returns in the control condition. Another possibility is that, on average, the second player they faced invested more, which prompted positive reciprocity in the human trustees. As all players were programmed in the same way, any difference would be due to participant's actions. Further, participants rated both players similarly on relevant attributes of cooperativeness and trust. The higher returns are thus unlikely to be driven by different beliefs about the investor. A likely explanation for overall higher trustworthiness, as measured by higher percentage return post investment, is that participants, on average, interpreted the intervention message as an argument for more pro-social behavior, irrespective of the investor's actions.

It is also noteworthy that there were important individual differences in the percentage return changes post vs. pre intervention, which can be seen as a proxy for the intervention effectiveness. Some participants might not have been convinced by the intervention's message and decided to reduce their returns both pre and post defection in the second trust game, while others increased their returns in both phases. This raises important questions for the measurement of intervention effectiveness. Recent work has shed light on the important heterogeneity inherent in how disorders are categorised: This heterogeneity arises from the view that mental health problems should be viewed as complex systems, or interactions between neuro-computational processes and socio-environmental contexts evolving over time [@fried_moving_2017]. This view was used to justify computational psychiatry's difficulty in establishing differential and reliable predictors of likely treatment responses [@hitchcock_computational_2022]. But if a healthy group's reaction to a relatively explicit intervention is itself heterogeneous as we have shown in this experiment, then the issue of variable treatment responses might the result of the interaction of two sources of variability: the phenotyping of the disorder as well as the phenomenological aspects of the intervention itself. As such, a rigorous exploration of the determinants of inter-individual differences to an intervention in the general patient population is required.

In our case, judging by the inter-individual heterogeneity in responses, some people may not have been convinced that a coaxing behavior was a good way to establish long term cooperative outcomes, and their need to “punish” the other player for their low investment may have been more pertinent than what we suggested. This was also evident from the participants' replies to a question about whether they would change their behavior, just after seeing the intervention manipulation. An important avenue is to explore the role of emotion in decision making in such situations. We could aim to measure emotional reactions more accurately and explore whether specific emotions mediate the relationship between the investment received and the decision of what proportion to return. Measuring the emotions using the two axes of valence and arousal could be improved: Results indicate that these concepts may not have been well understood by participants since we would not expect to see low arousal after the pre-programmed defection of the investor.

The effect of this short intervention was not transferred to the Repeated Prisoner's Dilemma game. In this game, the rate at which the cooperative option was chosen was not significantly different between the control and intervention groups, both pre and post defection. Since the prisoner's dilemma is a very popular economic game, it is possible that participants had strong prior preferences towards which strategy they would adopt, irrespective of whether or not they received the intervention. As such, this paradigm might not be the best test case for knowledge transfer. For those that took on the intervention message and showed coaxing behavior in the second trust game, the fact that the investor still defected in the final rounds might have reinforced the idea that not reciprocating negative behavior is a losing strategy after all.

Overall, it is remarkable that such a short intervention, consisting of reading a short text detailing a non-impulsive reaction to low investments can lead to such differentiated behavior. In future studies, we aim to explore the effects of different cognitive interventions and improve the experimental design in multiple ways. First, the intervention could benefit from being more interactive medium, with visual inputs such as cartoons and videos, rather than pure text which can be cumbersome to read and lead to lower engagement. Second, we selected trustees from the general population, which might not suffer from the inability or unwillingness to repair relationships due to accidental breakdown of trust that characterises some mental health disorders such as BPD. As such, it would be interesting to contrast these results with findings from experiments involving trustees that are selected from patient populations known to suffer from difficulties in maintaining or repairing cooperative interactions. Third, as we explained above, the choice of the task to measure transfer of intervention learning could be made better by involving less popular paradigms. The high popularity of the Prisoner's Dilemma and the strategy of playing tit-for-tat may have resulted in a strong prior on which strategy to adopt in this game irrespective of the intervention. We believed that asking people about how they felt in the control condition might have affected how they behaved and might constitute an intervention in itself. However, being able to compare the differential impact of the intervention on the emotional interpretation of the opponent action between an intervention and control conditions could lead to insights on the mechanism through which the intervention affects the emotional reaction to the opponent's actions.

# Conclusion

We explored the effect of a short cognitive intervention on the behavior of human trustees facing adaptive artificial agents endowed with multiple latent behavioral states. Each state defines different levels of a cooperative response with the agent able to transition between these states based on the behavior of the human opponent. Feedback from participants indicated that these agents were sometimes perceived as humans. Their strategy led to emergent cooperative behavior when playing the repeated trust game with human players. The intervention, promoting a less impulsive reaction to transgressive actions, led to coaxing behavior and less negative reciprocity when the investor sent a very low investment. It also led to more trustworthy behavior prior to the pre-programmed defection trial and to coaxing behavior after defection. Whilst this intervention effect varied between participants and generally was not transferred to a new game, an HMM analysis of participant's play post intervention showed differentiated patterns of transitions between latent states, indicating a change in the effect of the opponent action on the probability of transitioning between latent mental states.

# References
