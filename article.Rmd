---
title: "Repairing cooperation through a cognitive intervention in the repeated Trust Game"
author:
  - Ismail Guennouni
  - Quentin Huys
  - Samuel Dupret
  - Maarten Speekenbrink

# - name: Ismail Guennouni
#   address: Department of Experimental Psychology, University College London, 26 Bedford Way, London WC1H 0AP, United Kingdom
#   email: i.guennouni.17@ucl.ac.uk
# 
# - name: Maarten Speekenbrink
#   address: Department of Experimental Psychology, University College London, 26 Bedford Way, London WC1H 0AP, United Kingdom
#   email: m.speekenbrink@ucl.ac.uk
# 
# - name: Quentin Huys
#   address: Max Planck Institute of Computational Psychiatry
#   email: q.huys@ucl.ac.uk
# 
# - name: Samuel Dupret
#   address: HLI
#   email: sam.dupret@ucl.ac.uk
keywords:
- Economic Games 
- Hidden Markov Models
- Repair of Cooperation
- Cognitive Intervention 


abstract: | 
  Social trust is an important building block of strong social bonds, and its absence is a risk factor for social dysfunction. As such, interventions to foster and strengthen trust-based cooperation are highly desirable. Using the repeated Trust Game paradigm, we assess the effectiveness of a cognitive intervention aimed at repairing the potential breakdown of cooperation from a pre-programmed, one-off defection by the opponent. Over two games, participants are given the role of the trustee and face what they believe are two different players. In between games, they either receive a brief cognitive intervention or not. The intervention led to more cooperative behavior both pre and post defection by the opponent. HMM modelling of participants actions shows participants in the intervention group had a lower probability of transitioning to non cooperative states. Posterior latent state analysis also showed a  higher proportion of players best described by more cooperative latent states in the intervention condition compared to the control condition.
  
bibliography: "bib/cogIntervention.bib"
biblio-style: spphys
output:
  bookdown::pdf_document2:
   toc: false
---



```{r setupCoax, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE) 
knitr::opts_chunk$set(out.width = "\\textwidth")
```

```{r load-packages05, include = FALSE}
library(papaja)
library(kableExtra)
require(knitr)
#require(citr)
require(bookdown)

# using some functions dplyr, ggpubr, PairedData and sjPlot. Need to be loaded. 
library(tidyverse)
library(afex)
library(PairedData)
library(multcompView)
library(lsmeans)
library(depmixS4)
library(flextable)
library(gridExtra)
library(forcats)
library(ggsignif)


```

```{r analysis-preferences, include = FALSE}
# Seed for random number generation
set.seed(42)
options(tinytex.verbose = TRUE)
```

# Introduction

Determining the other's goals, intentions, and decision-making process is fundamental to successful social interaction. This inference is however fraught with uncertainty, as we cannot directly observe these features, and may need extensive prior knowledge of the person. Absent a history of interaction, one may decide to trust the other's goals and intentions are aligned with one's own. The challenge of trust is that it is by construction a risky endeavour. If we deem a person trustworthy, we might take the risk of investing in the relationship, hoping for a collaborative outcome. If this trust is misplaced, it can come at a high cost. Not trusting others is also risky since opportunities for cooperation may be foregone.

<!-- and any substitution for trust, such as excessive suspicion, over-reliance on self and other maladaptive strategies are likely to add burden and costs to a person. -->

Evidence from the literature emphasises the importance of social trust in determining why some people fare better than others physically and mentally [@giordano_trust_2016 ; @meng_multilevel_2014]. It affects the health status of individuals by reinforcing social support networks, maintaining community norms and facilitating collective action. Research into the determinants of psychopathology has linked trust-based constructs to the emergence of mental health disorders. @fonagy_role_2014 identified epistemic trust, or the belief in the authenticity and personal relevance of interpersonally transmitted knowledge, as an important function of early attachment relationships. It allows the individual receiving social information to let go of their natural self-protective vigilance, which can become a pathological hypervigilance frequently observed after traumatic experiences and a key factor for the emergence of multiple mental health disorders [@fonagy_mentalizing_2017].

<!-- A well-established paradigm in the study of the emergence and maintenance of trust is the repeated trust game [@joyce_trust_1995]. In this game, one player takes the role of the "investor" and is provided with a fixed endowment at the start of each trial. They get to decide how much of their endowment to invest with the other player taking the role of the "trustee". The amount that is sent is tripled and the trustee gets to decide, in return, how much of the tripled amount to send back to the investor. If the investor sends a non-zero amount, they express trust in the other player for that round, as the amount they will receive back is uncertain. Assuming the trustee sends back more than the initial investment, they signal trustworthiness to the investor and both players make gains. This scenario would constitute a cooperative exchange and would be mutually beneficial. However, cooperation in this setting is prone to be broken through intentional or simply misinterpreted actions that can convey lack of trust or trustworthiness such as low investments and returns [@bendor_when_1991]. In order to repair a damaged cooperative equilibrium, players need to infer that their behaviour has violated social norms and offer amends through generous actions at potentially a high cost to them. @king-casas_rupture_2008 links the breakdown of cooperation in trustees with Borderline Personality Disorder to the absence or reduction of activation in brain regions associated with the perception of norm violations.  -->

Since a lack of epistemic trust is a risk factor for social dysfunction [@fonagy_mentalizing_2017], and given the importance of trust for building and maintaining strong social bonds, interventions to foster and strengthen trust-based cooperation would be highly beneficial to society. Such interventions would allow people to more easily repair broken relationships, and continue harvesting the benefits of cooperation even in the presence of accidental or intentional social norm violations.

<!-- Mechanism design, pioneered by @vickrey_counterspeculation_1961, is a field that studies incentive alignment and looks for ways to promote social welfare or revenue maximization, despite self-interest of the individual actors. In the context of social dilemmas, key mechanisms were explored with good effect to foster and maintain the cooperative outcome. @axelrod_evolutionary_1986 studied the emergence and stability of behavioral norms to regulate non-cooperative actions in social settings. He identifies a behavioral norm as a dominant behavioural strategy which is often punished by others when not adhered to. A meta-norm is the propensity to incur a cost in order to enforce a norm. @axelrod_evolutionary_1986 showed that when playing a social dilemma game, individuals have a strong incentive to enforce punishment of defectors lest they are in turn punished by others. This led to a decline of defection. Thus, meta-norms can be seen as a mechanism to promote and sustain cooperation in a population. In the context of the trust game, @charness_investment_2008 explored the effect a third party monitor can have on the amounts sent and received. This third-party's payoff is unaffected by the decisions made by the investor and trustee. However, the study allowed the third party to punish overly selfish trustees or reward Investors making a loss on the interaction. They found that the actions of both players were materially more cooperative in the presence of this third party. @fiedler_effect_2017 found that the introduction of a third party that monitors the investments and returns of the players led to more cooperative behavior, even when the third party had no ability to reward or punish the players.  -->

A well-established paradigm in the study of trust is the repeated trust game [@joyce_trust_1995]. In this game, the "investor" decides how much of an endowment to send to the other player (the "trustee"). The amount that is sent is tripled and the trustee decides, in return, how much of the tripled amount to send back to the investor. To encourage the emergence and maintenance of trust in this setting, some studies focused on modifying the game mechanism, for example by introducing a third-party who monitors the actions of the other players [@charness_investment_2008; @fiedler_effect_2017]. Others chose to intervene directly on the participants. For example, @drazkowski_gratitude_2017 found that trust was increased when participants were asked to think about and write down five things that they were grateful for. @burnham_friend-or-foe_2000 found that trust was also increased when participants were primed with the concepts of friend and foe. 

Whilst these interventions show that it is possible to improve cooperative outcomes at the start of the game, they do not address how to repair a breakdown of trust that might occur due to intentional or accidental non-cooperative actions by the players. Cooperative play in the repeated trust game can easily break down when there is a transgressive behavior, such as a nil or very low investment by the investor or a return of the trustee below the investment sent [@bendor_when_1991]. Such ruptures of cooperation appear frequently when the trustee suffers from social disorders such as Borderline Personality Disorder [BPD; @lieb_borderline_2004]. In theses situations, BPD trustees fail to engage in trust repairing behaviours such as coaxing the investor by signalling trustworthiness via sending high returns. This failure may be linked to the misperception that their low returns in the game are not violating social norms [@king-casas_rupture_2008].

In devising potential interventions to repair trust, we can derive inspiration from the cognitive interventions championed by successful psychological therapies that aim to improve aspects of social dysfunction in BPD patients. Whilst there is no proven pharmacological therapy for BPD, psychotherapies such as Mentalisation Based Therapy [@allen_handbook_2006-1] and Dialectical Behavior Therapy [@linehan_cognitive-behavioral_1993] have been shown to improve various dysfunctional behaviors in BPD patients, including those related to social interaction [@gunderson_borderline_2018]. However, response to these treatments is highly variable, and determining which interventions are effective for particular patients is challenging [@rudge_mechanisms_2020; @arch_longitudinal_2012]. One promising approach is the study of how specific components of psychotherapeutic treatment affect quantitative markers of behaviour such as those inferred through computational models [@huys_computational_2016; @reiter_neuro-cognitive_2021]. Combining the use of specific cognitive probes inspired by therapeutic interventions and computational models of behaviour may allow us to uncover the cognitive mechanisms targeted by common forms of psychotherapy. In turn, this may provide the basis for choosing effective psychotherapeutic interventions for given individuals.

In this study, we assess the effectiveness of a cognitive intervention aimed at repairing the potential breakdown of cooperation from a one-off low investment sent by an computerised investor. The intervention focuses on explaining the potential harm from reciprocating non-cooperative actions and suggesting a non-impulsive course of action to coax the investor back into cooperation. Participants are given the role of the trustee and are randomly assigned to either a control or intervention group. They play two instances of the repeated trust game with two different investors. After the first instance of the game, they either receive a cognitive intervention (intervention condition) or perform an unrelated task solving anagrams (control condition). In reality, participants face the same computerised agent in both instances, which is programmed to play according to a hidden Markov model fitted to real players' data. We explore whether the intervention has an effect on the behaviour of the human trustee and whether this effect transfers to a different game (repeated Prisoner's Dilemma) and facing a seemingly new player.


```{r dataLoad, include=FALSE }
d_finished <- readRDS("data/d_finished.RDS")
```


# Method

## Participants and Design

A total of 318 participants were recruited on the Prolific Academic platform (prolific.co). The mean age of participants was `r round(mean(as.numeric(d_finished$exitSurvey.age), na.rm=TRUE),1)` years. Participants were paid a fixed fee of £5 plus a bonus payment dependent on their performance.<!--MS: state average bonus--> The experiment had a 2 (Condition: Intervention or Control) by 3 (Game: Trust-Game Pre Intervention, Trust-Game Post Intervention, Prisoner's Dilemma Post Intervention) design, with repeated measures on the second factor. Participants were randomly assigned to one of the two levels of the first factor.

## Tasks and Measures

### Repeated Trust Game

Participants played a 15-round repeated trust game [@joyce_trust_1995] in the trustee role against a computer-programmed investor. On each round the investor was endowed with 20 units and decided how much of that endowment to invest. This investment is tripled and the trustee then decides how to split this amount between them and the investor. If the trustee returns more than one third of the amount, the investor makes a gain. The Nash equilibrium for a single-round version is for the investor to send nothing. In the repeated version, rewards for both players are maximised if they build trust and share the benefits of the the investment multiplied by three. An investor who has been rewarded for taking the risk of sending an investment is more likely to invest more on future rounds. An investor obtaining a low return on their investment may choose to reduce future investment and thereby reduce both players’ gains.

```{r, include=FALSE}
Anti_social <-  c(0.1025436430408, 0.1221931236853, 0.1345215238995,
0.1368182252617, 0.1285592471751, 0.1116014322677, 0.0895041220882,
0.0663166721334, 0.0453950277118, 0.0287077419587, 0.0167723588011,
0.0090530028158, 0.0045143317507, 0.0020796744990, 0.0008851094702,
0.0003480141146, 0.0001264134789, 0.0000424213859, 0.0000131513231,
0.0000037665630, 0.0000009965755)

Neutral <- c(0.003393529, 0.006930874, 0.013053553, 0.022671228,
0.036310144, 0.053627606, 0.073039389, 0.091734929, 0.106248217,
0.113479701, 0.111769796, 0.101517390, 0.085028780, 0.065675083,
0.046778251, 0.030725245, 0.018610323, 0.010394861, 0.005354126,
0.002543094, 0.001113881)

Pro_social <- c(0.003162697, 0.001057162, 0.001410197, 0.001881016,
0.002508877, 0.003346113, 0.004462480, 0.005950950, 0.007935434,
0.010581067, 0.014107909, 0.018809194, 0.025075644, 0.033427845,
0.044559370, 0.059394206, 0.079163228, 0.105506029, 0.140606514,
0.187373417, 0.249680651)

investment <- seq(0:20) -1

response_probs <- as.data.frame(cbind(investment,Anti_social,Neutral,Pro_social)) %>% 
  rename("low-trust" = "Anti_social", "medium-trust"="Neutral", "high-trust" = "Pro_social") %>%
  pivot_longer(cols=c("low-trust","medium-trust","high-trust"),
                    names_to='Investor_state',
                    values_to='probability') %>% 
   mutate(across(Investor_state, factor, levels=c("low-trust","medium-trust","high-trust")))
```

```{r, include=FALSE}

plotinvHMM <- ggplot(response_probs,                            
       aes(x = investment,
           y = probability,
           fill = Investor_state)) +
  geom_bar(stat = "identity",
           position = "dodge") + 
  labs(fill='Latent investor state') + 
  theme_bw() + 
  theme(legend.position = "bottom")
  

```

```{r, include=FALSE}

unhappy_pars <- rbind(c(3.5435248 , 0.0592584), c(0.1611541, 0.4675468), c(0,0)) 
neutral_pars <- rbind(c(0.8846036, - 0.4394031), c(2.4214322, - 0.0710711), c(0,0))
happy_pars <- rbind(c(-2.004988 ,- 0.151186), c(-1.2976976 , - 0.1357088), c(0,0))

pars_inv <- list(unhappy_pars, neutral_pars, happy_pars)

plot_HMM_transitions <- function(ns, pars_mat) {

  trans_prob <- data.frame(
    from = rep(1:ns, each=100*ns),
    to = rep(1:ns, each=100),
    ret = seq(-20,60,length=100),
    probs = 0
  )
  
  
  y <- matrix(0.0,ncol=ns, nrow=100)
  
  for(from in 1:ns) {
  pars <- matrix(pars_mat[[from]], ncol=2)
  # print(pars)
  
    for(to in 1:ns) {
        x <- trans_prob[trans_prob$from == from & trans_prob$to == to,"ret"]
        y[,to] <- exp(pars[to,1] + pars[to,2]*x)
    }
    y <- y/rowSums(y)

    
    for(to in 1:ns) {
      trans_prob$probs[trans_prob$from == from & trans_prob$to == to] <- y[,to]
    }
  }
  
  df <- as.data.frame(trans_prob) %>% 
    mutate(from = recode(from, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust"),
           to = recode(to, "1" = "low-trust", "2" = "medium-trust", "3" = "high-trust") ) %>% 
    mutate(across(from, factor, levels=c("low-trust","medium-trust","high-trust"))) %>% 
    mutate(across(to, factor, levels=c("low-trust","medium-trust","high-trust")))
                                    
  
  ggplot(df,aes(x=ret,y=probs, colour = as.factor(to))) + geom_line() + facet_wrap(~from) + ylim(c(0,1)) +  labs(x = "Investor's Net Return", y = "Transition probability", color='State Transitioned to') + 
    theme_bw() + theme(legend.position = "bottom")


}

```

```{r, include=FALSE}

plotInvTran <- plot_HMM_transitions(3, pars_inv) 

```


```{r HMMPanels, fig.cap="A: Distribution of investments by the artificial investor agent conditional on its latent state as estimated by a three state hidden Markov model fitted to human dyadic play dataset. B: Transition function for the HMM investor conditional on its current state and the net return from the previous round of play.", fig.align="center"}

ggpubr::ggarrange(plotinvHMM , plotInvTran, nrow=2, ncol=1, labels = c("A", "B"), common.legend = TRUE, legend = "bottom")

```

The strategy of the computerised investor was modelled on behaviour of human investors in a 10-round RTG <!-- reference to data -->.  Using this data, we estimated a hidden Markov model (HMM) on investors' behaviour with three latent states, reflecting "low-trust", "medium-trust", or "high-trust". Each latent state was associated with a distribution over all possible investor actions (from 0 to 20 investment) that reflected the amount of trust (Figure \ref{fig:HMMPanels}.A). Over rounds, the investor can move between states, and the probability of these transitions was modelled as a function of the net return in the previous round (see Figure \ref{fig:HMMPanels}.B).

In order to probe efforts to repair trust, the computerised agent was programmed to provide a low investment on round 12 pre-intervention and 13 post-intervention. On all other rounds, the agent's actions were derived from the HMM (disregarding the participant's response on pre-programmed low investment rounds).

### Repeated Prisoner's Dillema

Participants played 7 rounds of a repeated Prisoner's Dilemma. In each round, participants could choose between: a cooperative action with a reward of 5 if the player also cooperated and a reward of 1 if not, or a non-cooperative action that would yield a 7 points if the other person chooses the cooperative action and 2 points if not. The Nash equilibrium for a single-round version is to choose the non-cooperative action.

The computerised agent was programmed to act according to a tit-for-tat strategy [@axelrod_evolution_1981], starting with a cooperative action and then mirroring what the other player chose in the preceding round. On round 4, the agent was pre-programmed to choose the defect action, regardless of the participant's preceding action. 

## Intervention

The intervention was built on interventions from DBT skills training, asking patients to reflect on the consequences of actions taken in emotional states [@linehan_dbt_2015]. Specifically, participants were presented with a low investment and asked to indicate their response. They were then invited to consider what their ultimate aim in the game was and whether this response was most likely to achieve their aim. The intervention is detailed in the supplementary information.

In the control condition, participants were asked to solve five anagrams ("listen", "triangle", "deductions", "players", "care"). They provided their answers in a free-form text box. The time given to solve the anagrams was the same as that given to respond to questions in the intervention manipulation.

## Procedure

```{r timeline, fig.cap = "Experiment overview. After playing 15 rounds of a repeated trust game (RTG) as trustee, participants were randomized to either receive the control or active intervention. They then played the second set of 15 rounds of RTG (again as trustee) to examine intervention effects, and 7 rounds of a repeated Prisoner’s Dilemma to examine generalization of intervention effects. Finally, participants answered questionnaires and were debriefed.", fig.align='center', out.width="80%"}

knitr::include_graphics("figures/timeline.png")

```


<!-- Figure \ref{fig:timeline} shows the timeline of the experiment. After reviewing an information sheet about the experiment, participants were informed that there would be three phases to go through, with them facing a different opponent in each phase. They would face the same player throughout the first phase, consisting of the "Investment Game" with several rounds. This was the moniker used for the repeated trust game, and a total of 15 rounds were played. Participants were then randomly assigned to either a control or intervention condition. -->

<!-- <!-- After reading instructions on how to play the trust game, players were told that they would be assigned the role of the trustee.  A comprehension quiz on the trust game followed the instructions. The first trust game then ensued:  Each round started with an investment stage where the investor decided how much to send to the trustee and that choice was revealed. Immediately afterwards, participants were presented with a two-dimensional field to indicate their emotional state on two dimensions: valence, from unpleasant to pleasant (on the horizontal axis) and arousal, from low arousal to high arousal (on the vertical axis). After selecting a point on the field, participants were asked to decide how much to send back to the investor using a slider ranging from sending back nothing to sending back the whole (tripled) investment. Following that choice, an outcome page summarised both players decisions and showed the total pay-off for each player and the round then concluded. At the end of the game, participants were asked to rate the player they were facing on 4 attributes using a scale from 1 to 10: Trustworthiness, friendliness, cooperativeness and selfishness. -->

<!-- In the second phase of the experiment, participants were informed they would be paired with a different player. This phase was similar to the first phase in terms of the game played (RTG) and the number of rounds. In all rounds of the RTG, participants gave feedback after seeing the investment received. This feedback was given though a two dimensional grid that was either related to their emotional state (degree of valence of arousal) in the Intervention group, or unrelated to the emotional state in the control group (speed of investor's response and magnitude of investment). At the end of each RTG, participants were asked to rate how cooperative, selfish, trustworthy and friendly they thought their interaction partner was. Details of the two dimensional grid and player ratings are given in the supplement. -->

<!-- After both trust games,  players were told they would be paired with a new player in the third phase of the experiment. This third phase consisted of 7 rounds of the prisoner's dilemma game, facing the new player. Throughout all games, players were explicitly told to aim to maximise the number of points as their bonus would depend on the score they accumulated throughout the experiment. The total number of rounds was not communicated to the participants in any of the games played. -->

<!-- After the three phases were completed, participants were asked to complete a series of questionnaires at the end of the experiment.  -->

<!-- <!-- These included: the PAI-BOR measuring Borderline traits [@morey_personality_1991], the DERS measuring Emotion Regulation ability [@gratz_multidimensional_2004] and the RFQ8 for mentalising abilities [@fonagy_development_2016].  -->

<!-- Finally, participants were asked a series of questions around how they played each phase. First, they were asked whether they thought they played differently in the second compared to the first phase of the RTG. Second, participants had to select whether they thought the opponents they faced were human or computer agents. Finally, we revealed to the participants that they faced the same computer agent throughout the RTG. We explained that any change in their perception of the opponent or any change in how the opponent played is due to their own change in behavior as the agent was simply reacting to their actions. Finally, we asked participants to reveal whether this experiment has taught them anything about how they should behave in social situations. -->

At the start of the experiment (Figure \ref{fig:timeline}), participants provided informed consent and were instructed the study would consist of three phases in which they would face a different other player. Participants were told their goal was to maximise the number of points in all phases. They were not told the number of rounds of each phase. Phase one was a 15 round repeated Trust Game (RTG) in which participants took the role of trustee, facing the same investor over all 15 rounds. On each round, after being informed about the amount sent by the investor, participants were asked to provide feedback, with participants in the Intervention condition rating their feeling in terms of valence (from negative to positive) and arousal (from low to high), and participants in the Control condition rating the investment in terms of speed (from slow to fast) and magnitude (from low to high). These ratings were made by indicating a point on a two-dimensional grid. Participants then decided on how much of the tripled investment to return to the investor, before continuing to the next round. After completing 15 rounds of the RTG, participants rated how cooperative, selfish, trustworthy and friendly they perceived their interaction partner (all on a scale from 1 to 10). After phase one, participants in the intervention condition completed the intervention, and participants in the control condition solved anagrams. Subsequent phase two was similar to phase one, with participants being told they would face a new player. Phase three consisted of 7 rounds of the repeated prisoner's dilemma game (RPD), with participants informed they would face a third player. Participants then completed questionnaires related to mentalising abilities, emotion regulation, and BPD traits (see the supplement for details). They were then asked about the strategy in the games, as well as whether they thought the other players were human or computer agents. They were then debriefed and thanked for their participation. 

## Statistical analysis

To explore whether participants behaved differently after the intervention compared to the control group over all rounds, we estimate a linear-mixed effects model as implemented in the R package "afex" [@singmann_afex_2022], with fixed effects for Condition (intervention or control), Game-number (pre- or post-intervention) and Investment, as well as interactions between Condition and both Investment and Game-number, and participant-wise random intercepts and random slopes for Game-number. More complex models with additional random effects provided could not be estimated reliably. For the $F$-tests, we used the Kenward-Roger approximation to the degrees of freedom, as implemented in the R package "afex". We Z-transform the Investment variable as centering is beneficial to interpreting the main effects more easily in the presence of interactions.

To model participants' returns in the RTG across games and conditions, we fit various hidden Markov models to participants' returns using the depmixS4 package [@visser_depmixs4_2021] for R. The transition between latent states is assumed to depend on the investment received and a dummy variable to characterise the group that the participant belongs to. Details on how the models are constructed can be found in the supplement. We fit models with different numbers of hidden states, and use the Bayesian Information Criterion [@schwarz_estimating_1978-1] to select the best model.

# Behavioural results


```{r dataClean, include=FALSE}
# Filter only trust rounds and create % returns and investments 

avg_ret_df <- d_finished %>%
  dplyr::select(id, condition.f,roundType,investment,returns,roundNum,gameNum.f,BPD_trait,PBOR_score,DERS_score,RFQ_c,RFQ_u) %>% 
  mutate( condition.f = fct_recode(condition.f, "intervention" = "coaxing"))%>%
  filter(roundType=="trust",!is.na(roundNum)) %>% 
  mutate(roundNum = as.numeric(as.character(roundNum))) %>%
  mutate(inv_scaled = scale(investment)) %>% 
  mutate(inv_pct = investment/20, ret_pct = returns/(3*investment), ret_pct_0 = ifelse(investment==0,0,returns/(3*investment)))  %>% 
  # Creating Quartiles of % returns by participant over BOTH TRUST GAMES
  group_by(id) %>% 
  mutate(mean_pct_ret = mean(ret_pct), mean_abs_ret = mean(returns), mean_inv = mean(investment)) %>%
  ungroup() %>% 
  mutate(Quart_pct_ret = ntile(mean_pct_ret,4),
         Quart_abs_ret = ntile(mean_abs_ret,4),
         Quart_inv     = ntile(mean_inv, 4)) 

# %>%
#   filter(complete.cases(.))   # <- one player had NA in one round as a return, so we exclude him from analysis. 


# Number of people left for analysis. 
nrow(avg_ret_df %>% filter(condition.f == "intervention"))/30
nrow(avg_ret_df %>% filter(condition.f == "control"))/30

# average investment for first 10 rounds pre intervention
avg_pct <- avg_ret_df %>% filter(roundNum < 11 , gameNum.f == "pre") %>% summarise(avg_inv = mean(inv_pct), avg_ret = mean(ret_pct, na.rm=TRUE))
```



```{r gamesPlot, echo=FALSE, fig.cap="Average and standard errors of the trustee's return as a percentage of the multiplied investment received for each round and for both conditions. The red line shows the returns pre-manipulation and the blue line post-manipulation.We note a different reaction to the pre-programmed one-off low investment between the two conditions: Whilst there is a dip in returns pre-manipulation for both conditions,  post manipulation we see higher returns in the intervention condition compared to the dip in returns seen in the control condition in the right panel",fig.align="center", fig.width=6, fig.height = 4}

# colors <- c("investment" = "blue", "returns" = "red")
# 
# ggplot(avg_ret_df,aes(x=as.factor(roundNum),group = 1)) +
#   stat_summary(fun = "mean", geom = "line", aes(y=returns, color ="returns")) +
#   stat_summary(fun.data = "mean_se", geom = "errorbar", alpha =0.3, width = 0.2, aes(y=returns) ) +
#   stat_summary(fun = "mean", geom = "line", alpha =0.4,aes(y=investment, color = "investment")) +
#   stat_summary(fun.data = "mean_se", geom = "errorbar", alpha =0.3, width = 0.2, aes(y=investment) ) +
#   facet_wrap(~condition.f*gameNum.f) +
#   labs(x = "Round",
#        y = "Investment / Return",
#        color = "Legend") +
#   scale_color_manual(values = colors) +
#   theme_bw() +
#   theme(legend.position = "bottom") 

# Alternative chart with pre vs post percentage returns in one panel as suggested by QH.

ggplot(avg_ret_df ,aes(x=as.factor(roundNum),group=gameNum.f, color = gameNum.f)) +
  stat_summary(fun = "mean", geom = "line", aes(y=ret_pct)) +
  stat_summary(fun.data = "mean_se", geom = "errorbar", alpha =0.3, width = 0.2, aes(y=ret_pct) )+
  labs(x = "Round",
       y = "Percentage Return",
       color = "Game") +
  # ylab("Percentage Return") +
  # xlab("Round") +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(~condition.f)

```


```{r, include=FALSE, cache=TRUE}

mod_returns_pct <- mixed( ret_pct ~ gameNum.f*condition.f*inv_scaled+ (1 + gameNum.f| id), avg_ret_df, REML= TRUE, method="KR")
anova(mod_returns_pct)
summary(mod_returns_pct)


prepost_bycond <- pairs(emmeans::emmeans(mod_returns_pct, c("gameNum.f"), by = "condition.f", pbkrtest.limit = 9400))

cond_effect <- pairs(emmeans::emmeans(mod_returns_pct, c("condition.f"), by="gameNum.f"))
```

```{r, include=FALSE}
pctRet_all <- afex::afex_plot(mod_returns_pct, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
            mapping = c("linetype", "shape", "fill"),
            data_geom = geom_violin, 
            data_arg = list(width = 0.5),
            factor_levels = list(gameNum.f = c("Pre", "Post")), legend_title = "Condition") + 
  theme_bw() + 
  labs(y = "Percentage Return", x = "Game") + 
  ggtitle("All rounds percentage returns") + 
  theme(plot.title = element_text(size = 10)) +
  theme(legend.position = "bottom") 
            
```


<!-- MS: double check statistics; I get different df when using KR in mixed -->

Average investments and returns prior to the "defection round" (Figure \ref{fig:gamesPlot}) were within the range of reported investments (40-60% of endowment) and returns (35-50% of total yield) in the literature [@charness_investment_2008; @fiedler_social_2011]. 
Mixed-effects analysis on the returns shows a significant main effect of Condition (intervention vs. control), `r papaja::apa_print(mod_returns_pct)$full_result$condition_f`<!--$F(1,315.31) = 9.52$, $p = .002$-->, with higher percentage returns in the intervention compared to the control condition. Importantly, we also find an interaction between Condition and Game (RTG pre- vs. post-intervention), `r papaja::apa_print(mod_returns_pct)$full_result$gameNum_f_condition_f`<!--$F(1,314.2) = 26.9$, $p < .001$-->. Post-hoc tests show an increase in the percentage returned in the intervention condition, pre - post, `r papaja::apa_print(prepost_bycond)$full_result$Intervention_Pre_post`, but a decrease in the control condition, `r papaja::apa_print(prepost_bycond)$full_result$Control_Pre_post` (see Figure \ref{fig:violinPanels}.A). This indicates the intervention was effective in increasing cooperative behaviour. There was also a significant main effect of Investment, `r papaja::apa_print(mod_returns_pct)$full_result$inv_scaled`<!--$F(1,9208) = 373.6$, $p < 0.001$-->, such that higher investments were associated with higher percentage returns. An Investment by Condition interaction, `r papaja::apa_print(mod_returns_pct)$full_result$condition_f_inv_scaled`<!--$F(1,9207) = 45.38$, $p < .001$-->, indicates the positive effect of investment on percentage returns was greater in the control than intervention condition. <!-- This suggests that the higher returns we see in the intervention group are not simply due to higher investments.--> There was also an Investment by Game interaction, `r papaja::apa_print(mod_returns_pct)$full_result$gameNum_f_inv_scaled`. Finally, we find a three way interaction between Game, Condition and Investment, `r papaja::apa_print(mod_returns_pct)$full_result$gameNum_f_condition_f_inv_scaled`<!--($F(1,8988)= 24.6, p < 0.001$),-->, showing that the differentiated effect of the investment on the proportion returned by condition is itself moderated by the Game (pre- vs post intervention).



```{r, include=FALSE, cache=TRUE}
mod_invs <- mixed( investment ~ gameNum.f*condition.f  + (1 + gameNum.f| id), avg_ret_df, method="KR")
summary(mod_invs)
anova(mod_invs)

#cond_effect_inv <- pairs(emmeans::emmeans(mod_invs, c("condition.f"), by = "gameNum.f", pbkrtest.limit = 9570))

# pairs(emmeans::emmeans(mod_invs, c("condition.f"), by = "gameNum.f" ))
# 
# pairs(emmeans::emmeans(mod_invs,c("gameNum.f") , by = c("condition.f")))
# 
# pairs(emmeans::emmeans(mod_invs, c("gameNum.f")))
# pairs(emmeans::emmeans(mod_invs, c("condition.f")))

 
```

```{r, include=FALSE}

inv_all <- afex_plot(mod_invs, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
            mapping = c("linetype", "shape", "fill"),
            data_geom = geom_violin,
            data_arg = list(width = 0.5),
            factor_levels = list(gameNum.f = c("Pre", "Post")), 
            legend_title = "Condition") + 
  theme_bw() + 
  ggtitle("All rounds investments") +
  labs(y = "HMM Investment", x = "Game") + 
  theme(plot.title = element_text(size = 10)) +
  theme(legend.position = "bottom")
          

```

We next analysed HMM agent investments with a linear-mixed effects model with fixed effects for Condition (intervention vs control), Game (pre vs post intervention), as well as interaction between Condition and Game, and participant-wise random intercepts and random slopes for Game. This shows a main effect of Condition, `r papaja::apa_print(mod_invs)$full_result$condition_f`<!--$F(1,317) = 8.7$, $p = .003$-->, and Game, `r papaja::apa_print(mod_invs)$full_result$gameNum_f`<!--$F(1,317) = 8.3$, $p = .004$-->. As can be seen in Figure \ref{fig:violinPanels}.B, investment was higher in the intervention compared to the control condition across games, and higher in the second game compared to first across conditions.


```{r, include=FALSE, cache=TRUE}
# ALL ROUNDS BEFORE DEFECTION TRIAL
pre_int_data <- avg_ret_df %>% filter(roundType=="trust",!is.na(gameNum.f),(roundNum < 12 & gameNum.f =="pre")| (roundNum < 13 & gameNum.f =="post"))

mod_returns_pre <- mixed( ret_pct ~ gameNum.f*condition.f*inv_scaled+ (1 + gameNum.f| id), pre_int_data, REML= TRUE, method="KR")
anova(mod_returns_pre)
summary(mod_returns_pre)


pairs_pre_int <- pairs(emmeans::emmeans(mod_returns_pre, c("gameNum.f"), by = "condition.f", pbkrtest.limit = 9400, reverse=TRUE))

```

We next analysed returns separately for rounds prior to the pre-programmed transgression (rounds 1 to 11 pre-intervention and 1 to 12 post-intervention) and rounds after (rounds 12 to 15 pre-intervention and rounds 13 to 15 post-intervention). Applying the same mixed effects model as before to returns before the transgression largely replicates the results over all trials. Participants in the intervention condition increased their returns in the second game, `r papaja::apa_print(pairs_pre_int)$full_result$Intervention_Pre_post`. There was no evidence that participants in the control condition changed their returns in pre-transgression trials between the first and second RTG, `r papaja::apa_print(pairs_pre_int)$full_result$Control_Pre_post`. Full results are provided in the supplement.


```{r, include=F}
pctRet_pre <- afex_plot(mod_returns_pre, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
            mapping = c("linetype", "shape", "fill"),
            data_geom = geom_violin,
            data_arg = list(width = 0.5),
            factor_levels = list(gameNum.f = c("Pre", "Post")), 
            legend_title = "Condition") + 
  theme_bw() + 
  labs(y = "Percentage Return", x = "Game") + 
  ggtitle("Pre defection trials percentage returns")+
  theme(plot.title = element_text(size = 10)) +
  theme(legend.position = "bottom")
```

```{r, include =FALSE}

# Defection trial only 
coax_data <- avg_ret_df %>%  filter(roundType=="trust",!is.na(gameNum.f),(roundNum == "12" & gameNum.f =="pre")| (roundNum == "13" & gameNum.f =="post"))

coax_data %>% group_by(gameNum.f, condition.f) %>% summarise(avg_inv = mean(investment),avg_return = mean(returns))


# ALL ROUNDS AFTER DEFECTION TRIAL (INCLUSIVE)
post_coax_data <- avg_ret_df %>% filter(roundType=="trust",!is.na(gameNum.f),(roundNum >= 12 & gameNum.f =="pre")| (roundNum >= 13 & gameNum.f =="post"))

post_coax_data %>% group_by(gameNum.f, condition.f) %>% summarise(avg_inv = mean(investment),avg_return = mean(returns))


```

```{r, include=FALSE, cache=TRUE}

mod_postcoax_trust <- mixed(ret_pct ~ gameNum.f*condition.f*inv_scaled  + ( 1 + gameNum.f|id), post_coax_data)
anova(mod_postcoax_trust)


postcoax_bygame <- emmeans::emmeans(mod_postcoax_trust, ~gameNum.f, pbkrtest.limit = 9400)
postcoax_bycond <- emmeans::emmeans(mod_postcoax_trust, ~condition.f, pbkrtest.limit = 9400)

postcoax_interaction <- emmeans::emmeans(mod_postcoax_trust, c("gameNum.f"), by = "condition.f", pbkrtest.limit = 9400)
postcoax_interaction

pairs(emmeans::emmeans(mod_postcoax_trust, c("gameNum.f"), by = "condition.f"))
```

```{r, include=FALSE}
pctRet_post <- afex_plot(mod_postcoax_trust, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
            mapping = c("linetype", "shape", "fill"),
            data_geom = geom_violin,
            data_arg = list(width = 0.5),
            factor_levels = list(gameNum.f = c("Pre", "Post")), 
            legend_title = "Condition") + 
  theme_bw() + 
  labs(y = "Percentage Return", x = "Game") + 
  ggtitle("Post defection trials percentage returns")+
  theme(plot.title = element_text(size = 10)) +
  theme(legend.position = "bottom")
```

```{r violinPanels, fig.cap="A: Marginal means and distributions of percentage trustee returns over all rounds, shown across participants by Game number and Condition. B: Marginal means and distributions of investments over all rounds for HMM investors, by Game number and Condition. C: Marginal means and distributions of percentage trustee returns across all participants for pre-defection trials only, by Game number and Condition. D: Marginal means and distributions of percentage trustee returns across all participants for post-defection trials only, by Game number and Condition.", fig.align="center", fig.width=6, fig.height = 6}

ggpubr::ggarrange(pctRet_all, inv_all, pctRet_pre, pctRet_post, nrow=2, ncol=2, labels = c("A", "B", "C", "D"), common.legend = TRUE, legend = "bottom")
```


Applying the same model to the returns after the transgression (see the supplement for full results), we again find a significant interaction between Condition and Game. Participants in the control condition decreased their post-transgression returns from the first to the second RTG, `r papaja::apa_print(pairs(postcoax_interaction, by = "condition.f", reverse=FALSE))$full_result$Control_Pre_post`. There was no significant change for participants in the intervention condition, `r papaja::apa_print(pairs(postcoax_interaction, by = "condition.f", reverse=FALSE))$full_result$Intervention_Pre_post`. When questionnaire scores for borderline traits, mentalising and emotion regulation abilities were added as explanatory variables, we found no interaction effect of these questionnaire scores with the Condition variable, nor a main effect of the questionnaire scores on participants returns in the RTG.

Taken together, we find that participants in the control condition sent lower percentage returns in the second game, despite the HMM investor sending on average higher investments in the second game. Those in the intervention group returned higher percentage returns in the second game, with the investor also sending higher investments. These higher returns in the intervention compared to the control condition were not purely driven by reciprocity towards higher investments, since we found a Condition by Game interaction whilst controlling for investment in the model, and a reduced effect of investment in the intervention condition. Whilst the intervention increased participants returns overall, it did not appear to increase participants' returns after the transgression by the other player. However, it may have countered the tendency to lower returns after the transgression in the second game compared to the first game, which was shown by participants in the control condition. 


## Emotion self-reports

```{r, include=TRUE}

# Get Emotions on x axis per round (valence)
emo.x <- d_finished %>% 
  mutate( condition.f = fct_recode(condition.f, "intervention" = "coaxing")) %>% 
  dplyr::select(id,roundType,condition.f,contains("emotionGrid")) %>% 
  dplyr::filter(roundType=="trust") %>% dplyr::select (-contains(".y") ) %>% pivot_longer(cols=contains(".x"), names_to = c("gameNumber","roundNum"), names_pattern ="return_trust_emotionGrid_(.*)_(.*)[.]x", values_to = "emo_coord_x") %>%
  distinct()  


#Get emotions on y axis (arousal)
emo.y <- d_finished %>%
  mutate( condition.f = fct_recode(condition.f, "intervention" = "coaxing")) %>%
  dplyr::select(id,roundType,condition.f,contains("emotionGrid")) %>% 
  dplyr::filter(roundType=="trust") %>% dplyr::select(-contains(".x") ) %>% pivot_longer(cols=contains(".y"), names_to = c("gameNumber","roundNum"), names_pattern ="return_trust_emotionGrid_(.*)_(.*)[.]y", values_to = "emo_coord_y") %>%
  distinct()  


# put emotions in one dataframe
full_emo <- full_join(emo.x,emo.y, by=c("id", "gameNumber","roundNum","roundType", "condition.f"))  %>% 
  mutate(roundNum=as.numeric(as.character(roundNum))) %>% 
  mutate(gameNum.f = factor(gameNumber,labels = c("pre","post"),levels=c("1","2"))) %>% 
  dplyr::select(-c("roundType","gameNumber")) %>% 
  # group_by(condition.f) %>% 
  mutate(emo_scaled_x = scale(emo_coord_x), emo_scaled_y= -scale(emo_coord_y))    # <--- SCALING and reversing Y coordinates (0,0 is top left)
  

#merge with returns dataframe
full_dat <- full_join(avg_ret_df, full_emo, by = c("id","condition.f","gameNum.f","roundNum" )) %>% filter(complete.cases(.))
#nrow(full_dat)

datCoax <- full_dat %>% filter(condition.f=="intervention")
datCtrl <- full_dat %>% filter(condition.f=="control")

```

```{r emoPlotCoax, fig.cap="Self-reported emotion valence and arousal as well as investment z-scores for each round of the repeated Trust Game averaged across participants in the intervention condition only.",fig.align="center", fig.width=6, fig.height = 4}

#################### two panels for before and after defection 
library(ggplot2)

# Define the colors in alphabetical order
colors <- c("Arousal" = "green", "Investment" = "blue", "Valence" = "red")

# Create a new variable to categorize the rounds
datCoax$roundGroup <- ifelse(datCoax$roundNum <= 10, "Rounds 1-10", "Rounds 11-15")

# p <- datCoax %>%
#   ggplot(aes(x=roundNum)) + stat_summary(fun = "mean", geom = "line", aes(y=emo_scaled_x, color = "Valence")) + stat_summary(fun = "mean", geom = "line", aes(y=emo_scaled_y, color = "Arousal")) + stat_summary(fun = "mean", geom = "line", aes(y=inv_scaled, color = "Investment")) + facet_wrap(~gameNum_f, scales = "free_x") 
               


# Plot 'pre'
p <- ggplot(datCoax[datCoax$gameNum.f == 'pre', ], aes(x=roundNum)) + 
  stat_summary(fun = "mean", geom = "line", group =1, aes(y=emo_scaled_x, color = "Valence", linetype = "a_Pre")) + 
  stat_summary(fun = "mean", geom = "line", group =1, aes(y=emo_scaled_y, color = "Arousal", linetype = "a_Pre")) + 
  stat_summary(fun = "mean", geom = "line", group =1, aes(y=inv_scaled, color = "Investment", linetype = "a_Pre")) +
# Plot 'post'
  stat_summary(data = datCoax[datCoax$gameNum.f == 'post', ], fun = "mean", geom = "line", group =1, aes(x=roundNum, y=emo_scaled_x, color = "Valence", linetype = "b_Post")) + 
  stat_summary(data = datCoax[datCoax$gameNum.f == 'post', ], fun = "mean", geom = "line", group =1, aes(x=roundNum, y=emo_scaled_y, color = "Arousal", linetype = "b_Post")) + 
  stat_summary(data = datCoax[datCoax$gameNum.f == 'post', ], fun = "mean", geom = "line", group =1, aes(x=roundNum, y=inv_scaled, color = "Investment", linetype = "b_Post")) +
  labs(x = "Round", y="Series Z-score") +
  geom_hline(yintercept = 0, linetype="dotted", color = "grey", linewidth=1.5) +
  scale_color_manual(name = " ", values = colors, labels = c("Emotion arousal", "Investment", "Emotion valence")) +
  scale_linetype_manual(values = c("a_Pre" = "dotted", "b_Post" = "solid"), labels = c("Pre", "Post")) +
  scale_x_continuous(breaks = 1:max(datCoax$roundNum)) +
  facet_wrap(~roundGroup, scales = "free_x") +
  theme_bw() + 
  theme(legend.position = "bottom")

# Print the plot
print(p)



```



```{r, include=FALSE}

mod_emo_x <- mixed( emo_scaled_x ~ gameNum.f*scale(investment) + (1 + gameNum.f| id), data=datCoax, method="KR")
summary(mod_emo_x)
anova(mod_emo_x)

modVal <- emmeans::emmeans(mod_emo_x, ~gameNum.f)
pairs(modVal)


mod_emo_y <- mixed( emo_scaled_y ~ gameNum.f*scale(investment) + (1 + gameNum.f| id), datCoax )
summary(mod_emo_y)
anova(mod_emo_y)

modArousal <- emmeans::emmeans(mod_emo_y, ~gameNum.f)
pairs(modArousal)

# afex_plot(mod_emo_x, x = "gameNum.f", trace = "condition.f", dodge = 0.8, error = "within",
#             data_geom = geom_violin, 
#             data_arg = list(width = 0.5))
# 

# library(GGally)
# ggpairs(datCoax %>% dplyr::select(emo_scaled_x,emo_scaled_y,inv_scaled))

cor(datCoax %>% dplyr::select(emo_scaled_x,emo_scaled_y,investment))
cor.test(datCoax$emo_scaled_x, datCoax$emo_scaled_y)
```

Participants in the intervention condition rated their emotion on valence (negative to positive) and arousal (low to high) after each investment. To assess the impact of the intervention on these emotional reactions, we used linear mixed-effects models (one for valence, and one for arousal) with fixed effects for Game (pre vs post intervention) and Investment, as well as interaction between Investment and Game, with participant-wide random intercepts and random slopes for Game. This showed that higher investments were associated with more positive emotions, `r papaja::apa_print(mod_emo_x)$full_result$scaleinvestment`, and higher arousal, `r papaja::apa_print(mod_emo_y)$full_result$scaleinvestment`. <!-- ($F(1,4664) = 2902, p < 0.001$), and higher arousal ($F(1,4668.4) = 1919, p < 0.001$)--> In addition, the positiveness of emotion declined between the two games, `r papaja::apa_print(mod_emo_x)$full_result$gameNum_f`, as did arousal, `r papaja::apa_print(mod_emo_y)$full_result$gameNum_f`. There was no indication that the effect of the investment on either aspect of emotion was affected by the intervention, as there was no interaction between Investment and Game on valence, `r papaja::apa_print(mod_emo_x)$full_result$gameNum_f_scaleinvestment`, or arousal, `r papaja::apa_print(mod_emo_y)$full_result$gameNum_f_scaleinvestment`. This indicates that participants in the intervention condition returned higher amounts post-intervention, despite their emotional reaction to investments remaining largely the same.



## Evaluation of the investor



```{r, include=FALSE}

# Pivot longer ratings on each attribute 
df_coop <- d_finished %>% dplyr::select(id,condition.f,contains("cooperative")) %>%  
  pivot_longer(cols=contains("cooperative"), names_to = c("gameNumber"), names_pattern ="rating_cooperative_(.*)", values_to = "rating_coop") %>% distinct()

df_selfish <- d_finished %>% dplyr::select(id,condition.f,contains("selfish")) %>% 
  pivot_longer(cols=contains("selfish"), names_to = c("gameNumber"), names_pattern ="rating_selfish_(.*)", values_to = "rating_selfish") %>% distinct

df_trustworthy <- d_finished %>% dplyr::select(id,condition.f,contains("trustworthy")) %>% 
  pivot_longer(cols=contains("trustworthy"), names_to = c("gameNumber"), names_pattern ="rating_trustworthy_(.*)", values_to = "rating_trustworthy") %>% distinct() 

df_friendly  <-  d_finished %>% dplyr::select(id,condition.f,contains("friendly")) %>% 
  pivot_longer(cols=contains("friendly"), names_to = c("gameNumber"), names_pattern ="rating_friendly_(.*)", values_to = "rating_friendly") %>%  distinct()  

#merge all data frames together
datRatings <- list(df_coop, df_selfish,df_trustworthy, df_friendly) %>% 
              reduce(full_join, by=c('id','gameNumber','condition.f') ) %>% 
              mutate(gameNum.f = factor(gameNumber,labels = c("pre","post"),levels=c("1","2")))

# Group means for each rating 
mu <- datRatings %>% group_by(gameNum.f, condition.f) %>% summarise(mean_coop = mean(rating_coop),
                                                  mean_selfish = mean(rating_selfish),
                                                  mean_trustworthy = mean(rating_trustworthy),
                                                  mean_friendly = mean(rating_friendly)
                                                  )
```

```{r, include=FALSE}


# Cooperative
coop_mod <- mixed(rating_coop ~ gameNum.f*condition.f + (1 | id), datRatings)
summary(coop_mod)

pairs(emmeans::emmeans(coop_mod, c("gameNum.f"), by = "condition.f"))

#Selfish
self_mod <- mixed(rating_selfish ~ gameNum.f*condition.f + (1 | id), datRatings)
summary(self_mod)
pairs(emmeans::emmeans(self_mod, c("gameNum.f"), by = "condition.f"))

#Trustworthy 
trust_mod <- mixed(rating_trustworthy ~ gameNum.f*condition.f + (1 | id), datRatings)
summary(trust_mod)
pairs(emmeans::emmeans(trust_mod, c("gameNum.f"), by = "condition.f"))


#Friendly
friend_mod <- mixed(rating_friendly ~ gameNum.f*condition.f + (1 | id), datRatings)
summary(friend_mod)
pairs(emmeans::emmeans(friend_mod, c("gameNum.f"), by = "condition.f"))

# Conduction t-tests 
# t.test(rating_coop ~ gameNumber, data = datRatingsCoax, paired = TRUE)
# t.test(rating_selfish ~ gameNumber, data = datRatingsCoax, paired = TRUE)
# t.test(rating_trustworthy ~ gameNumber, data = datRatingsCoax, paired = TRUE)
# t.test(rating_friendly ~ gameNumber, data = datRatingsCoax, paired = TRUE)


```


Participants rated the HMM investor in the second game as less cooperative (`r apa_print(pairs(emmeans::emmeans(coop_mod, c("gameNum.f"))))$full_result`), less trustworthy (`r apa_print(pairs(emmeans::emmeans(trust_mod, c("gameNum.f"))))$full_result`), less friendly (`r apa_print(pairs(emmeans::emmeans(friend_mod, c("gameNum.f"))))$full_result`) and more selfish (`r apa_print(pairs(emmeans::emmeans(self_mod, c("gameNum.f"))))$full_result`), than the HMM investor in the first game. Participants in the intervention condition rated players higher than those in the control condition on cooperativeness (`r apa_print(pairs(emmeans::emmeans(trust_mod, c("condition.f"))))$full_result`) and lower on selfishness (`r apa_print(pairs(emmeans::emmeans(self_mod, c("condition.f"))))$full_result`). There was no evidence for an interaction effect between Condition and Game on any of the attributes.

When asked during debrief whether they thought the investors they faced were Human or not, $40$% of participants thought they were either facing a human or were not sure of the nature of the opponent. Many answers reflected participants projecting human traits such as "spitefulness" or "greed" onto the artificial opponent's behaviour.




## Transfer to the repeated Prisoner's Dilemma game

```{r, include=FALSE}

PD_data <- d_finished %>%
  mutate( condition.f = fct_recode(condition.f, "intervention" = "coaxing")) %>%
  dplyr::select(id, condition.f,roundType,roundNum, PDoption,PDchoice, AiChoicePD,gameNum.f, PBOR_score) %>% 
                          filter(roundType == "PD",!is.na(roundNum)) %>% 
                          dplyr::mutate(coop = ifelse(PDchoice=="cooperate",1,0),phase = ifelse(roundNum <= 4, 0,1)) 

# Average cooperation rates per round
#PD_data %>% group_by(roundNum, condition.f) %>% summarise(coopRate = mean(coop))
```

```{r PDCoop, include=FALSE, fig.cap="Mean and standard error of the rate at which the cooperative action was chosen by the participants for each round of the repeated Prisoner's Dilemma game. Round 4 is where we programmed the Tit-for-Tat agent to defect, which explains the lower cooperation rate we see in round 5 onwards",fig.align="center", fig.width=6, fig.height =3}
# plot of cooperation rates per round
ggplot(PD_data,aes(x=roundNum,group = 1)) + 
  stat_summary(fun = "mean", geom = "line", aes(y=coop), color ="red") + 
  stat_summary(fun.data = "mean_se", geom = "errorbar",alpha =0.3, width = 0.2, aes(y=coop) ) + 
  facet_grid(~ condition.f) +
  xlab("Round") + 
  ylab("Cooperation rate (%)") +
  scale_x_continuous(breaks = round(seq(1,10, by = 1),1)) + 
  theme_bw()

```

```{r, include=FALSE}

ipd_mod <- mixed(coop ~ condition.f * phase + (1 |id), data= PD_data, method = "LRT", family= "binomial") 
summary(ipd_mod)

ipd_mod_r5 <- glm(coop ~ condition.f, data= PD_data%>% filter(roundNum >= 5)) 
summary(ipd_mod_r5)

```

We next asked whether the intervention had any discernible effect on participants' behaviour in a different, repeated Prisoner's Dilemma game. Predicting the probability of a cooperative action with a logistic mixed-effects regression model, with Condition and Phase (before or after defection trial) as fixed effects and a random intercept for participants, showed a decline in cooperation after defection by the other player, `r papaja::apa_print(ipd_mod)$full_result$phase`, but no evidence for a different cooperation rate in the intervention condition compared to the control condition, `r papaja::apa_print(ipd_mod)$full_result$condition_f`, or a different response to defection between the conditions, `r papaja::apa_print(ipd_mod)$full_result$condition_f_phase`. As such, there is no evidence that the intervention affected behaviour in this game. <!-- We also found no difference in cooperation rates post defection trial between conditions.-->


```{r, include=FALSE}
########### HOW DO PBOR SCORES affect returns and intervention effect ?########

avg_ret_df <- avg_ret_df %>% mutate(PBOR_scaled = scale(PBOR_score), DERS_scaled = scale(DERS_score), RFQc_scaled = scale(RFQ_c))

# these are repeated measures here, so not independent. need to used mixed effects model.
mixed_PBOR_pct <- afex::mixed(ret_pct ~ PBOR_scaled*gameNum.f*condition.f + investment + (1 | id ), data= avg_ret_df)
summary(mixed_PBOR_pct)

# At average value of PBOR score  
emmeans(mixed_PBOR_pct, pairwise ~ PBOR_scaled * condition.f )

## Looking at difference between average returns across rounds
#scoreDAT <- avg_ret_df %>% dplyr::select(id,diff_pctRet, PBOR_scaled, DERS_scaled, RFQ_c, condition.f) %>% unique()


```

```{r, include=FALSE}
# Install the 'psych' package
if (!requireNamespace("psych", quietly = TRUE)) {
  install.packages("psych")
}

# Load the 'psych' package
library(psych)

questionnaires <- avg_ret_df %>% group_by(id) %>% dplyr::select(PBOR_score,DERS_score,RFQ_c) %>% unique() %>% ungroup()
# Perform EFA
efa_result <- fa(questionnaires %>% dplyr::select(PBOR_score,DERS_score,RFQ_c), nfactors = 2, fm = "minres", rotate = "varimax")
# Print the EFA result
print(efa_result)

```



```{r, include=FALSE}
turing <- read_csv("data/turing.csv")
colnames(turing) <- c("responses", "category")

turing  %>%
    group_by(category) %>%
    summarize(count = n()) %>%
    mutate(percentage = count / sum(count) * 100) %>%
    dplyr::select(category, percentage)

```


# HMM analysis of participant returns

```{r, include=FALSE}


# Removing player whose return was not properly recorded by data (NA in one of the rounds) so as to run depmixS4
id_with_na <-  as.character(avg_ret_df[is.na(avg_ret_df$returns),"id"])

# Create return percentage bins Bins
avg_ret_df <- avg_ret_df %>%
  filter(id != id_with_na) %>% 
  mutate(game_id = rep(1:636, each=15)) %>%
  group_by(game_id) %>%
  mutate(next_investment = lead(investment, default=0),
         investment_bin = cut(investment, breaks = c(-1,2.5,7.5,12.5,17.5,21)),  
         return_pct_bin = cut(ret_pct_0, breaks = c(-.1,.16,.33,.50,.66,0.84,1.1)),  # 0, 1/6, 2/6, 3/6,...
         intervention_ctrst = factor(ifelse(gameNum.f=="pre", 0,ifelse(condition.f=="control",1,2))),
         ctrl_only_ctrst = factor(ifelse(gameNum.f=="post" && condition.f=="control", 1,0)),
         coax_only_ctrst = factor(ifelse(gameNum.f=="post" && condition.f=="intervention", 1,0)),
         pre_post_ctrst = factor(ifelse(gameNum.f=="post", 1,0)))  %>% 
  ungroup()
# We put factor as otherwise R thinks that it's a linear variable. We want the first level to be reference group, 0. Default uses that. 

priordat <- avg_ret_df %>% filter(roundNum==1)


############### HMM support functions   #########################

# order the states of the HMM to allow it to order them as low ret/mid/ret/high ret. 
label_switch <- function(mod,labels) {
  # labels is vector, first element is new label for original state 1, second is new label for original state 2, etc.
  if(!is(mod,"depmix") || !is(mod,"depmix.fitted")) stop("this function is for depmix models")
  n_states <- mod@nstates
  if(length(labels) != n_states || length(unique(labels)) != n_states || !(all(labels) %in% 1:n_states)) {
    stop("labels needs to be a vector of unique integers between 1 and", n_states)
  }
  inv_labels <- sapply(1:n_states,function(x) which(labels == x))
  tmp <- mod
  # relabel prior
  ppars <- getpars(mod@prior)
  fpars <- getpars(mod@prior,which="fixed")
  out_pars <- as.numeric(t(matrix(ppars,nrow=length(ppars)/n_states,byrow = TRUE)[,inv_labels]))
  out_fixed <- as.logical(t(matrix(fpars,nrow=length(fpars)/n_states,byrow = TRUE)[,inv_labels]))
  if(!tmp@prior@family$link=="identity") tmp@prior@family$base <- labels[tmp@prior@family$base]
  # relabel transition
  for(i in 1:n_states) {
    ppars <- getpars(mod@transition[[inv_labels[i]]])
    fpars <- getpars(mod@transition[[inv_labels[i]]],which="fixed")
    out_pars <- c(out_pars,as.numeric(t(matrix(ppars,nrow=length(ppars)/n_states,byrow = TRUE)[,inv_labels])))
    out_fixed <- c(out_fixed,as.logical(t(matrix(fpars,nrow=length(fpars)/n_states,byrow = TRUE)[,inv_labels])))
    tmp@transition[[i]] <- mod@transition[[inv_labels[i]]]
    if(!tmp@transition[[i]]@family$link=="identity") tmp@transition[[i]]@family$base <- labels[tmp@transition[[i]]@family$base]
    #out_pars <- c(out_pars,getpars(mod@transition[[inv_labels[i]]]))
  }
  # relabel response
  for(i in 1:n_states) {
    out_pars <- c(out_pars,unlist(lapply(mod@response[[inv_labels[i]]],getpars)))
    out_fixed <- c(out_fixed,unlist(lapply(mod@response[[inv_labels[i]]],getpars,which="fixed")))
  }
  tmp <- setpars(tmp,out_fixed,which="fixed")
  tmp <- setpars(tmp,out_pars)
  if(is(tmp,"depmix.fitted")) tmp@posterior <- viterbi(tmp)
  return(tmp)
}


# ORDERING STATES
order_mod_gauss <- function(mod) {
  ns <- nstates(mod)
  sum <- rep(0.0,ns)
  for(i in 1:ns) {
    # Expected return in each state calculation 
    sum[i] = mod@response[[i]][[1]]@parameters$mu
  }
  # reordering the states
  mod <- label_switch(mod, rank(sum))
  return(mod)
}


```

```{r, include=F}
# define a response class which only contains the standard slots, no additional slots
setClass("discgaus", contains="response", slots=c(breaks="numeric"))

# define a generic for the method defining the response class

setGeneric("discgaus", function(y, pstart = NULL, fixed = NULL, ...) standardGeneric("discgaus"))

# define the method that creates the response class

setMethod("discgaus", 
          signature(y="ANY"), 
          function(y,pstart=NULL,fixed=NULL, breaks = c(-Inf, 0:19 + .5, Inf), ...) {
            y <- matrix(y,length(y))
            x <- matrix(1)
            parameters <- list()
            npar <- 2
            if(is.null(fixed)) fixed <- as.logical(rep(0,npar))
            if(!is.null(pstart)) {
              if(length(pstart)!=npar) stop("length of 'pstart' must be ",npar)
              parameters$mu <- pstart[1]
              parameters$sigma <- pstart[2]
            }
            mod <- new("discgaus",parameters=parameters,fixed=fixed,x=x,y=y,npar=npar, breaks=breaks)
            mod
          }
)

setMethod("show","discgaus",
          function(object) {
            cat("Gaussian with discrete support\n")
            cat("Parameters: \n")
            cat("mu: ", object@parameters$mu, "\n")
            cat("sigma: ", object@parameters$sigma, "\n")
          }
)

setMethod("dens","discgaus",
          function(object,log=FALSE) {
            p <- pnorm(object@breaks[-1], mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(object@breaks[-length(object@breaks)], mean = object@parameters$mu, sd = object@parameters$sigma)
            if(log) return(log(p[as.numeric(cut(object@y, breaks=object@breaks))])) else return(p[as.numeric(cut(object@y, breaks=object@breaks))])
          }
)

setMethod("setpars","discgaus",
          function(object, values, which="pars", ...) {
            npar <- npar(object)
            if(length(values)!=npar) stop("length of 'values' must be",npar)
            # determine whether parameters or fixed constraints are being set
            nms <- names(object@parameters)
            switch(which,
                   "pars"= {
                     object@parameters$mu <- values[1]
                     object@parameters$sigma <- values[2]
                   },
                   "fixed" = {
                     object@fixed <- as.logical(values)
                   }
            )
            names(object@parameters) <- nms
            return(object)
          }
)

setMethod("getpars","discgaus",
          function(object,which="pars",...) {
            switch(which,
                   "pars" = {
                     parameters <- numeric()
                     parameters <- unlist(object@parameters)
                     pars <- parameters
                   },
                   "fixed" = {
                     pars <- object@fixed
                   }
            )
            return(pars)
          }
)

setMethod("fit","discgaus",
          function(object,w) {
            if(missing(w)) w <- NULL
            if(!is.null(w)) {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(w*log(dens(object)))
              }
            } else {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(log(dens(object)))
              }
            }
            pars <- optim(c(object@parameters$mu, log(object@parameters$sigma)), fn=negLL)$par
            object <- setpars(object,c(pars[1], exp(pars[2])))
            object
          }
)

setClass("truncdiscgaus", contains="discgaus", slots=c(min="numeric", max="numeric"))

setMethod("dens","truncdiscgaus",
          function(object,log=FALSE) {
            breaks <- c(object@min, object@breaks[object@breaks > object@min & object@breaks < object@max], object@max)
            p <- pnorm(breaks[-1], mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(breaks[-length(breaks)], mean = object@parameters$mu, sd = object@parameters$sigma)
            p <- p/sum(p)
            if(log) return(log(p[as.numeric(cut(object@y, breaks=object@breaks))])) else return(p[as.numeric(cut(object@y, breaks=object@breaks))])
          }
)

setGeneric("truncdiscgaus", function(y, pstart = NULL, fixed = NULL, ...) standardGeneric("truncdiscgaus"))

setMethod("truncdiscgaus", 
          signature(y="ANY"), 
          function(y,pstart=NULL,fixed=NULL, breaks = c(-Inf, 0:19 + .5, Inf), min=0, max=20, ...) {
            y <- matrix(y,length(y))
            x <- matrix(1)
            parameters <- list()
            npar <- 2
            if(is.null(fixed)) fixed <- as.logical(rep(0,npar))
            if(!is.null(pstart)) {
              if(length(pstart)!=npar) stop("length of 'pstart' must be ",npar)
              parameters$mu <- pstart[1]
              parameters$sigma <- pstart[2]
            }
            mod <- new("truncdiscgaus",parameters=parameters,fixed=fixed,x=x,y=y,npar=npar, breaks=breaks, min=min, max=max)
            mod
          }
)


order_mod_gauss <- function(mod) {
  ns <- nstates(mod)
  sum <- rep(0.0,ns)
  for(i in 1:ns) {
    # Expected return in each state calculation 
    sum[i] = mod@response[[i]][[1]]@parameters$mu
  }
  # reordering the states
  mod <- label_switch(mod, rank(sum))
  return(mod)
}

# define a response class which only contains the standard slots, no additional slots
setClass("vtdgaus", contains="response", slots=c(yield="numeric"))

# define a generic for the method defining the response class

setGeneric("vtdgaus", function(y, pstart = NULL, fixed = NULL, ...) standardGeneric("vtdgaus"))

# define the method that creates the response class

setMethod("vtdgaus", 
          signature(y="ANY"), 
          function(y, yield, pstart=NULL,fixed=NULL, ...) {
            y <- matrix(y,length(y))
            x <- matrix(1)
            parameters <- list()
            npar <- 2
            if(is.null(fixed)) fixed <- as.logical(rep(0,npar))
            if(!is.null(pstart)) {
              if(length(pstart)!=npar) stop("length of 'pstart' must be ",npar)
              parameters$mu <- pstart[1]
              parameters$sigma <- pstart[2]
            } else {
              parameters <- list(mu=.5,sigma=1)
            }
            mod <- new("vtdgaus",parameters=parameters,fixed=fixed,x=x,y=y,npar=npar, yield=yield)
            mod
          }
)

setMethod("show","vtdgaus",
  function(object) {
    cat("Gaussian with variable discrete support for percentage responses\n")
    cat("Parameters: \n")
    cat("mu: ", object@parameters$mu, "\n")
    cat("sigma: ", object@parameters$sigma, "\n")
  }
)

setMethod("dens","vtdgaus",
  function(object,log=FALSE) {
      # determine cuts for pnorm based on 
      p <- pnorm(sapply(object@y + .5*(1/object@yield),function(x) min(x,1.001)), mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(sapply(object@y - .5*(1/object@yield),function(x) max(x,-0.001)), mean = object@parameters$mu, sd = object@parameters$sigma)
      norm <- (pnorm(1 + .001, mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(-0.001, mean = object@parameters$mu, sd = object@parameters$sigma))
      p <- p/norm
      # alternatively, normalize factor based on size of cuts
      #p <- pnorm(object@y + .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(object@y - .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma)
      #p <- p/(pnorm(1 + .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma) - pnorm(0 - .5*(1/object@yield), mean = object@parameters$mu, sd = object@parameters$sigma))
    # probability when yield == 0 is always 1 
      p[object@yield == 0] <- 1
      if(log) return(log(p)) else return(p)
    }
)

setMethod("setpars","vtdgaus",
          function(object, values, which="pars", ...) {
            npar <- npar(object)
            if(length(values)!=npar) stop("length of 'values' must be",npar)
            # determine whether parameters or fixed constraints are being set
            nms <- names(object@parameters)
            switch(which,
                   "pars"= {
                     object@parameters$mu <- values[1]
                     object@parameters$sigma <- values[2]
                   },
                   "fixed" = {
                     object@fixed <- as.logical(values)
                   }
            )
            names(object@parameters) <- nms
            return(object)
          }
)

setMethod("getpars","vtdgaus",
          function(object,which="pars",...) {
            switch(which,
                   "pars" = {
                     parameters <- numeric()
                     parameters <- unlist(object@parameters)
                     pars <- parameters
                   },
                   "fixed" = {
                     pars <- object@fixed
                   }
            )
            return(pars)
          }
)

setMethod("fit","vtdgaus",
          function(object,w) {
            if(missing(w)) w <- NULL
            if(!is.null(w)) {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(w*log(dens(object)))
              }
            } else {
              negLL <- function(pars) {
                object <- setpars(object, c(pars[1], exp(pars[2])))
                -sum(log(dens(object)))
              }
            }
            pars <- optim(c(object@parameters$mu, log(object@parameters$sigma)), fn=negLL)$par
            object <- setpars(object,c(pars[1], exp(pars[2])))
            object
          }
)
```

```{r, include=F}
priordat <- avg_ret_df %>% filter(roundNum==1)
n_state_min <- 2
n_state_max <- 7

trust_simple <- trust_ctrl <- trust_coax <- trust_fullCtrst <- trust_prePost <- list()

# HMMs based on bins
for(i in n_state_min:n_state_max) {
  
  trust_simple[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
  
  trust_ctrl[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*ctrl_only_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
  
  trust_coax[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*coax_only_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
  
  trust_fullCtrst[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*intervention_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
  
  trust_prePost[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*pre_post_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))

}


# vtdgaus no contrasts
simple_HMMs <- ctrl_HMMs <- coax_HMMs <- fullCtrst_HMMs <- prePost_HMMs <- list()

for(i in n_state_min:n_state_max) {

  rModels <- rep(list(list(vtdgaus(y=avg_ret_df$ret_pct_0,yield=3*avg_ret_df$investment))),each=i)
  
  simple_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_simple[[i]]@transition,prior=trust_simple[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
  
  ctrl_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_ctrl[[i]]@transition,prior=trust_ctrl[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
  
  coax_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_coax[[i]]@transition,prior=trust_coax[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
  
  fullCtrst_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_fullCtrst[[i]]@transition,prior=trust_fullCtrst[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
  
  prePost_HMMs[[i]] <- makeDepmix(response=rModels,transition=trust_prePost[[i]]@transition,prior=trust_prePost[[i]]@prior, ntimes = rep(15,636), homogeneous=FALSE)
    
}
```

```{r, include=FALSE}

# fittedSimple <- fittedCoax  <- fittedCtrl  <- fittedFullCtrst  <- fittedPrePost  <- list()
# # increase default in multistart from 10 to 20. or set the same seed for every model
# 
# set.seed(20221028)
# for(i in n_state_min:n_state_max) {
# 
#   fittedSimple[[i]] <- multistart(simple_HMMs[[i]],nstart=20)
# }
# save(fittedSimple, file="fittedSimple.RData")
# ##############################
# 
# set.seed(20221028)
# for(i in n_state_min:n_state_max) {
#   fittedCtrl[[i]] <- multistart(ctrl_HMMs[[i]],nstart=20)
# }
# save(fittedCtrl, file="fittedCtrl.RData")
# ##############################
# 
# set.seed(20221028)
# for(i in n_state_min:n_state_max) {
#   fittedCoax[[i]] <- multistart(coax_HMMs[[i]],nstart=20)
# }
# save(fittedCoax, file="fittedCoax.RData")
# ##############################
# 
# set.seed(20221028)
# for(i in n_state_min:n_state_max) {
#   fittedPrePost[[i]] <- multistart(prePost_HMMs[[i]],nstart=20)
# }
# save(fittedPrePost, file="fittedPrePost.RData")
# #############################
# 
# 
# 
# for(i in n_state_min:n_state_max) {
#   fittedFullCtrst[[i]] <- multistart(fullCtrst_HMMs[[i]],nstart=20)
# }
# save(fittedFullCtrst, file="fittedFullCtrst.RData")
# ###############################


```

```{r, include=FALSE}

load("data/fittedSimple.RData")
load("data/fittedCtrl.RData")
load("data/fittedCoax.RData")
load("data/fittedFullCtrst.RData")
load("data/fittedPrePost.RData")
load("data/newFull.RData")

has_converged <- function(object, numeric = TRUE){
  msg <- object@message
  if(numeric) as.integer(grepl("converged", msg)) else 0
}


sapply(fittedSimple[2:7],has_converged)
sapply(fittedCtrl[2:7],has_converged)
sapply(fittedCoax[2:7],has_converged)
sapply(fittedFullCtrst[2:7],has_converged)
sapply(fittedPrePost[2:7],has_converged)
sapply(newFull[2:7],has_converged)

```

```{r}

# THE CODE BELOW WAS NOT USED; ALL CONVERGED. PUT IT HERE IN CASE IT IS NEEDED LATER ON.
# library(depmixS4)
# fit_until_convergence <- function(fitted_model, max_iterations=2) {
#   cat(fitted_model@nstates)
#   iterations <- 0
#   converged <- has_converged(fitted_model)
#   
#   while (!converged && iterations < max_iterations) {
#     # Use parameters from the fitted model as initial parameters
#     initial_params <- getpars(fitted_model)
#     new_model <- setpars(fitted_model, initial_params)
#     
#     # Refit the model
#     fitted_model <- fit(new_model)
#     converged <- has_converged(fitted_model)
#     iterations <- iterations + 1
#   }
#   
#   if (converged) {
#     cat("NS = ", fitted_model@nstates,"Convergence has been reached.\n")
#     flush.console()
#     return(fitted_model)
#   } else {
#     cat("Maximum iterations reached. Convergence has not been reached.\n")
#     flush.console()
#     return(fitted_model)
#   }
# }
# 
# 
# run_parallel_fitting <- function(mods_vec,num_cores = 5) {
#   # Set up the parallel backend
#   my.cluster <- parallel::makeCluster(num_cores, type = "PSOCK")
#   doParallel::registerDoParallel(cl = my.cluster)
#   
#   # Export the fit_until_convergence function to the workers
#   parallel::clusterExport(my.cluster, "fit_until_convergence")
#   parallel::clusterExport(my.cluster, "has_converged")
# 
#   # Run the loop in parallel using foreach
#   converged_mods_vec <- foreach(mod = mods_vec, .packages = c("depmixS4"), .combine = "c") %dopar% {
#     cat(mod@nstates)
#     fit_until_convergence(mod)
#   }
# 
#   # Stop the parallel backend
#   parallel::stopCluster(my.cluster)
#   return(converged_mods_vec)
# }
# 
```


```{r, include=FALSE}
# # The full contrast model convergence was not attained. Here we use parameters of fitted PrePost model as initial values of the FullContrast model to speed up fitting and aim for faster convergence.

# newFull <- fittedFullCtrst
# for (ns in n_state_min :n_state_max){
# 
#   fmod <- fittedPrePost[[ns]]
#   origin_pars <- getpars(fmod)
#   numCovTr <- 4
#   numCovIn <- 2
#   
#   # create a new vector which has the right number of pars for the full contrast model. 
#   new_pars <- c(origin_pars[1:(ns*2)])
#   # from is state we are transitioning from 
#   for(from in 1:ns) {
#   mat <- matrix(getpars(fmod)[seq(ns*numCovIn + 1 + (from - 1)*numCovTr*ns, ns*numCovIn + 1 + (from - 1)*numCovTr*ns + numCovTr*ns - 1)],ncol=numCovTr)
#   new_mat <- mat[,c(1:2,3,3,4,4)]
#   new_pars <- c(new_pars,as.numeric(new_mat))
#   }
#   
#   new_pars <- c(new_pars,origin_pars[(ns*numCovIn + 1 + (ns - 1)*numCovTr*ns + numCovTr*ns):length(origin_pars)])
#   
#   newFull[[ns]] <- setpars(newFull[[ns]],new_pars)
#   newFull[[ns]] <- fit(newFull[[ns]], emcontrol= em.control(maxit = 1000,random.start = FALSE))
# }
# 
# save(newFull, file="newFull.RData")
 
```

```{r, include=FALSE}

load("data/fittedSimple.RData")
load("data/fittedCtrl.RData")
load("data/fittedCoax.RData")
load("data/fittedFullCtrst.RData")
load("data/fittedPrePost.RData")
load("data/newFull.RData")

BICs_simple <- BICs_Ctrl <- BICs_Coax <- BICs_FullCtrst <- BICs_PrePost <-  BICs_newFull <- list()
for(i in n_state_min:n_state_max) {
  BICs_simple[[i]] <- BIC(fittedSimple[[i]]) 
  BICs_Ctrl[[i]] <- BIC(fittedCtrl[[i]])
  BICs_Coax[[i]] <- BIC(fittedCoax[[i]]) 
  BICs_FullCtrst[[i]] <- BIC(fittedFullCtrst[[i]]) 
  BICs_PrePost[[i]] <- BIC(fittedPrePost[[i]]) 
  BICs_newFull[[i]] <- BIC(newFull[[i]]) 
  
}

print("SIMPLE HMM models")
BICs_simple

print("HMM with contrast on post Control vs others")
BICs_Ctrl

print("HMM with contrast on post Coax vs others")
BICs_Coax

print("HMM with Pre vs Post Contrast")
BICs_PrePost

print("HMM with contrast levels Pre, Post Control and Post Coaxing")
BICs_FullCtrst

print("HMM with contrast levels Pre, Post Control and Post Coaxing, new fitting")
BICs_newFull

df_bics <- cbind(2:7,as.numeric(BICs_simple[2:7]), as.numeric(BICs_Ctrl[2:7]),as.numeric(BICs_Coax[2:7]), as.numeric(BICs_PrePost[2:7]), as.numeric(BICs_newFull[2:7]))
df_bics


```

```{r, include=FALSE}
library(knitr)
library(kableExtra)

# Create a data frame for the models
models <- data.frame(
  Model = c("HMM-inv", "HMM-prepost", "HMM-coax", "HMM-ctrl", "HMM-full"),
  Pre_Intervention =  c(0, -1, -1, -1, -1),
  Post_Intervention = c(0, 1, 1, -1, 2),
  Pre_Control =       c(0, -1, -1, -1, -1),
  Post_Control =      c(0, 1, -1, 1, 1)
)

# Create a table
models %>%
  kable("pipe", caption = "Models and their Contrasts") %>%
  kable_styling()

```

```{r table-BICs-coax, include =FALSE, warning = FALSE, echo=FALSE, ft.align="center", tab.id='table-BICs-coax', label='table-BICs-coax'}

data.frame(df_bics) %>% 
  `colnames<-` (c("Number of states","HMM-inv", "HMM-ctrl", "HMM-coax", "HMM-prepost","HMM-full")) %>%
  mutate_if(is.numeric, format, digits=4,nsmall = 0, big.mark = ",") %>% 
  knitr::kable(.,booktabs = TRUE,
  caption = 'Table of BICs for each of the estimated HMM models for assumed number of latent states between 2 and 7') %>% kable_styling(latex_options="scale_down")
```

We used hidden Markov models (HMMs) to further assess differences between the intervention and control condition in participants' reactions to the investor. As in the models for the investor, these HMMs assume behaviour is governed by latent states, with participants' switches between states now dependent on the investments made. We also allowed for differences between games and conditions in how investments govern state transitions. More in particular, we fitted five main models which all regressed state transition probabilities onto investments, as well as on additional contrast-coded predictors for condition and/or game number. In the most complex model (HMM-full), the transition probabilities were allowed to differ between all four combinations of game number and condition. The HMM-coax model allowed differences between post-intervention and the other three conditions (pre-intervention, pre-control, post-control) assuming these latter were the same. Similarly, the HMM-ctrl model allowed differences between post-control and the other three conditions. The HMM-prepost model allowed differences between the first and second RGT. Finally, the HMM-inv model did not allow transition probabilities to differ between conditions or game numbers, modelling them only as a function of investment. As the number of hidden states was unknown, for each model we estimated versions with 2 to 7 states, and used the BIC to select the best fitting model. Generally, best fitting models had between 5 to 7 hidden states.

<!-- Table \ref{tab:table-BICs-coax} shows the BICs of the various fitted models for an assumed number of states between 2 and 7.  For a simple model without any contrasts (HMM-inv) and a model with post-control only contrast (HMM-ctrl) we find a 6-state model to be best fitting. If the contrast is between the post-intervention group and all the other groups (HMM-coax), then a 7 state model is best fitting. When the contrast is comparing only pre and post Intervention groups (HMM-prepost), a 5 state model fits best. Finally, when we distinguish between pre-manipulation, post-control and post-intervention (HMM-full), we find that a 5 state model fits best. Since we only fit models between 2 and 7 states, it is possible that for those where we find the 7 state model to be best fitting, models with a higher number of states could fit the data better. We decided to stop at 7 states for computational cost reasons and because the interpretation of models with a higher number of states becomes complex.  -->

```{r, include=FALSE}
summary(fittedSimple[[5]])

logLik(fittedSimple[[5]])
logLik(fittedCtrl[[5]])
logLik(fittedCoax[[5]])
logLik(fittedPrePost[[5]])
# logLik(fittedFullCtrst[[5]])
logLik(newFull[[5]])

# Nested model comparison for 5 states, with and without intervention contrast. llratio test shows no effect, meaning interaction term addition does not change goodness of fit of model. 
llratio(newFull[[5]], fittedSimple[[5]])

llratio(fittedCtrl[[5]],fittedSimple[[5]])
llratio(fittedCoax[[5]],fittedSimple[[5]])
llratio(fittedPrePost[[5]],fittedSimple[[5]])

llratio(newFull[[5]],fittedCtrl[[5]])
llratio(newFull[[5]],fittedCoax[[5]])
llratio(newFull[[5]],fittedPrePost[[5]])

llratio(newFull[[6]],fittedCtrl[[6]])
llratio(newFull[[6]],fittedCoax[[6]])
llratio(newFull[[6]],fittedPrePost[[6]])
```

<!-- MS: There seems to be an issue with the likelihoods of the models. For example, for 6 states models, the likelihood of the Ctrl and Coax model are higher than for the Full model, but this is theoretically not possible as additional parameters can only increase the likelihood! -->

Focussing on models with 5 latent states (which is the optimal number for the HMM-full model), likelihood ratio tests showed that the HMM-full model fits significantly better than HMM-ctrl ($\chi^2(40) = `r round(-2*as.numeric(logLik(fittedCtrl[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$), HMM-coax ($\chi^2(40) = `r round(-2*as.numeric(logLik(fittedCoax[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$) and HMM-prepost ($\chi^2(40) = `r round(-2*as.numeric(logLik(fittedPrePost[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$). This is consistent with state transitions differing both due to game number and condition as can be seen in Figure \ref{fig:plotTransitionsDiscGaus}.

<!-- We start by comparing HMM-full with HMM-inv. We find that HMM-full fits the data better than HMM-inv ($\chi^2(84) = `r round(-2*as.numeric(logLik(fittedSimple[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$). Likewise HMM-ctrl fits better than HMM-inv ($\chi^2(44) = `r round(-2*as.numeric(logLik(fittedSimple[[5]])) - (-2*as.numeric(logLik(fittedCtrl[[5]]))) , 2)`$, $p < .001$). The same is true for HMM-coax compared to HMM-inv ($\chi^2(44) = `r round(-2*as.numeric(logLik(fittedSimple[[5]])) - (-2*as.numeric(logLik(fittedCoax[[5]]))) , 2)`$, $p < .001$) and HMM-prepost compared to HMM-inv ($\chi^2(44) = `r round(-2*as.numeric(logLik(fittedSimple[[5]])) - (-2*as.numeric(logLik(fittedPrePost[[5]]))) , 2)`$, $p < .001$). HMM-inv being the worst fitting model compared to the others indicates the existence of differentiated behavior pre vs post manipulation and/or between the control and intervention groups.  -->

<!-- Using likelihood ratio tests, we find that the HMM-full model fits significantly better than HMM-ctrl ($\chi^2(40) = `r round(-2*as.numeric(logLik(fittedCtrl[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$), HMM-coax ($\chi^2(40) = `r round(-2*as.numeric(logLik(fittedCoax[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$) and HMM-prepost ($\chi^2(40) = `r round(-2*as.numeric(logLik(fittedPrePost[[5]])) - (-2*as.numeric(logLik(newFull[[5]]))) , 2)`$, $p < .001$). This is consistent with a differentiated behavior of the trustees between all three groups: the post-intervention group, the post-control group and the pre-manipulation group. -->

<!--    ORDER THE STATES    -->

```{r, include=FALSE}
tr_fdmod_5 <- order_mod_gauss(newFull[[5]])
```

```{r, include=FALSE}

state1 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[1]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

state2 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[2]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

state3 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[3]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

state4 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[4]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

state5 <- dens(truncdiscgaus(seq(0.025,0.975,length=20),pstart=c(unlist(tr_fdmod_5@response[[5]][[1]]@parameters)), breaks = c(0, seq(0.05,0.95,length=19) , 1),  min=0, max=1))

returns <- seq(0.025,0.975,length=20)

response_best_mod <- as.data.frame(cbind(returns,state1,state2,state3,state4,state5)) %>% 
  pivot_longer(cols=c("state1","state2","state3","state4","state5"),
                    names_to='Trustee_state',
                    values_to='probability')

```



<!-- Using the best fitting model according to likelihood ratio tests (HMM-full), Figure \ref{fig:trusteeHMMPlot} shows the distribution of the participants' returns conditional on the latent state they are in. The states are ordered based on the mean of the Gaussian distribution fitted to the response (percentage return). State 1 represents the state in which the returns have have the lowest underlying mean, and state 5 is the state in which the returns have the highest underlying mean. The higher the state number the more pro-social the policy adopted. More specifically, state 1 can be thought of as a non-cooperative state in which returns are low and close to 0, meaning that the trustee is keeping most of the tripled investment. State 2 is a state where the average return is around the investment sent and can be interpreted as a cautious state in which the return on trust is small. States 3, 4 and 5 are increasingly cooperative states. For instance, in state 5, the average return is close to two thirds of the tripled investment, meaning the trustee is keeping an amount similar to the investment that was sent and returning to the investor double the investment. -->

<!-- Figure \ref{fig:plotTransitionsDiscGaus} shows the transition between states as a function of the investment received for each group (pre-manipulation, post-control and post-intervention) using results from the best fitting model: HMM-full. The best fitting HMM model has multiple states and a high number of parameters. We can nonetheless focus on particular states linked to the breakdown and repair of cooperation. For instance, focusing on the transition functions to state 1 (the lowest return state with returns close to 0) from higher return states, we can compare the  post-control group to the post-intervention group. The red line representing the probability of transitioning to the low-return state 1 when the investment is close to 0 is lower in the intervention group compared to the control group when the trustee is in a relatively pro-social state (states 3 to 5). This is pointing towards more "forgiving" behavior where participants in the intervention group were less likely to transition to this anti-social state compared to the control group.  -->

<!-- MS: I think Figure 6 can be moved to the supplement and perhaps Figure 6.A too. -->

<!-- Using the HMM-full model, we can retrieve participants' return distributions based on their latent states (Figures \ref{fig:postStatesBestMod}.A) and transition probabilities between these states (Figure \ref{fig:plotTransitionsDiscGaus}). The states are ranked by mean return, with State 1 having the lowest mean return and State 5 the highest. A higher state number indicates a more pro-social policy. We focused on states related to cooperation's breakdown and repair. We compared the transition probabilities between states when the investment is low for post-control and post-intervention groups. Figure \ref{fig:plotTransitionsDiscGaus} suggests that the intervention group is more forgiving of low investments, as they are less likely to shift to an anti-social state when faced with defection compared to the control group. -->


```{r, include=FALSE}

plot_state_transitions <- function(fmod, numCovIn, numCovTr) {

  #print(getpars(fmod))
  ns <- nstates(fmod)
  
  trans_prob <- data.frame(
    from = rep(1:ns, each=100*ns),
    to = rep(1:ns, each=100),
    investment = seq(0,20,length=100),
    prob_pre = 0,
    prob_ctrl = 0,
    prob_coax =0
  )
  
  y0 <- matrix(0.0,ncol=ns, nrow=100)
  y1 <- matrix(0.0,ncol=ns, nrow=100)
  y2 <- matrix(0.0,ncol=ns, nrow=100)
  
  for(from in 1:ns) {
  pars <- matrix(getpars(fmod)[seq(ns*numCovIn + 1 + (from - 1)*numCovTr*ns, ns*numCovIn + 1 + (from - 1)*numCovTr*ns + numCovTr*ns - 1)],ncol=numCovTr)
  #print(pars)
  
    for(to in 1:ns) {
        x <- trans_prob[trans_prob$from == from & trans_prob$to == to,"investment"]
        y0[,to] <- exp(pars[to,1] + pars[to,2]*x)
        #ctrst 2 = 1, post intervention vs pre
        y2[,to] <- exp(pars[to,1] + pars[to,2]*x + pars[to,3]*1 + pars[to,5]*x )
        #ctrst 1 = 1, post control vs pre
        y1[,to] <- exp(pars[to,1] + pars[to,2]*x + pars[to,4]*1 + pars[to,6]*x )
    }
    y0 <- y0/rowSums(y0)
    y1 <- y1/rowSums(y1)
    y2 <- y2/rowSums(y2)
    
    for(to in 1:ns) {
      trans_prob$prob_pre[trans_prob$from == from & trans_prob$to == to] <- y0[,to]
      trans_prob$prob_ctrl[trans_prob$from == from & trans_prob$to == to] <- y1[,to]
      trans_prob$prob_coax[trans_prob$from == from & trans_prob$to == to] <- y2[,to]
    }
  }
  
  
  
  saveRDS(trans_prob, "data/trans_prob.RDS")
  
  return(trans_prob)
  
  #  p_pre <- ggplot(trans_prob,aes(x=investment,y=prob_pre, colour = as.factor(to))) + geom_line() + facet_wrap(~from) + ylim(c(0,1)) + ggtitle("Transition function pre manipulation") + labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + theme_bw()
  # 
  # p_ctrl <- ggplot(trans_prob,aes(x=investment,y=prob_ctrl, colour = as.factor(to))) + geom_line() + facet_wrap(~from) + ylim(c(0,1)) + ggtitle("Transition function post control") + labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + theme_bw()
  # 
  # p_coax <- ggplot(trans_prob,aes(x=investment,y=prob_coax, colour = as.factor(to))) + geom_line() + facet_wrap(~from) + ylim(c(0,1)) + ggtitle("Transition function post intervention") + labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + theme_bw()
  # 
  # grid.arrange(p_pre, p_ctrl,p_coax, nrow=3, ncol=1)


}


# plot_state_transitions(tr_fdmod_5,numCovIn=2, numCovTr=6) 

```

```{r,include=F}

trans_prob <- readRDS("data/trans_prob.RDS")

ctrl_pre_plot <- ggplot(trans_prob,aes(x=investment,y=prob_ctrl, colour = as.factor(to))) + 
  geom_line() + 
  geom_line(aes(y=prob_pre),linetype="dotted") +
  facet_wrap(~from) + 
  ylim(c(0,1)) + 
  ggtitle("Transition function pre- and post-control manipulation") + 
  labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + 
  theme_bw()


coax_pre_plot <- ggplot(trans_prob,aes(x=investment,y=prob_coax, colour = as.factor(to))) + 
  geom_line() + 
  geom_line(aes(y=prob_pre),linetype="dotted") +
  facet_wrap(~from) + 
  ylim(c(0,1)) + 
  ggtitle("Transition function pre- and post-intervention manipulation") + 
  labs(x = "Investment", y = "Transition probability", color='State Transitioned to') + 
  theme_bw()



```

```{r plotTransitionsDiscGaus, fig.cap="Transition function for the HMM-full trustee model. Each panel represents the state transitioned from, and each color the state transitioned to. Solid lines show estimated transition probabillities post-manipulation. Dotted lines show the same probabilities prior to the manipulation",fig.align="center", fig.width=6, fig.height = 7 }

grid.arrange(ctrl_pre_plot , coax_pre_plot , nrow=2, ncol=1)

# plot_state_transitions(tr_fdmod_5,numCovIn=2, numCovTr=6) 

```

<!-- To explore the differences in transition probabilities between the control and coaxing conditions, we can choose an investment and compare the probabilities of transitioning between States. For instance, in case the trustee is low in trustworthiness (State 1), and the investor sends an average amount, we can compare the likelihood of the trustee transitioning away from the low trustworthiness state. Assuming an investment of 10 (half the endowment), The trustee remains in State 1 with around $85\%$ probability in the control condition, but only $67\%$ probability after the coaxing intervention. Likewise, assuming the trustee is in State 4, and receiving a low investment of 2, there is a much lower probability ($0.2\%$) of transitioning to low trustworthiness state in the coaxing condition compared to the control condition ($21\%$). -->

```{r, include = FALSE}
set.seed(20221010)
# Get investor posterior states from model and add to data table

# mention we are using local decoding (refer to the book). 
predTrStates <- posterior(tr_fdmod_5, type="local")
avg_ret_df$TrState <-  factor(predTrStates, levels= c(1,2,3,4,5),labels=c("1","2","3","4","5"))

# avg_ret_df$TrState <-  factor(predTrStates, levels= c(5,4,3,2,1),labels=c("5","4","3","2","1"))


# predTrStates <- posterior(tr_fdmod_5)
# avg_ret_df$TrState <-  factor(predTrStates$state, levels= c(1,2,3,4,5),labels=c("1","2","3","4","5"))

library(dplyr)
temp_df <- avg_ret_df %>% dplyr::select(roundNum,investment,returns, next_investment, TrState)
```

```{r, include=FALSE}

trusteeHMMPlot <- ggplot(response_best_mod,                            
       aes(x = returns,
           y = probability,
           fill = Trustee_state)) +
  geom_bar(stat = "identity",
           position = "dodge") + 
  labs(fill='Latent trustee State') +
  theme_bw() + 
  theme(legend.position = "bottom")

# investor real state distribution (posterior)
postHMM <- ggplot(avg_ret_df %>% dplyr::filter(gameNum.f=="post")) +
  geom_bar(aes(x = roundNum, group = TrState, fill = TrState),  position = position_stack(reverse = TRUE)) + 
  facet_wrap(~condition.f) +  
  labs(x = "Round", fill='Posterior trustee state') +
  theme_bw() +
  theme(legend.position = "bottom")

```

```{r postStatesBestModOld,  echo=FALSE, fig.cap = "A: Distribution of participants' percentage return for each of the latent states in the 5 state HMM-full model. The latent states are ordered by the mean of the Gaussian that best fits the policy in that state, so higher numbered states are more pro-social. B: Distribution of posterior trustee states post manipulation by condition for all rounds, as estimated by the most likely posterior state in the best fitting HMM model (HMM-full) using a local decoding procedure.", fig.align="center", fig.height = 8}

# ggpubr::ggarrange(trusteeHMMPlot , postHMM , nrow=2, ncol=1,labels = c("A", "B"),common.legend = FALSE)

```

```{r postStatesBestMod,  echo=FALSE, fig.cap = "Distribution of posterior trustee states post manipulation by condition for all rounds, as estimated by the most likely posterior state in the best fitting HMM model (HMM-full) using a local decoding procedure.", fig.align="center", fig.height = 4}

postHMM

```





```{r, include= F}

props_df_5 <- avg_ret_df %>% 
  filter(gameNum.f=="post", roundNum== 5) %>% 
  group_by(condition.f,TrState) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))

prop.test(c(11,29), c(159,159))

props_df_14 <- avg_ret_df %>% 
  filter(gameNum.f=="post", roundNum== 14) %>% 
  group_by(condition.f,TrState) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))


prop.test(c(35,68), c(159,159))



props_df_13 <- avg_ret_df %>% 
  filter(gameNum.f=="post", roundNum== 13) %>% 
  group_by(condition.f,TrState) %>% 
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))

# compare proportions in state 1 in round 13 between conditions
prop.test(c(48,72), c(159,159))

# compare proportions in states 4 and 5  in round 13 between conditions
prop.test(c(48,18), c(159,159))

# props_df_12 <- avg_ret_df %>% 
#   filter(gameNum.f=="post", roundNum== 12) %>% 
#   group_by(condition.f,TrState) %>% 
#   summarise(n = n()) %>%
#   mutate(freq = n / sum(n))

```

Taking the best-fitting 5-state HMM-full model, we used a local decoding procedure to assign observations (participants' returns on trials) to latent states. The states are ordered by expected return, with state 1 having the lowest mean return and state 5 the highest. Figure \ref{fig:postStatesBestMod} shows that participants were more likely to be in a lower return state in the control condition compared to the intervention condition both pre and post defection. For instance, in round 5, state 1 was the most likely posterior state for only $7$% of participants in the intervention condition compared to $24$% in the control condition ($\chi^2(1) = 8.26, p < 0.01$). For the post-defection trial after the intervention (round 14), state 1 was the most likely state for only $22$% of participants in the intervention condition compared to $43$% in the control condition ($\chi^2(1) = 14.70, p < 0.001$). Whilst the posterior states indicate that the intervention was effective, a non-negligible proportion of participants in the intervention condition did not exhibit the coaxing behaviour promoted by the intervention. Directly following the low investment in round 13, $30.2$% of participants in the intervention condition were assigned to state 1 with the lowest average returns. There is thus clear heterogeneity in the effectiveness of the intervention.

<!-- To quantitatively explore the differences in transition probabilities between the control and intervention conditions, we can estimate from the model, using local decoding methods from the depmixS4 package [@visser_depmixs4_2021], the most likely posterior state of the trustee participants by round given the actions they have taken. Figure \ref{fig:postStatesBestMod}.B shows that participants were more likely to be in a lower return state in the control condition compared to the intervention condition both pre and post defection. For instance, in round 5, state 1 was the most likely posterior state for only $7$% of participants in the intervention condition compared to $24$% in the control condition ($\chi^2(1) = 8.26, p < 0.01$). For the post-defection trial after the intervention (round 14), state 1 was the most likely state for only $22$% of participants in the intervention condition compared to $43$% in the control condition ($\chi^2(1) = 14.70, p < 0.001$). 

The posteriors also suggest that a non-negligible proportion of participants in the intervention condition did not exhibit a behaviour consistent with the goal of the intervention as they were still best fit by low-return states post intervention. For instance, focusing on round 13 post defection $30.2$% of those in the intervention condition were most likely to be in the least pro-social state 1. These differences can be seen as an indication of important heterogeneity in the effectiveness of the intervention.
-->

```{r, include=FALSE}
# library(depmixS4)
# 
# n_bootstraps <- 1  # number of bootstrap resamples
# bootstrap_estimates <- matrix(NA, nrow=n_bootstraps, ncol=1)  # to store bootstrap estimates
# 
# ns <- 3
# numCovIn <- 2
# numCovTr <- 6
# from <- 3
# to <- 1
# 
# for (i in 1:n_bootstraps) {
#   # create a bootstrap resample of the data
#   #bootstrap_data <- data[sample(nrow(data), replace=TRUE), ]
#   bootstrap_data <- avg_ret_df %>% filter(id %in% sample(id,replace=TRUE))
#   
#   rModels <- rep(list(list(vtdgaus(y=bootstrap_data$ret_pct_0,yield=3*bootstrap_data$investment))),each=ns)
#   
#   simple_mod <- depmix(ret_pct ~ 1, data = bootstrap_data, nstates = ns, transition = ~ next_investment*intervention_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
#   
#   
#   # fit the model to the bootstrap resample
# 
#   model <- makeDepmix(response=rModels, transition = simple_mod@transition , prior = simple_mod@prior, initdata=priordat, ntimes = rep(15,636), homogeneous=FALSE)
#   
#   cat("two")
#   # trust_fullCtrst[[i]] <- depmix(return_pct_bin ~ 1, data = avg_ret_df, nstates = i, transition = ~ next_investment*intervention_ctrst, prior = ~ investment, initdata=priordat, family=multinomial("mlogit"), ntimes = rep(15,636))
#   
#   
# 
#   fit <- fit(model)
#   cat("post-fit")
# 
#   # store the estimates
#   #bootstrap_estimates[i, ] <- getpars(fit)
#   
#   pars <- matrix(getpars(fit)[seq(ns*numCovIn + 1 + (from - 1)*numCovTr*ns, ns*numCovIn + 1 + (from - 1)*numCovTr*ns + numCovTr*ns - 1)],ncol=numCovTr)
#   
#    bootstrap_estimates[i, ] <- pars[to,3]
#   
# }
# 
# # calculate 95% confidence intervals
# ci_lower <- apply(bootstrap_estimates, 2, function(x) quantile(x, 0.025))
# ci_upper <- apply(bootstrap_estimates, 2, function(x) quantile(x, 0.975))
# 
# # print the confidence intervals
# print(ci_lower)
# print(ci_upper)

```

# Discussion

In this experiment, human participants took the role of the trustee in a repeated trust game (RTG) where they faced artificial computer agents who's behaviour was partly determined by participants' returns. The behaviour of the artificial investors was determined by a 3-state hidden Markov model (HMM), which was estimated from the behaviour of humans in the RTG in prior research. Overall, investments and returns by the artificial and human agents replicated that of human dyads in prior research using the RTG [@charness_investment_2008; @fiedler_social_2011]. This, together with participants' reported uncertainty about whether they faced a human or artificial investor, shows the potential of using HMM-based artificial agents to mimic human behaviour in economic games, whilst offering a higher degree of experimental control.

The aim of the cognitive intervention was to articulate the potential unwanted effects of acting on impulse after a transgressive action from the investor in the form of a one-off low investment. After the intervention, participants sent back higher returns compared to before the intervention, and did not decrease their returns after a transgressive action like participants in the control condition did. The overall higher returns after the intervention occurred despite participants' emotional reactions to the investments remaining largely the same as before the intervention. This indicates the intervention achieved its goal of encouraging participants to respond in a non-impulsive and considered manner, overriding an emotional urge to retaliate. 

That participants generally send higher returns to the investor after the intervention is unlikely due to a  general learning effect unrelated to the intervention, as participants in the control condition did not increase their returns. Also, as participants in the intervention and control condition faced the same HMM investor, the higher post-intervention returns are not solely due to a difference in investor behaviour. As the investor reacts to participants' returns, those who return more will generally see higher investments. But this is driven by the magnitude of their returns, not by a change in the strategy of the investor. Finally, as participants rated the first and second HMM agent similarly on attributes such as cooperativeness and trust, the increased returns are unlikely to be the result of a more favourable evaluation of the investor. Rather, we find it most likely that the increased returns are due to participants inferring from the intervention that pro-social and trustworthy behaviour may generally motivate the investor to send high investments, which can provide more beneficial outcomes to them in the long run.

The effect of the intervention was not transferred to the Repeated Prisoner's Dilemma (RPD) game. There was no difference between the intervention and control condition in the rate of cooperation, whether before or after a preprogrammed defection by the artificial agent. As the prisoner's dilemma is a popular economic game, it is possible that participants had a strong prior commitment towards the strategy they would adopt, which was not overridden by the intervention. The RPD also involves much coarser actions (cooperate vs defect) than the finer-grained returns in the RTG. This would make it more difficult to observe more subtle effects of the intervention. As such, the RPD might not be the best choice for any knowledge transfer. In any case, we can not rule out that the effects of the brief cognitive intervention, which explicitly focused on the RTG, are confined to the RTG. Future research will need to assess whether transfer to other games is possible. <!-- For those that took on the intervention message and showed coaxing behavior in the second trust game, the fact that the investor still defected in the final rounds might have reinforced the idea that not reciprocating negative behavior is a losing strategy after all.-->

Analysing participants' behaviour with hidden Markov models, we found clear individual differences in how returns changed between the pre- and post-intervention RTG, which can be seen as a proxy for the effectiveness of the intervention. Some participants may not have been convinced that coaxing via high returns was a good way to establish cooperation and decided to reduce their returns in the second trust game. Their impulse to “punish” the other player for a transgression may have been too strong to be overridden by the intervention. This was also evident from the participants' replies to a question about whether they would change their behaviour, just after receiving the intervention. Other participants responded to the intervention and increased their returns. <!-- This raises important questions for the measurement of intervention effectiveness.--> Heterogeneity in response to treatment is common in psychiatry and related fields. Such heterogeneity may reflect the complex nature of mental health problems, which may be best viewed as complex systems involving interactions between neuro-computational processes and socio-environmental contexts evolving over time [@fried_moving_2017]. This view was used to justify computational psychiatry's difficulty in establishing differential and reliable predictors of likely treatment response [@hitchcock_computational_2022]. Here, we found heterogeneity in reaction to a relatively explicit intervention by a sample of participants from the general population. This suggests that the issue of variable treatment responses may result from the interaction of two sources of variability: the phenotyping of the disorder as well as the phenomenological aspects of the intervention itself. As such, a rigorous exploration of the determinants of inter-individual differences to an intervention in the general patient population is required.
<!-- In our case, judging by the inter-individual heterogeneity in responses, some people may not have been convinced that coaxing via high returns was a good way to re-establish cooperation after a transgression. Their impulse to “punish” the other player for their transgression may have been too strong to be overridden by the intervention. This was also evident from the participants' replies to a question about whether they would change their behaviour, just after seeing the intervention manipulation. An important avenue is to explore the role of emotion in decision making in such situations. We could aim to measure emotional reactions more accurately and explore whether specific emotions mediate the relationship between the investment received and the decision of what proportion to return. Measuring the emotions using the two axes of valence and arousal could be improved: Results indicate that these concepts may not have been well understood by participants since we would not expect to see low arousal after the pre-programmed defection of the investor.-->
Overall, we are encouraged that our brief cognitive intervention, consisting of reading a short text detailing a non-impulsive reaction to low investments, can lead to clearly differentiated behaviour. In future studies, we aim to explore the effects of improved cognitive interventions to enhance cooperative behaviour. We may enhance engagement by making the intervention more interactive and visually appealing, rather than the "dry" textual format used in the experiment. It would also be of interest to test such interventions with who suffer from an inability or unwillingness to repair relationships after an accidental breakdown of trust, such as people with Borderline Personality Disorder. The relative ease by which online interventions can be assigned, and the opportunity for people to test the effect of their behaviour with artificial, but human-like agents, may pave the way for efficient, low-cost, effective treatment programmes which may help a wide-variety of people overcome detrimental actions in social situations.

<!--
Second, we selected trustees from the general population, which might not suffer from the inability or unwillingness to repair relationships due to accidental breakdown of trust that characterises some mental health disorders such as BPD. As such, it would be interesting to contrast these results with findings from experiments involving trustees that are selected from patient populations known to suffer from difficulties in maintaining or repairing cooperative interactions. Third, as we explained above, the choice of the task to measure transfer of intervention learning could be made better by involving less popular paradigms. The high popularity of the Prisoner's Dilemma and the strategy of playing tit-for-tat may have resulted in a strong prior on which strategy to adopt in this game irrespective of the intervention. We believed that asking people about how they felt in the control condition might have affected how they behaved and might constitute an intervention in itself. However, being able to compare the differential impact of the intervention on the emotional interpretation of the opponent action between an intervention and control conditions could lead to insights on the mechanism through which the intervention affects the emotional reaction to the opponent's actions.
-->

# Conclusion

<!-- MS: Don't think we need a conclusion? -->

We explored the effect of a brief cognitive intervention on the behaviour of human trustees facing adaptive artificial investors designed to replicate the behaviour of human investors in the repeated trust game. Each state defines different levels of a cooperative response with the agent able to transition between these states based on the behavior of the human opponent. Feedback from participants indicated that these agents were sometimes perceived as humans. Their strategy led to emergent cooperative behaviour when playing the repeated trust game with human players. The intervention, promoting a less impulsive reaction to transgressive actions, led to coaxing behavior and less negative reciprocity when the investor sent a very low investment. It also led to more trustworthy behavior prior to the pre-programmed defection trial and to coaxing behavior after defection. Whilst this intervention effect varied between participants and generally was not transferred to a new game, an HMM analysis of participant's play post intervention showed differentiated patterns of transitions between latent states, indicating a change in the effect of the opponent action on the probability of transitioning between latent mental states.

# References
